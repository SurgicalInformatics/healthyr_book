% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
\PassOptionsToPackage{dvipsnames,svgnames*,x11names*}{xcolor}
%
\documentclass[
  12pt,
  krantz2]{krantz}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
  \setmonofont[Scale=0.65]{Source Code Pro}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={R for Health Data Science},
  pdfauthor={Ewen Harrison and Riinu Pius},
  colorlinks=true,
  linkcolor=Maroon,
  filecolor=Maroon,
  citecolor=Blue,
  urlcolor=Blue,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx,grffile}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage[bf,singlelinecheck=off]{caption}

% Required for kableExtra - EMH 29/07/2019
\usepackage{array}
\usepackage{multirow}
% \usepackage[table]{xcolor} %This conflicted
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage[normalem]{ulem}

% Changing line spacing of verbatim (R code results) - RO
% Should only be temp fix, as all verbatim affect including
% chapter numbers, titles, quotes etc - EH
\usepackage{etoolbox}
\BeforeBeginEnvironment{verbatim}{\def\baselinestretch{0.7}}

% To print text width - RO
\usepackage{layouts}
%\printinunitsof{cm}\prntlen{\textwidth}


% float handling package  - RO
\usepackage{placeins}

% krantz2 option - EMH 05/09/2019
% \documentclass[krantz2]{krantz}

\usepackage{framed,color}
\definecolor{shadecolor}{RGB}{248,248,248}

\renewcommand{\textfraction}{0.05}
\renewcommand{\topfraction}{0.8}
\renewcommand{\bottomfraction}{0.8}
\renewcommand{\floatpagefraction}{0.75}

\renewenvironment{quote}{\begin{VF}}{\end{VF}}
\let\oldhref\href
\renewcommand{\href}[2]{#2\footnote{\url{#1}}}

\makeatletter
\newenvironment{kframe}{%
\medskip{}
\setlength{\fboxsep}{.8em}
 \def\at@end@of@kframe{}%
 \ifinner\ifhmode%
  \def\at@end@of@kframe{\end{minipage}}%
  \begin{minipage}{\columnwidth}%
 \fi\fi%
 \def\FrameCommand##1{\hskip\@totalleftmargin \hskip-\fboxsep
 \colorbox{shadecolor}{##1}\hskip-\fboxsep
     % There is no \\@totalrightmargin, so:
     \hskip-\linewidth \hskip-\@totalleftmargin \hskip\columnwidth}%
 \MakeFramed {\advance\hsize-\width
   \@totalleftmargin\z@ \linewidth\hsize
   \@setminipage}}%
 {\par\unskip\endMakeFramed%
 \at@end@of@kframe}
\makeatother

\renewenvironment{Shaded}{\begin{kframe}}{\end{kframe}}

\usepackage{makeidx}
\makeindex

\urlstyle{tt}

\usepackage{amsthm}
\makeatletter
\def\thm@space@setup{%
  \thm@preskip=8pt plus 2pt minus 4pt
  \thm@postskip=\thm@preskip
}
\makeatother

\frontmatter
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\usepackage[]{natbib}
\bibliographystyle{apalike}

\title{R for Health Data Science}
\author{Ewen Harrison and Riinu Pius}
\date{2020-08-19}

\begin{document}
\maketitle

% you may need to leave a few empty pages before the dedication page

%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage\thispagestyle{empty}\null
%\cleardoublepage\newpage
\thispagestyle{empty}

\begin{center}
``The future is already here — it's just not evenly distributed.''

William Gibson
%\includegraphics{images/dedication.pdf}
\end{center}

\setlength{\abovedisplayskip}{-5pt}
\setlength{\abovedisplayshortskip}{-5pt}

{
\hypersetup{linkcolor=}
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoftables
\listoffigures
\hypertarget{preface}{%
\chapter*{Preface}\label{preface}}


\textbf{For draft version}

This is the electronic version of the HealthyR book to be published by CRC Press/Chapman \& Hall in November 2020.
The electronic version will always be freely available.

HealthyR resources: \href{https://healthyr.surgicalinformatics.org/}{healthyr.surgicalinformatics.org}

Version 0.9.7

This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivs 3.0 United States License. To view a copy of this license, visit \url{http://creativecommons.org/licenses/by-nc-nd/3.0/us/}

\hypertarget{why-read-this-book}{%
\section*{Why read this book}\label{why-read-this-book}}


\begin{quote}
We are drowning in information but starved for knowledge.\\
John Naisbitt
\end{quote}

In this age of information, the manipulation, analysis and interpretation of data has become a fundamental part of professional life.
Nowhere more so than in the delivery of healthcare.
From the understanding of disease and the development of new treatments, to the diagnosis and management of individual patients, the use of data and technology is now an integral part of the business of healthcare.

Those working in healthcare interact daily with data, often without realising it.
The conversion of this avalanche of information to useful knowledge is essential for high-quality patient care.
An important part of this information revolution is the opportunity for everybody to become involved in data analysis.
This democratisation is driven in part by the open source software movement -- no longer do we require expensive specialised software to do this.

The statistical programming language, R, is firmly at the heart of this.

This book will take an individual with little or no experience in data science, all the way through to the execution of sophisticated analyses.
We emphasise the importance of truly understanding the underlying data with liberal use of plotting, rather than relying on opaque and possibly poorly understood statistical tests.
There are numerous examples included that can be adapted for your own data, together with our own R packages with easy-to-use functions.

We have a lot of fun teaching this course and focus on making the material as accessible as possible.
We limit equations to a minimum in favour of code, and use examples rather than lengthy explanations.
We are grateful to the many individuals and students who have helped refine this book and welcome suggestions and bug reports via \url{https://github.com/SurgicalInformatics}.

Ewen Harrison and Riinu Pius

\hypertarget{acknowledgments}{%
\section*{Acknowledgments}\label{acknowledgments}}


Katie Connor, Tom Drake, Cameron Fairfield, Peter Hall, Stephen Knight, Kenneth McLean, Lisa Norman, Katie Shaw, Michael Ramage, Einar Pius, Olivia Swann.

\hypertarget{about-the-authors}{%
\chapter*{About the Authors}\label{about-the-authors}}


Ewen is a surgeon and Riinu is a physicist.
And they're both data scientists too.
They dabble with a few programming languages and are generally all over technology.
They are most enthusiastic about the R statistical programming language and have a combined experience of 25 years using it.
They work at the University of Edinburgh and have taught R to hundreds of healthcare professionals and researchers.

They believe a first introduction to R and statistical programming should be relatively jargon-free and outcome-oriented (get those pretty plots out).
The understanding of complicated concepts will come over time with practice and experience, not through a re-telling of the history of computing bit-by-byte, or with the inclusion of the underlying equations for each statistical test (although Ewen has sneaked a few equations in).

Overall, they hope to make the text fun and accessible.
Just like them.

\mainmatter

\hypertarget{part-data-wrangling-and-visualisation}{%
\part{Data wrangling and visualisation}\label{part-data-wrangling-and-visualisation}}

\hypertarget{why-we-love-r}{%
\chapter{Why we love R}\label{why-we-love-r}}

Thank you for choosing this book on using R for health data analysis.
Even if you're already familiar with the R language, we hope you will find some new approaches here as we make the most of the latest R tools including some we've developed ourselves.
Those already familiar with R are encouraged to still skim through the first few chapters to familiarise yourself with the style of R we recommend.

R can be used for all the health data science applications we can think of.
From bioinformatics and computational biology, to administrative data analysis and natural language processing, through internet-of-things and wearable data, to machine learning and artificial intelligence, and even public health and epidemiology.
R has it all.

Here are the main reasons we love R:

\begin{itemize}
\tightlist
\item
  R is versatile and powerful - use it for

  \begin{itemize}
  \tightlist
  \item
    graphics;
  \item
    all the statistical tests you can dream of;
  \item
    machine learning and deep learning;
  \item
    automated reports;
  \item
    websites;
  \item
    and even books (yes, this book was written entirely in R).
  \end{itemize}
\item
  R scripts can be reused - gives you efficiency and reproducibility.
\item
  It is free to use by anyone, anywhere.
\end{itemize}

\includegraphics[width=1.5625in,height=\textheight]{images/chapter01/Rlogo.png}

\hypertarget{chap01-what-script}{%
\section{Help, what's a script?}\label{chap01-what-script}}

\index{RStudio@\textbf{RStudio}!script}

A script is a list of instructions.
It is just a text file and no special software is required to view one.
An example R script is shown in Figure \ref{fig:chap01-fig-rscript}.

\textbf{Don't panic!}
The only thing you need to understand at this point is that what you're looking at is a list of instructions written in the R language.

\index{comments}
You should also notice that some parts of the script look like normal English.
These are the lines that start with a \# and they are called ``comments''.
We can (and should) include these comments in everything we do.
These are notes of what we were doing, both for colleagues as well as our future selves.

\begin{figure}
\includegraphics[width=0.9\linewidth]{images/chapter01/example_script} \caption{An example R script from RStudio.}\label{fig:chap01-fig-rscript}
\end{figure}

Lines that do not start with \# are R code.
This is where the number crunching really happens.
We will cover the details of this R code in the next few chapters.
The purpose of this chapter is to describe some of the terminology as well as the interface and tools we use.

For the impatient:

\begin{itemize}
\tightlist
\item
  We interface R using RStudio
\item
  We use the \textbf{tidyverse} packages that are a substantial extension to base R functionality (we repeat: extension, not replacement)
\end{itemize}

Even though R is a language, don't think that after reading this book you should be able to open a blank file and just start typing in R code like an evil computer genius from a movie.
This is not what real-world programming looks like.

Firstly, you should be copy-pasting and adapting existing R code examples - whether from this book, the internet, or later from your existing work.
Re-writing everything from scratch is not efficient.
Yes, you will understand and eventually remember a lot of it, but to spend time memorising specific functions that can easily be looked up and copied is simply not necessary.

Secondly, R is an interactive language.
Meaning that we ``run'' R code line by line and get immediate feedback.
We do not write a whole script without trying each part out as we go along.

Thirdly, do not worry about making mistakes.
Celebrate them!
The whole point of R and reproducibility is that manipulations are not applied directly on a dataset, but a copy of it.
Everything is in a script, so you can't do anything wrong.
If you make a mistake like accidentally overwriting your data, we can just reload it, rerun the steps that worked well and continue figuring out what went wrong at the end.
And since all of these steps are written down in a script, R will redo everything with a single push of a button.
You do not have to repeat a set of mouse clicks from dropdown menus as in other statistical packages, which quickly becomes a blessing.

\hypertarget{what-is-rstudio}{%
\section{What is RStudio?}\label{what-is-rstudio}}

\index{RStudio}

RStudio is a free program that makes working with R easier.
An example screenshot of RStudio is shown in Figure \ref{fig:chap01-fig-rstudio}.
We have already introduced what is in the top-left pane - the \textbf{Script}.

\begin{figure}
\includegraphics[width=1\linewidth]{images/chapter01/rstudio_interface} \caption{We use RStudio to work with R.}\label{fig:chap01-fig-rstudio}
\end{figure}

Now, look at the little \textbf{Run} and \textbf{Source} buttons at the top-right corner of the script pane.
Clicking \textbf{Run} executes a line of R code.
Clicking \textbf{Source} executes all lines of R code in the script (it is essentially `Run all lines').
When you run R code, it gets sent to the \textbf{Console} which is the bottom-left panel.
This is where R really lives.

\begin{quote}
Keyboard Shortcuts!\\
Run line: Control+Enter\\
Run all lines (Source): Control+Shift+Enter\\
(On a Mac, both Control or Command work)
\end{quote}

The Console is where R speaks to us.
When we're lucky, we get results in there - in this example the results of a \emph{t}-test (last line of the script).
When we're less lucky, this is also where Errors or Warnings appear.

R Errors are a lot less scary than they seem!
Yes, if you're using a regular computer program where all you do is click on some buttons, then getting a proper red error that stops everything is quite unusual.
But in programming, Errors are just a way for R to communicate with us.

We see Errors in our own work every single day, they are very normal and do not mean that everything is wrong or that you should give up.
Try to re-frame the word Error to mean ``feedback'', as in ``Hello, this is R. I can't continue, this is the feedback I am giving you.''
The most common Errors you'll see are along the lines of ``Error: something not found''.
This almost always means there's a typo or you've misspelled something.
Furthermore, R is case sensitive so capitalisation matters (variable name \texttt{lifeExp} is not the same as \texttt{lifeexp}).

The Console can only print text, so any plots you create in your script appear in the \textbf{Plots} pane (bottom-right).

Similarly, datasets that you've loaded or created appear in the \textbf{Environment} tab.
When you click on a dataset, it pops up in a nice viewer that is fast even when there is a lot of data.
This means you can have a look and scroll through your rows and columns, the same way you would with a spreadsheet.

\hypertarget{getting-started}{%
\section{Getting started}\label{getting-started}}

\index{installation@\textbf{installation}!tidyverse}
\index{installation@\textbf{installation}!packages}
\index{installation@\textbf{installation}!RStudio}

To start using R, you should do these two things:

\begin{itemize}
\tightlist
\item
  Install R (from \url{https://www.r-project.org/})
\item
  Install RStudio Desktop (from \url{https://www.rstudio.com/})
\end{itemize}

When you first open up RStudio, you'll also want to install some extra packages to extend the base R functionality.
You can do this in the \textbf{Packages} tab (next to the Plots tab in the bottom-right in Figure \ref{fig:chap01-fig-rstudio}).

A Package is just a collection of functions (commands) that are not included in the standard R installation, called base-R.

A lot of the functionality introduced in this book comes from the \textbf{tidyverse} family of R packages (\url{http://tidyverse.org} \citet{tidyverse2019}).
So when you go to Packages, click \textbf{Install}, type in \textbf{tidyverse}, and a whole collection of useful and modern packages will be installed.

Even though you've installed the \textbf{tidyverse} packages, you'll still need to tell R when you're about to use them.
We include \texttt{library(tidyverse)} at the top of every script we write:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

\includegraphics[width=0.7\linewidth]{images/chapter01/tidyverse_loading_messages}

We can see that it has loaded 8 packages (\textbf{ggplot2}, \textbf{tibble}, \textbf{tidyr}, \textbf{readr}, \textbf{purrr}, \textbf{dplyr}, \textbf{stringr}, \textbf{forcats}), the number behind a package name is its version.

The ``Conflicts'' message is expected and can safely be ignored.\footnote{It just means that when we use \texttt{filter} or \texttt{lag}, they will come from the \textbf{dplyr} package, rather than the \textbf{stats} package.
  We've never needed to use \texttt{filter} and \texttt{lag} from \textbf{stats}, but if you do, then use the double colon, i.e., \texttt{stats::filter()} or \texttt{stats::lag()}, as just \texttt{filter()} will use the \textbf{dplyr} one.}

There are a few other R packages that we use and are not part of the tidyverse, but we will introduce them as we go along.
If you're incredibly curious, head to the Resources section of the HealthyR website which is the best place to find up-to-date links and installation instructions. Our R and package versions are also listed in the Appendix.

\hypertarget{getting-help}{%
\section{Getting help}\label{getting-help}}

\index{help}
\index{errors}

The best way to troubleshoot R errors is to copy-paste them into a search engine (e.g., Google).
Searching online is also a great way to learn how to do new specific things or to find code examples.
You should copy-paste solutions into your R script to then modify to match what you're trying to do.
We are constantly copying code from online forums and our own existing scripts.

However, there are many different ways to achieve the same thing in R.
Sometimes you'll search for help and come across R code that looks nothing like what you've seen in this book.
The \textbf{tidyverse} packages are relatively new and use the pipe (\texttt{\%\textgreater{}\%}), something we'll come on to.
But search engines will often prioritise older results that use a more traditional approach.

So older solutions may come up at the top.
Don't get discouraged if you see R code that looks completely different to what you were expecting.
Just keep scrolling down or clicking through different answers until you find something that looks a little bit more familiar.

If you're working offline, then RStudio's built in \textbf{Help} tab is useful.
To use the Help tab, click your cursor on something in your code (e.g., \texttt{read\_csv()}) and press F1.
This will show you the definition and some examples.
F1 can be hard to find on some keyboards, an alternative is to type, e.g., \texttt{?read\_csv}.
This will also open the Help tab for this function.

However, the Help tab is only useful if you already know what you are looking for but can't remember exactly how it works.
For finding help on things you have not used before, it is best to Google it.

R has about 2 million users so someone somewhere has probably had the same question or problem.

RStudio also has a Help drop-down menu at the very top (same row where you find ``File'', "Edit, \ldots).
The most notable things in the Help drop-down menu are the Cheatsheets.
These tightly packed two-pagers include many of the most useful functions from \texttt{tidyverse} packages.
They are not particularly easy to learn from, but invaluable as an \emph{aide-mémoire}.

\hypertarget{work-in-a-project}{%
\section{Work in a Project}\label{work-in-a-project}}

The files on your computer are organised into folders.
RStudio Projects live in your computer's normal folders - they placemark the working directory of each analysis project.
These project folders can be viewed or moved around the same way you normally work with files and folders on your computer.

The top-right corner of your RStudio should never say \textbf{``Project: (None)''}.
If it does, click on it and create a New Project.
After clicking on New Project, you can decide whether to let RStudio create a New Directory (folder) on your computer. Alternatively, if your data files are already organised into an ``Existing folder'', use the latter option.

Every set of analysis you are working on must have its own folder and RStudio project.
This enables you to switch between different projects without getting the data, scripts, or output files all mixed up.
Everything gets read in or saved to the correct place.
No more exporting a plot and then going through the various Documents, etc., folders on your computer trying to figure out where your plot might have been saved to.
It got saved to the project folder.

\hypertarget{restart-r-regularly}{%
\section{Restart R regularly}\label{restart-r-regularly}}

Have you tried turning it off and on again? It is vital to restart R regularly.
Restarting R helps to avoid accidentally using the wrong data or functions stored in the environment.
Restarting R only takes a second and we do it several times per day!
Once you get used to saving everything in a script, you'll always be happy to restart R.
This will help you develop robust and reproducible data analysis skills.

\begin{quote}
You can restart R by clicking on \texttt{Session\ -\textgreater{}\ Restart\ R} (top menu).
\end{quote}

Furthermore, RStudio has a default setting that is no longer considered best practice.
After installing RStudio, you should go change two small but important things in \texttt{Tools\ -\textgreater{}\ Global\ Options}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Uncheck} ``Restore .RData into Workspace on startup''
\item
  Set ``Save .RData on exit'' to \textbf{Never}
\end{enumerate}

\begin{figure}
\includegraphics[width=1\linewidth]{images/chapter01/rstudio_settings} \caption{Configuring your RStudio Tools -> Global Options:  Untick "Restore .RData into Workspace on Exit" and Set "Save .RData on exit" to Never.}\label{fig:chap01-fig-settings}
\end{figure}

This does not mean you can't or shouldn't save your work in \texttt{.RData/.rda} files.
But it is best to do it consciously and load exactly what you want to load.
Letting R silently save and load everything for you may also include broken data or objects.

\hypertarget{notation-throughout-this-book}{%
\section{Notation throughout this book}\label{notation-throughout-this-book}}

When mentioned in the text, the names of R packages are in bold font, e.g., \textbf{ggplot2}, whereas functions, objects, and variables are printed with mono-spaced font, e.g \texttt{filter()}, \texttt{mean()}, \texttt{lifeExp}. Functions are always followed by brackets: \texttt{()}, whereas data objects or variables are not.

Otherwise, R code lives in the grey areas known as `code chunks'.
Lines of R \emph{output} start with a double \#\# - this will be the numbers or text that R gives us after executing code.
R also adds a counter at the beginning of every new line; look at the numbers in the square brackets {[}{]} below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# colon between two numbers creates a sequence}
\DecValTok{1001}\OperatorTok{:}\DecValTok{1017}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1001 1002 1003 1004 1005 1006 1007 1008 1009 1010 1011 1012 1013 1014 1015
## [16] 1016 1017
\end{verbatim}

Remember, lines of R code that start with \# are called comments.
We already introduced comments as notes about the R code earlier in this chapter (Section \ref{chap01-what-script} ``Help, what's a script?''), however, there is a second use case for comments.

When you make R code a comment, by adding a \# in front of it, it gets `commented out'.
For example, let's say your R script does two things, prints numbers from 1 to 4, and then numbers from 1001 to 1004:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's print small numbers:}
\DecValTok{1}\OperatorTok{:}\DecValTok{4}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now we're printing bigger numbers:}
\DecValTok{1001}\OperatorTok{:}\DecValTok{1004}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1001 1002 1003 1004
\end{verbatim}

If you decide to `comment out' the printing of big numbers, the code will look like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Let's print small numbers:}
\DecValTok{1}\OperatorTok{:}\DecValTok{4}

\CommentTok{# Now we're printing bigger numbers:}
\CommentTok{# 1001:1004}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1 2 3 4
\end{verbatim}

You may even want to add another real comment to explain why the latter was commented out:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Now commented out as not required any more}
\CommentTok{# Now we're printing bigger numbers:}
\CommentTok{# 1001:1004}
\end{Highlighting}
\end{Shaded}

You could of course delete the line altogether, but commenting out is useful as you might want to include the lines later by removing the \# from the beginning of the line.

\begin{quote}
Keyboard Shortcut for commenting out/commenting in multiple lines at a time:
Control+Shift+C\\
(On a Mac, both Control or Command work)
\end{quote}

\hypertarget{r-basics}{%
\chapter{R basics}\label{r-basics}}

Throughout this book, we are conscious of the balance between theory and practice.
Some learners may prefer to see all definitions laid out before being shown an example of a new concept.
Others would rather see practical examples and explanations build up to a full understanding over time.
We strike a balance between these two approaches that works well for most people in the audience.

Sometimes we will show you an example that may use words that have not been formally introduced yet.
For example, we start this chapter with data import - R is nothing without data.

In so doing, we have to use the word ``argument'', which is only defined two sections later (in \ref{chap02-objects-functions} ``Objects and functions'').
A few similar instances arise around statistical concepts in the Data Analysis part of the book.
You will come across sentences along the lines of ``this concept will become clearer in the next section''.
Trust us and just go with it.

The aim of this chapter is to familiarise you with how R works.
We will read in data and start basic manipulations. You may want to skip parts of this chapter if you already:

\begin{itemize}
\tightlist
\item
  have found the Import Dataset interface;
\item
  know what numbers, characters, factors, and dates look like in R;
\item
  are familiar with the terminology around objects, functions, arguments;
\item
  have used the pipe: \texttt{\%\textgreater{}\%};
\item
  know how to filter data with operators such as \texttt{==,\ \textgreater{},\ \textless{},\ \&,\ \textbar{}};
\item
  know how to handle missing data (NAs), and why they can behave weirdly in a filter;
\item
  have used \texttt{mutate()}, \texttt{c()}, \texttt{paste()}, \texttt{if\_else()}, and the joins.
\end{itemize}

\hypertarget{chap02-h2-reading-data-into-r}{%
\section{Reading data into R}\label{chap02-h2-reading-data-into-r}}

\index{import data}
\index{reading data}

Data usually comes in the form of a table, such as a spreadsheet or database.
In the world of the \textbf{tidyverse}, a table read into R gets called a \texttt{tibble}.

A common format in which to receive data is CSV (comma separated values).
CSV is an uncomplicated spreadsheet with no formatting.
It is just a single table with rows and columns (no worksheets or formulas).
Furthermore, you don't need special software to quickly view a CSV file - a text editor will do, and that includes RStudio.

For example, look at ``example\_data.csv'' in the healthyr project's folder in Figure \ref{fig:chap2-fig-examplecsv} (this is the Files pane at the bottom-right corner of your RStudio).

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/chapter02/files_csv_example} 

}

\caption{View or import a data file.}\label{fig:chap2-fig-examplecsv}
\end{figure}

Clicking on a data file gives us two options: ``View File'' or ``Import Dataset''.

We will show you how to use the Import Dataset interface in a bit, but for standard CSV files, we don't usually bother with the Import interface and just type in (or copy from a previous script):
\index{functions@\textbf{functions}!read\_csv}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{example_data <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"example_data.csv"}\NormalTok{)}
\KeywordTok{View}\NormalTok{(example_data)}
\end{Highlighting}
\end{Shaded}

There are a couple of things to say about the first R code chunk of this book.
First and foremost: do not panic.
Yes, if you're used to interacting with data by double-clicking on a spreadsheet that just opens up, then the above R code does seem a bit involved.

However, running the example above also has an immediate visual effect.
As soon as you click Run (or press Ctrl+Enter/Command+Enter), the dataset immediately shows up in your Environment and opens in a Viewer.
You can have a look and scroll through the same way you would in Excel or similar.

So what's actually going on in the R code above:

\begin{itemize}
\tightlist
\item
  We load the \textbf{tidyverse} packages (as covered in the first chapter of this book).
\item
  We have a CSV file called ``example\_data.csv'' and are using \texttt{read\_csv()} to read it into R.
\item
  We are using the assignment arrow \texttt{\textless{}-} to save it into our Environment using the same name: \texttt{example\_data}.
\item
  The \texttt{View(example\_data)} line makes it pop up for us to view it. Alternatively, click on \texttt{example\_data} in the Environment to achieve the exact same thing.
\end{itemize}

More about the assignment arrow (\texttt{\textless{}-}) and naming things in R are covered later in this chapter.
Do not worry if everything is not crystal clear just now.

\hypertarget{import-dataset-interface}{%
\subsection{Import Dataset interface}\label{import-dataset-interface}}

In the \texttt{read\_csv()} example above, we read in a file that was in a specific (but common) format.

However, if your file uses semicolons instead of commas, or commas instead of dots, or a special number for missing values (e.g., 99), or anything else weird or complicated, then we need a different approach.

RStudio's \textbf{Import Dataset} interface (Figure \ref{fig:chap2-fig-examplecsv}) can handle all of these and more.

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/chapter02/import_options} 

}

\caption{Import: Some of the special settings your data file might have.}\label{fig:chap02-fig-import-tool}
\end{figure}

\begin{figure}

{\centering \includegraphics[width=0.5\linewidth]{images/chapter02/code_preview} 

}

\caption{After using the Import Dataset window, copy-paste the resulting code into your script.}\label{fig:chap02-fig-import-code}
\end{figure}

After selecting the specific options to import a particular file, a friendly preview window will show whether R properly understands the format of your data.

DO NOT BE tempted to press the \textbf{Import} button.

Yes, this will read in your dataset once, but means you have to reselect the options every time you come back to RStudio.
Instead, copy-paste the code (e.g., Figure \ref{fig:chap02-fig-import-code}) into your R script.
This way you can use it over and over again.

Ensuring that all steps of an analysis are recorded in scripts makes your workflow reproducible by your future self, colleagues, supervisors, and extraterrestrials.

\begin{quote}
The \texttt{Import\ Dataset} button can also help you to read in Excel, SPSS, Stata, or SAS files (instead of \texttt{read\_csv()}, it will give you \texttt{read\_excel()}, \texttt{read\_sav()}, \texttt{read\_stata()}, or \texttt{read\_sas()}).
\end{quote}

If you've used R before or are using older scripts passed by colleagues, you might see \texttt{read.csv()} rather than \texttt{read\_csv()}.
Note the dot rather than the underscore.

In short, \texttt{read\_csv()} is faster and more predictable and in all new scripts is to be recommended.

In existing scripts that work and are tested, we do not recommend that you start replacing \texttt{read.csv()} with \texttt{read\_csv()}.
For instance, \texttt{read\_csv()} handles categorical variables differently \footnote{It does not silently convert strings to factors, i.e., it defaults to \texttt{stringsAsFactors\ =\ FALSE}. For those not familiar with the terminology here - don't worry, we will cover this in just a few sections.}.
An R script written using the \texttt{read.csv()} might not work as expected any more if just replaced with \texttt{read\_csv()}.

\begin{quote}
Do not start updating and possibly breaking existing R scripts by replacing base R functions with the tidyverse equivalents we show here. Do use the modern functions in any new code you write.
\end{quote}

\hypertarget{reading-in-the-global-burden-of-disease-example-dataset}{%
\subsection{Reading in the Global Burden of Disease example dataset}\label{reading-in-the-global-burden-of-disease-example-dataset}}

In the next few chapters of this book, we will be using the Global Burden of Disease datasets.
The Global Burden of Disease Study (GBD) is the most comprehensive worldwide observational epidemiological study to date.
It describes mortality and morbidity from major diseases, injuries and risk factors to health at global, national and regional levels.
\footnote{Global Burden of Disease Collaborative Network.
  Global Burden of Disease Study 2017 (GBD 2017) Results.
  Seattle, United States: Institute for Health Metrics and Evaluation (IHME), 2018.
  Available from \url{http://ghdx.healthdata.org/gbd-results-tool}.}

GBD data are publicly available from the website.
Table \ref{tab:chap2-tab-gbd} and Figure \ref{fig:chap2-fig-gbd} show a high level version of the project data with just 3 variables: \texttt{cause}, \texttt{year}, \texttt{deaths\_millions} (number of people who die of each cause every year).
Later, we will be using a longer dataset with different subgroups and we will show you how to summarise comprehensive datasets yourself.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{gbd_short <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:chap2-tab-gbd}Deaths per year from three broad disease categories (short version of the Global Burden of Disease example dataset).}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}[t]{lcr}
\toprule
year & cause & deaths\_millions\\
\midrule
1990 & Communicable diseases & 15.36\\
1990 & Injuries & 4.25\\
1990 & Non-communicable diseases & 26.71\\
\addlinespace
1995 & Communicable diseases & 15.11\\
1995 & Injuries & 4.53\\
1995 & Non-communicable diseases & 29.27\\
\addlinespace
2000 & Communicable diseases & 14.81\\
2000 & Injuries & 4.56\\
2000 & Non-communicable diseases & 31.01\\
\addlinespace
2005 & Communicable diseases & 13.89\\
2005 & Injuries & 4.49\\
2005 & Non-communicable diseases & 32.87\\
\addlinespace
2010 & Communicable diseases & 12.51\\
2010 & Injuries & 4.69\\
2010 & Non-communicable diseases & 35.43\\
\addlinespace
2015 & Communicable diseases & 10.88\\
2015 & Injuries & 4.46\\
2015 & Non-communicable diseases & 39.28\\
\addlinespace
2017 & Communicable diseases & 10.38\\
2017 & Injuries & 4.47\\
2017 & Non-communicable diseases & 40.89\\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}

{\centering \includegraphics{02_basics_files/figure-latex/chap2-fig-gbd-1} 

}

\caption{Line and bar charts: Cause of death by year (GBD). Data in (B) are the same as (A) but stacked to show the total of all causes.}\label{fig:chap2-fig-gbd}
\end{figure}

\hypertarget{chap02-vartypes}{%
\section{Variable types and why we care}\label{chap02-vartypes}}

\index{variable types@\textbf{variable types}}
\index{continuous data@\textbf{continuous data}!variable types}
\index{categorical data@\textbf{categorical data}!variable types}
\index{date-time@\textbf{date-time}}

There are three broad types of data:

\begin{itemize}
\tightlist
\item
  continuous (numbers), in R: numeric, double, or integer;
\item
  categorical, in R: character, factor, or logical (TRUE/FALSE);
\item
  date/time, in R: POSIXct date-time\footnote{Portable Operating System Interface (POSIX) is a set of computing standards. There's nothing more to understand about this other than when R starts shouting ``POSIXct this or POSIXlt that'' at you, check your date and time variables}.
\end{itemize}

Values within a column all have to be the same type, but a tibble can of course hold columns of different types.
Generally, R is good at figuring out what type of data you have (in programming, this `figuring out' is called `parsing').

For example, when reading in data, it will tell you what was assumed for each column:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{typesdata <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/typesdata.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   id = col_character(),
##   group = col_character(),
##   measurement = col_double(),
##   date = col_datetime(format = "")
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   id    group     measurement date               
##   <chr> <chr>           <dbl> <dttm>             
## 1 ID1   Control           1.8 2017-01-02 12:00:00
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00
\end{verbatim}

This means that a lot of the time you do not have to worry about those little \texttt{\textless{}chr\textgreater{}} vs \texttt{\textless{}dbl\textgreater{}} vs \texttt{\textless{}S3:\ POSIXct\textgreater{}} labels.
But in cases of irregular or faulty input data, or when doing a lot of calculations and modifications to your data, we need to be aware of these different types to be able to find and fix mistakes.

For example, consider a similar file as above but with some data entry issues introduced:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata_faulty <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/typesdata_faulty.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Parsed with column specification:
## cols(
##   id = col_character(),
##   group = col_character(),
##   measurement = col_character(),
##   date = col_character()
## )
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata_faulty}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   id    group     measurement date           
##   <chr> <chr>     <chr>       <chr>          
## 1 ID1   Control   1.8         02-Jan-17 12:00
## 2 ID2   Treatment 4.5         03-Feb-18 13:00
## 3 ID3   Treatment 3.7 or 3.8  04-Mar-19 14:00
\end{verbatim}

Notice that R parsed both the measurement and date variables as characters.
Measurement has been parsed as a character because of a data entry issue: the person taking the measurement couldn't decide which value to note down (maybe the scale was shifting between the two values) so they included both values and text ``or'' in the cell.

A numeric variable will also get parsed as a categorical variable if it contains certain typos, e.g., if entered as ``3..7'' instead of ``3.7''.

The reason R didn't automatically make sense of the date column is that it couldn't tell which is the date and which is the year: \texttt{02-Jan-17} could stand for \texttt{02-Jan-2017} as well as \texttt{2002-Jan-17}.

Therefore, while a lot of the time you do not have to worry about variable types and can just get on with your analysis, it is important to understand what the different types are to be ready to deal with them when issues arise.

\begin{quote}
Since health datasets are generally full of categorical data, it is crucial to understand the difference between characters and factors (both are types of categorical variables in R with pros and cons).
\end{quote}

So here we go.

\hypertarget{numeric-variables-continuous}{%
\subsection{Numeric variables (continuous)}\label{numeric-variables-continuous}}

\index{variable types@\textbf{variable types}!continuous / numeric}

Numbers are straightforward to handle and don't usually cause trouble.
R usually refers to numbers as \texttt{numeric} (or \texttt{num}), but sometimes it really gets its nerd on and calls numbers \texttt{integer} or \texttt{double}.
Integers are numbers without decimal places (e.g., \texttt{1,\ 2,\ 3}), whereas \texttt{double} stands for ``Double-precision floating-point'' format (e.g., \texttt{1.234,\ 5.67890}).

It doesn't usually matter whether R is classifying your continuous data \texttt{numeric/num/double/int}, but it is good to be aware of these different terms as you will see them in R messages.

Something to note about numbers is that R doesn't usually print more than 6 decimal places, but that doesn't mean they don't exist.
For example, from the \texttt{typedata} tibble, we're taking the \texttt{measurement} column and sending it to the \texttt{mean()} function.
R then calculates the mean and tells us what it is with 6 decimal places:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata}\OperatorTok{$}\NormalTok{measurement }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.333333
\end{verbatim}

Let's save that in a new object:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{measurement_mean <-}\StringTok{ }\NormalTok{typesdata}\OperatorTok{$}\NormalTok{measurement }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

But when using the double equals operator to check if this is equivalent to a fixed value (you might do this when comparing to a threshold, or even another mean value), R returns \texttt{FALSE}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{measurement_mean }\OperatorTok{==}\StringTok{ }\FloatTok{3.333333}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

Now this doesn't seem right, does it - R clearly told us just above that the mean of this variable is 3.333333 (reminder: the actual values in the measurement column are 1.8, 4.5, 3.7).
The reason the above statement is \texttt{FALSE} is because \texttt{measurement\_mean} is quietly holding more than 6 decimal places.

And it gets worse. In this example, you may recognise that repeating decimals (0.333333\ldots) usually mean there's more of them somewhere. And you may think that rounding them down with the \texttt{round()} function would make your \texttt{==} behave as expected. Except, it's not about rounding, it's about how computers store numbers with decimals. Computers have issues with decimal numbers, and this simple example illustrates one:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\FloatTok{0.10} \OperatorTok{+}\StringTok{ }\FloatTok{0.05}\NormalTok{) }\OperatorTok{==}\StringTok{ }\FloatTok{0.15}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

This returns FALSE, meaning R does not seem to think that \texttt{0.10\ +\ 0.05} is equal to \texttt{0.15}. This issue isn't specific to R, but to programming languages in general. For example, python also thinks that the sum of \texttt{0.10} and \texttt{0.05} does not equal \texttt{0.15}.

This is where the \texttt{near()} function comes in handy:

\index{functions@\textbf{functions}!near}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{near}\NormalTok{(}\FloatTok{0.10+0.05}\NormalTok{, }\FloatTok{0.15}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{near}\NormalTok{(measurement_mean, }\FloatTok{3.333333}\NormalTok{, }\FloatTok{0.000001}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

The first two arguments for \texttt{near()} are the numbers you are comparing; the third argument is the precision you are interested in. So if the numbers are equal within that precision, it returns \texttt{TRUE}. You can omit the third argument - the precision (in this case also known as the tolerance). If you do, \texttt{near()} will use a reasonable default tolerance value.

\hypertarget{character-variables}{%
\subsection{Character variables}\label{character-variables}}

\index{variable types@\textbf{variable types}!character}

\emph{Characters} (sometimes referred to as \emph{strings} or \emph{character strings}) in R are letters, words, or even whole sentences (an example of this may be free text comments).
Characters are displayed in-between \texttt{""} (or \texttt{\textquotesingle{}\textquotesingle{}}).

A useful function for quickly investigating categorical variables is the \texttt{count()} function:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{typesdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(group)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   group         n
##   <chr>     <int>
## 1 Control       1
## 2 Treatment     2
\end{verbatim}

\texttt{count()} can accept multiple variables and will count up the number of observations in each subgroup, e.g., \texttt{mydata\ \%\textgreater{}\%\ count(var1,\ var2)}.

Another helpful option to count is \texttt{sort\ =\ TRUE}, which will order the result putting the highest count (\texttt{n}) to the top.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(group, }\DataTypeTok{sort =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   group         n
##   <chr>     <int>
## 1 Treatment     2
## 2 Control       1
\end{verbatim}

\texttt{count()}with the \texttt{sort\ =\ TRUE} option is also useful for identifying duplicate IDs or misspellings in your data.
With this example \texttt{tibble} (\texttt{typesdata}) that only has three rows, it is easy to see that the \texttt{id} column is a unique identifier whereas the \texttt{group} column is a categorical variable.

You can check everything by just eyeballing the \texttt{tibble} using the built in Viewer tab (click on the dataset in the Environment tab).

But for larger datasets, you need to know how to check and then clean data programmatically - you can't go through thousands of values checking they are all as intended without unexpected duplicates or typos.

For most variables (categorical or numeric), we recommend always plotting your data before starting analysis.
But to check for duplicates in a unique identifier, use \texttt{count()} with \texttt{sort\ =\ TRUE}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# all ids are unique:}
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{count}\NormalTok{(id, }\DataTypeTok{sort =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   id        n
##   <chr> <int>
## 1 ID1       1
## 2 ID2       1
## 3 ID3       1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# we add in a duplicate row where id = ID3,}
\CommentTok{# then count again:}
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_row}\NormalTok{(}\DataTypeTok{id =} \StringTok{"ID3"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{count}\NormalTok{(id, }\DataTypeTok{sort =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 2
##   id        n
##   <chr> <int>
## 1 ID3       2
## 2 ID1       1
## 3 ID2       1
\end{verbatim}

\hypertarget{factor-variables-categorical}{%
\subsection{Factor variables (categorical)}\label{factor-variables-categorical}}

\index{variable types@\textbf{variable types}!categorical / factor}

\emph{Factors} are fussy characters.
Factors are fussy because they include something called \emph{levels}.
Levels are all the unique values a factor variable could take, e.g., like when we looked at \texttt{typesdata\ \%\textgreater{}\%\ count(group)}.
Using factors rather than just characters can be useful because:

\begin{itemize}
\tightlist
\item
  The values factor levels can take are fixed.
  For example, once you tell R that \texttt{typesdata\$group} is a factor with two levels: Control and Treatment, combining it with other datasets with different spellings or abbreviations for the same variable will generate a warning.
  This can be helpful but can also be a nuisance when you really do want to add in another level to a \texttt{factor} variable.
\item
  Levels have an order.
  When running statistical tests on grouped data (e.g., Control vs Treatment, Adult vs Child) and the variable is just a character, not a factor, R will use the alphabetically first as the reference (comparison) level.
  Converting a character column into a factor column enables us to define and change the order of its levels.
  Level order affects many things including regression results and plots: by default, categorical variables are ordered alphabetically.
  If we want a different order in say a bar plot, we need to convert to a factor and reorder before we plot it.
  The plot will then order the groups correctly.
\end{itemize}

So overall, since health data is often categorical and has a reference (comparison) level, then factors are an essential way to work with these data in R.
Nevertheless, the fussiness of factors can sometimes be unhelpful or even frustrating.
A lot more about factor handling will be covered later (\ref{chap08-h1}).

\hypertarget{datetime-variables}{%
\subsection{Date/time variables}\label{datetime-variables}}

\index{variable types@\textbf{variable types}!date-time}
\index{functions@\textbf{functions}!dmy}
\index{functions@\textbf{functions}!ymd}

R is good for working with dates.
For example, it can calculate the number of days/weeks/months between two dates, or it can be used to find what future date is (e.g., ``what's the date exactly 60 days from now?'').
It also knows about time zones and is happy to parse dates in pretty much any format - as long as you tell R how your date is formatted (e.g., day before month, month name abbreviated, year in 2 or 4 digits, etc.).
Since R displays dates and times between quotes (""), they look similar to characters.
However, it is important to know whether R has understood which of your columns contain date/time information, and which are just normal characters.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate) }\CommentTok{# lubridate makes working with dates easier}
\NormalTok{current_datetime <-}\StringTok{ }\KeywordTok{Sys.time}\NormalTok{()}
\NormalTok{current_datetime}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-08-19 12:42:06 BST"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datetime <-}\StringTok{ "2020-12-01 12:00"}
\NormalTok{my_datetime}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-12-01 12:00"
\end{verbatim}

When printed, the two objects - \texttt{current\_datetime} and \texttt{my\_datetime} seem to have a similar format.
But if we try to calculate the difference between these two dates, we get an error:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datetime }\OperatorTok{-}\StringTok{ }\NormalTok{current_datetime}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in `-.POSIXt`(my_datetime, current_datetime): can only subtract from "POSIXt" objects
\end{verbatim}

That's because when we assigned a value to \texttt{my\_datetime}, R assumed the simpler type for it - so a character.
We can check what the type of an object or variable is using the \texttt{class()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{current_datetime }\OperatorTok{%>%}\StringTok{ }\KeywordTok{class}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "POSIXct" "POSIXt"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datetime }\OperatorTok{%>%}\StringTok{ }\KeywordTok{class}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "character"
\end{verbatim}

So we need to tell R that \texttt{my\_datetime} does indeed include date/time information so we can then use it in calculations:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datetime_converted <-}\StringTok{ }\KeywordTok{ymd_hm}\NormalTok{(my_datetime)}
\NormalTok{my_datetime_converted}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-12-01 12:00:00 UTC"
\end{verbatim}

Calculating the difference will now work:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datetime_converted }\OperatorTok{-}\StringTok{ }\NormalTok{current_datetime}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Time difference of 104.0124 days
\end{verbatim}

Since R knows this is a difference between two date/time objects, it prints them in a nicely readable way.
Furthermore, the result has its own type; it is a ``difftime''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{my_datesdiff <-}\StringTok{ }\NormalTok{my_datetime_converted }\OperatorTok{-}\StringTok{ }\NormalTok{current_datetime}
\NormalTok{my_datesdiff }\OperatorTok{%>%}\StringTok{ }\KeywordTok{class}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "difftime"
\end{verbatim}

This is useful if we want to apply this time difference on another date, e.g.:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2021-01-02 12:00"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{my_datesdiff}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2021-04-16 12:17:53 UTC"
\end{verbatim}

But if we want to use the number of days in a normal calculation, e.g., what if a measurement increased by 560 arbitrary units during this time period.
We might want to calculate the increase per day like this:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{560}\OperatorTok{/}\NormalTok{my_datesdiff}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error in `/.difftime`(560, my_datesdiff): second argument of / cannot be a "difftime" object
\end{verbatim}

Doesn't work, does it.
We need to convert \texttt{my\_datesdiff} (which is a difftime value) into a numeric value by using the \texttt{as.numeric()} function:

\begin{Shaded}
\begin{Highlighting}[]
\DecValTok{560}\OperatorTok{/}\KeywordTok{as.numeric}\NormalTok{(my_datesdiff)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 5.383972
\end{verbatim}

The \textbf{lubridate} package comes with several convenient functions for parsing dates, e.g., \texttt{ymd()}, \texttt{mdy()}, \texttt{ymd\_hm()}, etc. - for a full list see \url{lubridate.tidyverse.org}.

However, if your date/time variable comes in an extra special format, then use the \texttt{parse\_date\_time()} function where the second argument specifies the format using the specifiers given in Table \ref{tab:chap2-tab-timehelpers}.

\begin{table}[!h]

\caption{\label{tab:chap2-tab-timehelpers}Date/time format specifiers.}
\centering
\fontsize{9}{11}\selectfont
\begin{tabular}[t]{llr}
\toprule
Notation & Meaning & Example\\
\midrule
\%d & day as number & 01-31\\
\%m & month as number & 01-12\\
\%B & month name & January-December\\
\%b & abbreviated month & Jan-Dec\\
\%Y & 4-digit year & 2019\\
\%y & 2-digit year & 19\\
\%H & hours & 12\\
\%M & minutes & 01\\
\%S & seconds & 59\\
\%A & weekday & Monday-Sunday\\
\%a & abbreviated weekday & Mon-Sun\\
\bottomrule
\end{tabular}
\end{table}

For example:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{parse_date_time}\NormalTok{(}\StringTok{"12:34 07/Jan'20"}\NormalTok{, }\StringTok{"%H:%M %d/%b'%y"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-01-07 12:34:00 UTC"
\end{verbatim}

Furthermore, the same date/time specifiers can be used to rearrange your date and time for printing:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Sys.time}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-08-19 12:42:06 BST"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Sys.time}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{format}\NormalTok{(}\StringTok{"%H:%M on %B-%d (%Y)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "12:42 on August-19 (2020)"
\end{verbatim}

You can even add plain text into the \texttt{format()} function, R will know to put the right date/time values where the \texttt{\%} are:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Sys.time}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{format}\NormalTok{(}\StringTok{"Happy days, the current time is %H:%M %B-%d (%Y)!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Happy days, the current time is 12:42 August-19 (2020)!"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Sys.time}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }\KeywordTok{format}\NormalTok{(}\StringTok{"Happy days, the current time is %H:%M %B-%d (%Y)!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Happy days, the current time is 12:42 August-19 (2020)!"
\end{verbatim}

\hypertarget{chap02-objects-functions}{%
\section{Objects and functions}\label{chap02-objects-functions}}

\index{objects}
\index{functions@\textbf{functions}}

There are two fundamental concepts in statistical programming that are important to get straight - objects and functions.
The most common object you will be working with is a dataset.
This is usually something with rows and columns much like the example in Table \ref{tab:chap2-tab-examp1}.

\begin{table}

\caption{\label{tab:chap2-tab-examp1}Example of data in columns and rows, including missing values denoted `NA` (Not applicable/Not available). Once this dataset has been read into R it gets called dataframe/tibble.}
\centering
\fontsize{9}{11}\selectfont
\begin{tabular}[t]{rlrrr}
\toprule
id & sex & var1 & var2 & var3\\
\midrule
1 & Male & 4 & NA & 2\\
2 & Female & 1 & 4 & 1\\
3 & Female & 2 & 5 & NA\\
4 & Male & 3 & NA & NA\\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier

To get the small and made-up ``dataset'' into your Environment, copy and run this code\footnote{\texttt{c()} stands for combine and will be introduced in more detail later in this chapter}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{mydata <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}
  \DataTypeTok{id   =} \DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{,}
  \DataTypeTok{sex  =} \KeywordTok{c}\NormalTok{(}\StringTok{"Male"}\NormalTok{, }\StringTok{"Female"}\NormalTok{, }\StringTok{"Female"}\NormalTok{, }\StringTok{"Male"}\NormalTok{),}
  \DataTypeTok{var1 =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{),}
  \DataTypeTok{var2 =} \KeywordTok{c}\NormalTok{(}\OtherTok{NA}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\OtherTok{NA}\NormalTok{),}
  \DataTypeTok{var3 =} \KeywordTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{, }\OtherTok{NA}\NormalTok{, }\OtherTok{NA}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Data can live anywhere: on paper, in a spreadsheet, in an SQL database, or in your R Environment.
We usually initiate and interface with R using RStudio, but everything we talk about here (objects, functions, environment) also work when RStudio is not available, but R is.
This can be the case if you are working on a supercomputer that can only serve the R Console and not RStudio.

\hypertarget{data-frametibble}{%
\subsection{\texorpdfstring{\texttt{data\ frame/tibble}}{data frame/tibble}}\label{data-frametibble}}

So, regularly shaped data in rows and columns is called a table when it lives outside R, but once you read/import it into R it gets called a tibble.
If you've used R before, or get given a piece of code that uses \texttt{read.csv()} instead of \texttt{read\_csv()}, you'll have come across the term \texttt{data\ frame}.\footnote{\texttt{read.csv()} comes with base R, whereas \texttt{read\_csv()} comes from the \texttt{readr} package within the \texttt{tidyverse}. We recommend using \texttt{read\_csv()}.}

A \texttt{tibble} is the modern/\textbf{tidyverse} version of a data frame in R.
In most cases, \texttt{data\ frames} and \texttt{tibbles} work interchangeably, but \texttt{tibbles} often work better.
Another great alternative to base R \texttt{data\ frames} are \texttt{data\ tables}.
In this book, and for most of our day-to-day work these days, we will use \texttt{tibbles}.

\hypertarget{naming-objects}{%
\subsection{Naming objects}\label{naming-objects}}

When you read data into R, you want it to show up in the Environment tab.
Everything in your Environment needs to have a name.
You will likely have many objects such as tibbles going on at the same time.
Note that tibble is what the thing is, rather than its name.
This is the `class' of an object.

To keep our code examples easy to follow, we call our example tibble \texttt{mydata}.
In a real analysis, you should give your tibbles meaningful names, e.g., \texttt{patient\_data}, \texttt{lab\_results}, \texttt{annual\_totals}, etc.
Object names can't have spaces in it, which is why we use the underscore (\texttt{\_}) to separate words.
Object names can include numbers, but they can't start with a number: so \texttt{labdata2019} works, \texttt{2019labdata} does not.

So, the tibble named \texttt{mydata} is an example of an object that can be in the Environment of your R Session:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     1 Male       4    NA     2
## 2     2 Female     1     4     1
## 3     3 Female     2     5    NA
## 4     4 Male       3    NA    NA
\end{verbatim}

\hypertarget{function-and-its-arguments}{%
\subsection{Function and its arguments}\label{function-and-its-arguments}}

A function is a procedure which takes some information (input), does something to it, and passes back the modified information (output).

A simple function that can be applied to numeric data is \texttt{mean()}.

R functions always have round brackets after their name.
This is for two reasons.
First, it easily differentiates them as functions - you will get used to reading them like this.\\
Second, and more importantly, we can put \emph{arguments} in these brackets.

Arguments can also be thought of as input.
In data analysis, the most common input for a function is data.
For instance, we need to give \texttt{mean()} some data to average over.
It does not make sense (nor will it work) to feed \texttt{mean()} the whole tibble with multiple columns, including patient IDs and a categorical variable (\texttt{sex}).

To quickly extract a single column, we use the \texttt{\$} symbol like this:
\index{symbols@\textbf{symbols}!select column \texttt{\$}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}\OperatorTok{$}\NormalTok{var1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4 1 2 3
\end{verbatim}

You can ignore the \texttt{\#\#\ {[}1{]}} at the beginning of the extracted values - this is something that becomes more useful when printing multiple lines of data as the number in the square brackets keeps count on how many values we are seeing.

We can then use \texttt{mydata\$var1} as the first argument of \texttt{mean()} by putting it inside its brackets:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{var1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.5
\end{verbatim}

which tells us that the mean of \texttt{var1} (4, 1, 2, 3) is 2.5.
In this example, \texttt{mydata\$var1} is the first and only argument to \texttt{mean()}.

But what happens if we try to calculate the average value of \texttt{var2} (NA, 4, 5, NA) (remember, \texttt{NA} stands for Not Applicable/Available and is used to denote missing data):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{var2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

So why does \texttt{mean(mydata\$var2)} return \texttt{NA} (``not available'') rather than the mean of the values included in this column?
That is because the column includes missing values (\texttt{NAs}), and R does not want to average over \texttt{NAs} implicitly.
It is being cautious - what if you didn't know there were missing values for some patients?
If you wanted to compare the means of \texttt{var1} and \texttt{var2} without any further filtering, you would be comparing samples of different sizes.

We might expect to see an \texttt{NA} if we tried to, for example, calculate the average of \texttt{sex}.
And this is indeed the case:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in mean.default(mydata$sex): argument is not numeric or logical:
## returning NA
\end{verbatim}

\begin{verbatim}
## [1] NA
\end{verbatim}

Furthermore, R also gives us a pretty clear Warning suggesting it can't compute the mean of an argument that is not numeric or logical.
The sentence actually reads pretty fun, as if R was saying it was not logical to calculate the mean of something that is not numeric.

But, R is actually saying that it is happy to calculate the mean of two types of variables: numerics or logicals, but what you have passed is neither.

If you decide to ignore the NAs and want to calculate the mean anyway, you can do so by adding this argument to \texttt{mean()}:

\index{missing values remove \texttt{na.rm}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{mean}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{var2, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4.5
\end{verbatim}

Adding \texttt{na.rm\ =\ TRUE} tells R that you are happy for it to calculate the mean of any existing values (but to remove - \texttt{rm} - the \texttt{NA} values).
This `removal' excludes the NAs from the calculation, it does not affect the actual tibble (\texttt{mydata}) holding the dataset.

R is case sensitive, so \texttt{na.rm}, not \texttt{NA.rm} etc.
There is, however, no need to memorize how the arguments of functions are exactly spelled - this is what the Help tab is for (press \texttt{F1} when the cursor is on the name of the function).
Help pages are built into R, so an internet connection is not required for this.

\begin{quote}
Make sure to separate multiple arguments with commas or R will give you an error of \texttt{Error:\ unexpected\ symbol}.
\end{quote}

Finally, some functions do not need any arguments to work.
A good example is the \texttt{Sys.time()} which returns the current time and date.
This is useful when using R to generate and update reports automatically.
Including this means you can always be clear on when the results were last updated.

\index{functions@\textbf{functions}!Sys.time}
\index{system time}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{Sys.time}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "2020-08-19 12:42:06 BST"
\end{verbatim}

\hypertarget{working-with-objects}{%
\subsection{Working with objects}\label{working-with-objects}}

To save an object in our Environment we use the assignment arrow:
\index{symbols@\textbf{symbols}!assignment \texttt{<-}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a <-}\StringTok{ }\DecValTok{103}
\end{Highlighting}
\end{Shaded}

This reads: the object \texttt{a} is assigned value 103.
\texttt{\textless{}-} is called ``the arrow assignment operator'', or ``assignment arrow'' for short.

\begin{quote}
Keyboard shortcuts to insert \texttt{\textless{}-}:\\
Windows: Alt-\\
macOS: Option-
\end{quote}

You know that the assignment worked when it shows up in the Environment tab.
If we now run \texttt{a} just on its own, it gets printed back to us:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{a}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 103
\end{verbatim}

Similarly, if we run a function without assignment to an object, it gets printed but not saved in your Environment:
\index{functions@\textbf{functions}!seq}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{seq}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
\end{verbatim}

\texttt{seq()} is a function that creates a sequence of numbers (+1 by default) between the two arguments you pass to it in its brackets.
We can assign the result of \texttt{seq(15,\ 30)} into an object, let's call it \texttt{example\_sequence}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_sequence <-}\StringTok{ }\KeywordTok{seq}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{30}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Doing this creates \texttt{example\_sequence} in our Environment, but it does not print it.
To get it printed, run it on a separate line like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_sequence}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30
\end{verbatim}

\begin{quote}
If you save the results of an R function in an object, it does not get printed.
If you run a function without the assignment (\texttt{\textless{}-}), its results get printed, but not saved as an object.
\end{quote}

Finally, R doesn't mind overwriting an existing object, for example:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{example_sequence <-}\StringTok{ }\NormalTok{example_sequence}\OperatorTok{/}\DecValTok{2}

\NormalTok{example_sequence}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  7.5  8.0  8.5  9.0  9.5 10.0 10.5 11.0 11.5 12.0 12.5 13.0 13.5 14.0 14.5
## [16] 15.0
\end{verbatim}

Notice how we then include the variable on a new line to get it printed as well as overwritten.

\hypertarget{and}{%
\subsection{\texorpdfstring{\texttt{\textless{}-} and \texttt{=}}{\textless- and =}}\label{and}}

Note that many people use \texttt{=} instead of \texttt{\textless{}-}.
Both \texttt{\textless{}-} and \texttt{=} can save what is on the right into an object with named on the left.
Although \texttt{\textless{}-} and \texttt{=} are interchangeable when saving an object into your Environment, they are not interchangeable when used as function argument.
For example, remember how we used the \texttt{na.rm} argument in the \texttt{mean()} function, and the result got printed immediately?
If we want to save the result into an object, we'll do this, where \texttt{mean\_result} could be any name you choose:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean_result <-}\StringTok{ }\KeywordTok{mean}\NormalTok{(mydata}\OperatorTok{$}\NormalTok{var2, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note how the example above uses both operators: the assignment arrow for saving the result to the Environment, the \texttt{=} equals operator for setting an argument in the \texttt{mean()} function (\texttt{na.rm\ =\ TRUE}).

\hypertarget{recap-object-function-input-argument}{%
\subsection{Recap: object, function, input, argument}\label{recap-object-function-input-argument}}

\begin{itemize}
\item
  To summarise, objects and functions work hand in hand.
  Objects are both an input as well as the output of a function (what the function returns).
\item
  When passing data to a function, it is usually the first argument, with further arguments used to specify behaviour.
\item
  When we say ``the function returns'', we are referring to its output (or an Error if it's one of those days).
\item
  The returned object can be different to its input object.
  In our \texttt{mean()} examples above, the input object was a column (\texttt{mydata\$var1}: 4, 1, 2, 3), whereas the output was a single value: 2.5.
\item
  If you've written a line of code that doesn't include the assignment arrow (\texttt{\textless{}-}), its results would get printed.
  If you use the assignment arrow, an object holding the results will get saved into the Environment.
\end{itemize}

\hypertarget{pipe--}{%
\section{\texorpdfstring{Pipe - \texttt{\%\textgreater{}\%}}{Pipe - \%\textgreater\%}}\label{pipe--}}

\index{symbols@\textbf{symbols}!pipe \texttt{\%>\%}}
\index{pipe@\textbf{pipe}}

The pipe - denoted \texttt{\%\textgreater{}\%} - is probably the oddest looking thing you'll see in this book.
But please bear with; it is not as scary as it looks!
Furthermore, it is super useful.
We use the pipe to send objects into functions.

In the above examples, we calculated the mean of column \texttt{var1} from \texttt{mydata} by \texttt{mean(mydata\$var1)}. With the pipe, we can rewrite this as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{mydata}\OperatorTok{$}\NormalTok{var1 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 2.5
\end{verbatim}

Which reads: ``Working with \texttt{mydata}, we select a single column called \texttt{var1} (with the \texttt{\$}) \textbf{and then} calculate the \texttt{mean()}.''
The pipe becomes especially useful once the analysis includes multiple steps applied one after another.
A good way to read and think of the pipe is ``and then''.

This piping business is not standard R functionality and before using it in a script, you need to tell R this is what you will be doing.
The pipe comes from the \texttt{magrittr} package (Figure \ref{fig:chap2-fig-pipe}), but loading the \textbf{tidyverse} will also load the pipe.
So \texttt{library(tidyverse)} initialises everything you need.

\begin{quote}
To insert a pipe \texttt{\%\textgreater{}\%}, use the keyboard shortcut \texttt{Ctrl+Shift+M}.
\end{quote}

With or without the pipe, the general rule ``if the result gets printed it doesn't get saved'' still applies.
To save the result of the function into a new object (so it shows up in the Environment), you need to add the name of the new object with the assignment arrow (\texttt{\textless{}-}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mean_result <-}\StringTok{ }\NormalTok{mydata}\OperatorTok{$}\NormalTok{var1 }\OperatorTok{%>%}\StringTok{ }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{images/chapter02/magrittr} 

}

\caption{This is not a pipe. René Magritte inspired artwork, by Stefan Milton Bache.}\label{fig:chap2-fig-pipe}
\end{figure}

\hypertarget{using-.-to-direct-the-pipe}{%
\subsection{Using . to direct the pipe}\label{using-.-to-direct-the-pipe}}

By default, the pipe sends data to the beginning of the function brackets (as most of the functions we use expect data as the first argument).
So \texttt{mydata\ \%\textgreater{}\%\ lm(dependent\textasciitilde{}explanatory)} is equivalent to \texttt{lm(mydata,\ dependent\textasciitilde{}explanatory)}.
\texttt{lm()} - linear model - will be introduced in detail in Chapter \ref{chap07-h1}.

However, the \texttt{lm()} function does not expect data as its first argument.
\texttt{lm()} wants us to specify the variables first (\texttt{dependent\textasciitilde{}explanatory}), and then wants the tibble these columns are in.
So we have to use the \texttt{.} to tell the pipe to send the data to the second argument of \texttt{lm()}, not the first, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(var1}\OperatorTok{~}\NormalTok{var2, }\DataTypeTok{data =}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\hypertarget{operators-for-filtering-data}{%
\section{Operators for filtering data}\label{operators-for-filtering-data}}

\index{operators}
\index{functions@\textbf{functions}!filter}
\index{symbols@\textbf{symbols}!less than \texttt{<}}
\index{symbols@\textbf{symbols}!greater than \texttt{>}}
\index{symbols@\textbf{symbols}!less or equal \texttt{<=}}
\index{symbols@\textbf{symbols}!greater or equal \texttt{>=}}
\index{symbols@\textbf{symbols}!equal \texttt{=}}
\index{symbols@\textbf{symbols}!not \texttt{"!}}
\index{symbols@\textbf{symbols}!AND \texttt{\&}}
\index{symbols@\textbf{symbols}!OR \texttt{"|}}

Operators are symbols that tell R how to handle different pieces of data or objects.
We have already introduced three: \texttt{\$} (selects a column), \texttt{\textless{}-} (assigns values or results to a variable), and the pipe - \texttt{\%\textgreater{}\%} (sends data into a function).

Other common operators are the ones we use for filtering data - these are arithmetic comparison and logical operators.
This may be for creating subgroups, or for excluding outliers or incomplete cases.

The comparison operators that work with numeric data are relatively straightforward: \texttt{\textgreater{},\ \textless{},\ \textgreater{}=,\ \textless{}=}.
The first two check whether your values are greater or less than another value, the last two check for ``greater than or equal to'' and ``less than or equal to''.
These operators are most commonly spotted inside the \texttt{filter()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{<}\StringTok{ }\DecValTok{1995}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1990 Communicable diseases               15.4 
## 2  1990 Injuries                             4.25
## 3  1990 Non-communicable diseases           26.7
\end{verbatim}

Here we send the data (\texttt{gbd\_short}) to the \texttt{filter()} and ask it to retain all years that are less than 1995.
The resulting tibble only includes the year 1990.
Now, if we use the \texttt{\textless{}=} (less than or equal to) operator, both 1990 and 1995 pass the filter:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{<=}\StringTok{ }\DecValTok{1995}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1990 Communicable diseases               15.4 
## 2  1990 Injuries                             4.25
## 3  1990 Non-communicable diseases           26.7 
## 4  1995 Communicable diseases               15.1 
## 5  1995 Injuries                             4.53
## 6  1995 Non-communicable diseases           29.3
\end{verbatim}

Furthermore, the values either side of the operator could both be variables, e.g., \texttt{mydata\ \%\textgreater{}\%\ filter(var2\ \textgreater{}\ var1)}.

To filter for values that are equal to something, we use the \texttt{==} operator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1995}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1995 Communicable diseases               15.1 
## 2  1995 Injuries                             4.53
## 3  1995 Non-communicable diseases           29.3
\end{verbatim}

This reads, take the GBD dataset, send it to the filter and keep rows where year is equal to 1995.

Accidentally using the single equals \texttt{=} when double equals is necessary \texttt{==} is a common mistake and still happens to the best of us.
It happens so often that the error the \texttt{filter()} function gives when using the wrong one also reminds us what the correct one was:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\DataTypeTok{year =} \DecValTok{1995}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Error: Problem with `filter()` input `..1`.
## x Input `..1` is named.
## i This usually means that you've used `=` instead of `==`.
## i Did you mean `year == 1995`?
\end{verbatim}

\begin{quote}
The answer to 'do you need ==?" is almost always, ``Yes R, I do, thank you''.
\end{quote}

But that's just because \texttt{filter()} is a clever cookie and is used to this common mistake.
There are other useful functions we use these operators in, but they don't always know to tell us that we've just confused \texttt{=} for \texttt{==}.
So if you get an error when checking for an equality between variables, always check your \texttt{==} operators first.

R also has two operators for combining multiple comparisons: \& and \textbar, which stand for AND and OR, respectively.
For example, we can filter to only keep the earliest and latest years in the dataset:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1995} \OperatorTok{|}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{2017}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1995 Communicable diseases               15.1 
## 2  1995 Injuries                             4.53
## 3  1995 Non-communicable diseases           29.3 
## 4  2017 Communicable diseases               10.4 
## 5  2017 Injuries                             4.47
## 6  2017 Non-communicable diseases           40.9
\end{verbatim}

This reads: take the GBD dataset, send it to the filter and keep rows where year is equal to 1995 OR year is equal to 2017.

Using specific values like we've done here (1995/2017) is called ``hard-coding'', which is fine if we know for sure that we will not want to use the same script on an updated dataset.
But a cleverer way of achieving the same thing is to use the \texttt{min()} and \texttt{max()} functions:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(year) }\OperatorTok{|}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ }\KeywordTok{min}\NormalTok{(year))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1990 Communicable diseases               15.4 
## 2  1990 Injuries                             4.25
## 3  1990 Non-communicable diseases           26.7 
## 4  2017 Communicable diseases               10.4 
## 5  2017 Injuries                             4.47
## 6  2017 Non-communicable diseases           40.9
\end{verbatim}

\begin{table}

\caption{\label{tab:chap2-tab-filtering-operators}Filtering operators.}
\centering
\fontsize{8}{10}\selectfont
\begin{tabular}[t]{lc}
\toprule
Operators & Meaning\\
\midrule
== & Equal to\\
!= & Not equal to\\
< & Less than\\
> & Greater than\\
<= & Less than or equal to\\
>= & Greater then or equal to\\
\& & AND\\
\addlinespace
| & OR\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{worked-examples}{%
\subsection{Worked examples}\label{worked-examples}}

Filter the dataset to only include the year 2000.
Save this in a new variable using the assignment operator.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata_year2000 <-}\StringTok{ }\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Let's practice combining multiple selections together.

Reminder: `\textbar{}' means OR and `\&' means AND.

From \texttt{gbd\_short}, select the lines where year is either 1990 or 2017 and cause is ``Communicable diseases'':

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{new_data_selection <-}\StringTok{ }\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{((year }\OperatorTok{==}\StringTok{ }\DecValTok{1990} \OperatorTok{|}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{2013}\NormalTok{) }\OperatorTok{&}\StringTok{ }\NormalTok{cause }\OperatorTok{==}\StringTok{ "Communicable diseases"}\NormalTok{)}

\CommentTok{# Or we can get rid of the extra brackets around the years}
\CommentTok{# by moving cause into a new filter on a new line:}

\NormalTok{new_data_selection <-}\StringTok{ }\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1990} \OperatorTok{|}\StringTok{ }\NormalTok{year }\OperatorTok{==}\StringTok{ }\DecValTok{2013}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(cause }\OperatorTok{==}\StringTok{ "Communicable diseases"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\index{symbols@\textbf{symbols}!comment \texttt{\#}}
The hash symbol (\texttt{\#}) is used to add free text comments to R code.
R will not try to run these lines, they will be ignored.
Comments are an essential part of any programming code and these are ``Dear Diary'' notes to your future self.

\hypertarget{the-combine-function-c}{%
\section{\texorpdfstring{The combine function: \texttt{c()}}{The combine function: c()}}\label{the-combine-function-c}}

\index{functions@\textbf{functions}!c() combine}

The combine function as its name implies is used to combine several values.
It is especially useful when used with the \texttt{\%in\%} operator to filter for multiple values.
Remember how the gbd\_short cause column had three different causes in it:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short}\OperatorTok{$}\NormalTok{cause }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Communicable diseases"     "Injuries"                 
## [3] "Non-communicable diseases"
\end{verbatim}

Say we wanted to filter for communicable and non-communicable diseases.
\footnote{In this example, it would just be easier to used the ``not equal'' operator, filter(cause \texttt{!=} ``Injuries''), but imagine your column had more than just three different values in it.} We could use the OR operator \texttt{\textbar{}} like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# also filtering for a single year to keep the result concise}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1990}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(cause }\OperatorTok{==}\StringTok{ "Communicable diseases"} \OperatorTok{|}\StringTok{ }\NormalTok{cause }\OperatorTok{==}\StringTok{ "Non-communicable diseases"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1990 Communicable diseases                15.4
## 2  1990 Non-communicable diseases            26.7
\end{verbatim}

But that means we have to type in \texttt{cause} twice (and more if we had other values we wanted to include).
This is where the \texttt{\%in\%} operator together with the \texttt{c()} function come in handy:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_short }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1990}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(cause }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Communicable diseases"}\NormalTok{, }\StringTok{"Non-communicable diseases"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##    year cause                     deaths_millions
##   <dbl> <chr>                               <dbl>
## 1  1990 Communicable diseases                15.4
## 2  1990 Non-communicable diseases            26.7
\end{verbatim}

\hypertarget{missing-values-nas-and-filters}{%
\section{Missing values (NAs) and filters}\label{missing-values-nas-and-filters}}

\index{missing values}

Filtering for missing values (NAs) needs special attention and care.
Remember the small example tibble from Table \ref{tab:chap2-tab-examp1} - it has some NAs in columns \texttt{var2} and \texttt{var3}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     1 Male       4    NA     2
## 2     2 Female     1     4     1
## 3     3 Female     2     5    NA
## 4     4 Male       3    NA    NA
\end{verbatim}

If we now want to filter for rows where \texttt{var2} is missing, \texttt{filter(var2\ ==\ NA)} is not the way to do it, it will not work.

Since R is a programming language, it can be a bit stubborn with things like these.
When you ask R to do a comparison using \texttt{==} (or \texttt{\textless{}}, \texttt{\textgreater{}}, etc.) it expects a value on each side, but NA is not a value, it is the lack thereof.
The way to filter for missing values is using the \texttt{is.na()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(var2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##      id sex    var1  var2  var3
##   <int> <chr> <dbl> <dbl> <dbl>
## 1     1 Male      4    NA     2
## 2     4 Male      3    NA    NA
\end{verbatim}

We send \texttt{mydata} to the filter and keep rows where \texttt{var2} is \texttt{NA}.
Note the double brackets at the end: that's because the inner one belongs to \texttt{is.na()}, and the outer one to \texttt{filter()}.
Missing out a closing bracket is also a common source of errors, and still happens to the best of us.

If filtering for rows where \texttt{var2} is not missing, we do this\footnote{In this simple example, \texttt{mydata\ \%\textgreater{}\%\ filter(!\ is.na(var2))} could be replaced by a shorthand: \texttt{mydata\ \%\textgreater{}\%\ drop\_na(var2)}, but it is important to understand how the ! and \texttt{is.na()} work as there will be more complex situations where using these is necessary.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\KeywordTok{is.na}\NormalTok{(var2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     2 Female     1     4     1
## 2     3 Female     2     5    NA
\end{verbatim}

In R, the exclamation mark (!) means ``not''.

Sometimes you want to drop a specific value (e.g., an outlier) from the dataset like this.
The small example tibble \texttt{mydata} has 4 rows, with the values for \texttt{var2} as follows: NA, 4, 5, NA.
We can exclude the row where \texttt{var2} is equal to 5 by using the ``not equals'' (\texttt{!=})\footnote{\texttt{filter(var2\ !=\ 5)\ is\ equivalent\ to\ filter(!\ var2\ ==\ 5)}}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(var2 }\OperatorTok{!=}\StringTok{ }\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     2 Female     1     4     1
\end{verbatim}

However, you'll see that by doing this, R drops the rows where \texttt{var2} is NA as well, as it can't be sure these missing values were not equal to 5.

If you want to keep the missing values, you need to make use of the OR (\texttt{\textbar{}}) operator and the \texttt{is.na()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(var2 }\OperatorTok{!=}\StringTok{ }\DecValTok{5} \OperatorTok{|}\StringTok{ }\KeywordTok{is.na}\NormalTok{(var2))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     1 Male       4    NA     2
## 2     2 Female     1     4     1
## 3     4 Male       3    NA    NA
\end{verbatim}

Being caught out by missing values, either in filters or other functions is common (remember \texttt{mydata\$var2\ \%\textgreater{}\%\ mean()} returns NA unless you add \texttt{na.rm\ =\ TRUE}).
This is also why we insist that you always plot your data first - outliers will reveal themselves and NA values usually become obvious too.

Another thing we do to stay safe around filters and missing values is saving the results and making sure the number of rows still add up:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subset1 <-}\StringTok{ }\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(var2 }\OperatorTok{==}\StringTok{ }\DecValTok{5}\NormalTok{)}

\NormalTok{subset2 <-}\StringTok{ }\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\OperatorTok{!}\StringTok{ }\NormalTok{var2 }\OperatorTok{==}\StringTok{ }\DecValTok{5}\NormalTok{)}

\NormalTok{subset1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     3 Female     2     5    NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subset2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 5
##      id sex     var1  var2  var3
##   <int> <chr>  <dbl> <dbl> <dbl>
## 1     2 Female     1     4     1
\end{verbatim}

If the numbers are small, you can now quickly look at RStudio's Environment tab and figure out whether the number of observations (rows) in \texttt{subset1} and \texttt{subset2} add up to the whole dataset (\texttt{mydata}). Or use the \texttt{nrow()} function to check the number of rows in each dataset:

Rows in \texttt{mydata}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(mydata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 4
\end{verbatim}

Rows in \texttt{subset1}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(subset1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

Rows in \texttt{subset2}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(subset2)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

Asking R whether adding these two up equals the original size:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{nrow}\NormalTok{(subset1) }\OperatorTok{+}\StringTok{ }\KeywordTok{nrow}\NormalTok{(subset2) }\OperatorTok{==}\StringTok{ }\KeywordTok{nrow}\NormalTok{(mydata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] FALSE
\end{verbatim}

As expected, this returns FALSE - because we didn't add special handling for missing values.
Let's create a third subset only including rows where \texttt{var3} is NA:

Rows in \texttt{subset2}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{subset3 <-}\StringTok{ }\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(}\KeywordTok{is.na}\NormalTok{(var2))}

\KeywordTok{nrow}\NormalTok{(subset1) }\OperatorTok{+}\StringTok{ }\KeywordTok{nrow}\NormalTok{(subset2) }\OperatorTok{+}\StringTok{ }\KeywordTok{nrow}\NormalTok{(subset3) }\OperatorTok{==}\StringTok{ }\KeywordTok{nrow}\NormalTok{(mydata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] TRUE
\end{verbatim}

\hypertarget{creating-new-columns---mutate}{%
\section{\texorpdfstring{Creating new columns - \texttt{mutate()}}{Creating new columns - mutate()}}\label{creating-new-columns---mutate}}

\index{column, create}
\index{functions@\textbf{functions}!mutate}

The function for adding new columns (or making changes to existing ones) to a tibble is called \texttt{mutate()}.
As a reminder, this is what \texttt{typesdata} looked like:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   id    group     measurement date               
##   <chr> <chr>           <dbl> <dttm>             
## 1 ID1   Control           1.8 2017-01-02 12:00:00
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00
\end{verbatim}

Let's say we decide to divide the column \texttt{measurement} by 2.
A quick way to see these values would be to pull them out using the \texttt{\$} operator and then divide by 2:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata}\OperatorTok{$}\NormalTok{measurement}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1.8 4.5 3.7
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata}\OperatorTok{$}\NormalTok{measurement}\OperatorTok{/}\DecValTok{2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.90 2.25 1.85
\end{verbatim}

But this becomes cumbersome once we want to combine multiple variables from the same tibble in a calculation. So the \texttt{mutate()} is the way to go here:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(measurement}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   id    group     measurement date                `measurement/2`
##   <chr> <chr>           <dbl> <dttm>                        <dbl>
## 1 ID1   Control           1.8 2017-01-02 12:00:00            0.9 
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00            2.25
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00            1.85
\end{verbatim}

Notice how the \texttt{mutate()} above returns the whole tibble with a new column called \texttt{measurement/2}.
This is quite nice of \texttt{mutate()}, but it would be best to give columns names that don't include characters other than underscores (\texttt{\_}) or dots (\texttt{.}).
So let's assign a more standard name for this new column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{measurement_half =}\NormalTok{ measurement}\OperatorTok{/}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   id    group     measurement date                measurement_half
##   <chr> <chr>           <dbl> <dttm>                         <dbl>
## 1 ID1   Control           1.8 2017-01-02 12:00:00             0.9 
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00             2.25
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00             1.85
\end{verbatim}

Better.
You can see that R likes the name we gave it a bit better as it's now removed the back-ticks from around it.
Overall, back-ticks can be used to call out non-standard column names, so if you are forced to read in data with, e.g., spaces in column names, then the back-ticks enable calling column names that would otherwise error\footnote{If this happens to you a lot, then check out \texttt{library(janitor)} and its function \texttt{clean\_names()} for automatically tidying non-standard column names.}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mydata}\OperatorTok{$}\StringTok{`}\DataTypeTok{Nasty column name}\StringTok{`}

\CommentTok{# or}

\NormalTok{mydata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\StringTok{`}\DataTypeTok{Nasty column name}\StringTok{`}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

But as usual, if it gets printed, it doesn't get saved.
We have two options - we can either overwrite the \texttt{typesdata} tibble (by changing the first line to \texttt{typesdata\ =\ typesdata\ \%\textgreater{}\%}), or we can create a new one (that appears in your Environment):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata_modified <-}\StringTok{ }\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{measurement_half =}\NormalTok{ measurement}\OperatorTok{/}\DecValTok{2}\NormalTok{)}

\NormalTok{typesdata_modified}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   id    group     measurement date                measurement_half
##   <chr> <chr>           <dbl> <dttm>                         <dbl>
## 1 ID1   Control           1.8 2017-01-02 12:00:00             0.9 
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00             2.25
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00             1.85
\end{verbatim}

The \texttt{mutate()} function can also be used to create a new column with a single constant value; which in return can be used to calculate a difference for each of the existing dates:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{reference_date   =} \KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2020-01-01 12:00"}\NormalTok{),}
         \DataTypeTok{dates_difference =}\NormalTok{ reference_date }\OperatorTok{-}\StringTok{ }\NormalTok{date) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(date, reference_date, dates_difference)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##   date                reference_date      dates_difference
##   <dttm>              <dttm>              <drtn>          
## 1 2017-01-02 12:00:00 2020-01-01 12:00:00 1094.0000 days  
## 2 2018-02-03 13:00:00 2020-01-01 12:00:00  696.9583 days  
## 3 2019-03-04 14:00:00 2020-01-01 12:00:00  302.9167 days
\end{verbatim}

(We are then using the \texttt{select()} function to only choose the three relevant columns.)

Finally, the mutate function can be used to create a new column with a summarised value in it, e.g., the mean of another column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{mean_measurement =} \KeywordTok{mean}\NormalTok{(measurement))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   id    group     measurement date                mean_measurement
##   <chr> <chr>           <dbl> <dttm>                         <dbl>
## 1 ID1   Control           1.8 2017-01-02 12:00:00             3.33
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00             3.33
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00             3.33
\end{verbatim}

Which in return can be useful for calculating a standardized measurement (i.e.~relative to the mean):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{mean_measurement     =} \KeywordTok{mean}\NormalTok{(measurement)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{measurement_relative =}\NormalTok{ measurement}\OperatorTok{/}\NormalTok{mean_measurement) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"measurement"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##   measurement mean_measurement measurement_relative
##         <dbl>            <dbl>                <dbl>
## 1         1.8             3.33                 0.54
## 2         4.5             3.33                 1.35
## 3         3.7             3.33                 1.11
\end{verbatim}

\hypertarget{worked-exampleexercise}{%
\subsection{Worked example/exercise}\label{worked-exampleexercise}}

Round the difference to 0 decimal places using the \texttt{round()} function inside a \texttt{mutate()}.
Then add a clever \texttt{matches("date")} inside the \texttt{select()} function to choose all matching columns.

\index{functions@\textbf{functions}!matches}

Solution:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{reference_date   =} \KeywordTok{ymd_hm}\NormalTok{(}\StringTok{"2020-01-01 12:00"}\NormalTok{),}
         \DataTypeTok{dates_difference =}\NormalTok{ reference_date }\OperatorTok{-}\StringTok{ }\NormalTok{date) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{dates_difference =} \KeywordTok{round}\NormalTok{(dates_difference)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"date"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##   date                reference_date      dates_difference
##   <dttm>              <dttm>              <drtn>          
## 1 2017-01-02 12:00:00 2020-01-01 12:00:00 1094 days       
## 2 2018-02-03 13:00:00 2020-01-01 12:00:00  697 days       
## 3 2019-03-04 14:00:00 2020-01-01 12:00:00  303 days
\end{verbatim}

You can shorten this by adding the \texttt{round()} function directly around the subtraction, so the third line becomes \texttt{dates\_difference\ =\ round(reference\_date\ -\ date))\ \%\textgreater{}\%}.
But sometimes writing calculations out longer than the absolute minimum can make them easier to understand when you return to an old script months later.

Furthermore, we didn't have to save the \texttt{reference\_date} as a new column, the calculation could have used the value directly: \texttt{mutate(dates\_difference\ =\ ymd\_hm("2020-01-01\ 12:00")\ -\ date)\ \%\textgreater{}\%}.
But again, defining it makes it clearer for your future self to see what was done. And it makes \texttt{reference\_date} available for reuse in more complicated calculations within the tibble.

\hypertarget{conditional-calculations---if_else}{%
\section{\texorpdfstring{Conditional calculations - \texttt{if\_else()}}{Conditional calculations - if\_else()}}\label{conditional-calculations---if_else}}

And finally, we combine the filtering operators (\texttt{==}, \texttt{\textgreater{}}, \texttt{\textless{}}, etc) with the \texttt{if\_else()} function to create new columns based on a condition.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{above_threshold =} \KeywordTok{if_else}\NormalTok{(measurement }\OperatorTok{>}\StringTok{ }\DecValTok{3}\NormalTok{,}
                                   \StringTok{"Above three"}\NormalTok{,}
                                   \StringTok{"Below three"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   id    group     measurement date                above_threshold
##   <chr> <chr>           <dbl> <dttm>              <chr>          
## 1 ID1   Control           1.8 2017-01-02 12:00:00 Below three    
## 2 ID2   Treatment         4.5 2018-02-03 13:00:00 Above three    
## 3 ID3   Treatment         3.7 2019-03-04 14:00:00 Above three
\end{verbatim}

We are sending \texttt{typesdata} into a \texttt{mutate()} function, we are creating a new column called \texttt{above\_threshold} based on whether \texttt{measurement} is greater or less than 3.
The first argument to \texttt{if\_else()} is a condition (in this case that measurement is greater than 3), the second argument is the value if the condition is TRUE, and the third argument is the value if the condition is FALSE.

It reads, ``if this condition is met, return this, else return that''.

Look at each line in the tibble above and convince yourself that the \texttt{threshold} variable worked as expected.
Then look at the two closing brackets - \texttt{))} - at the end and convince yourself that they are both needed.

\begin{quote}
\texttt{if\_else()} and missing values tip: for rows with missing values (NAs), the condition returns neither TRUE nor FALSE, it returns NA.
And that might be fine, but if you want to assign a specific group/label for missing values in the new variable, you can add a fourth argument to \texttt{if\_else()}, e.g., \texttt{if\_else(measurement\ \textgreater{}\ 3,\ "Above\ three",\ "Below\ three",\ "Value\ missing")}.
\end{quote}

\hypertarget{create-labels---paste}{%
\section{\texorpdfstring{Create labels - \texttt{paste()}}{Create labels - paste()}}\label{create-labels---paste}}

\index{functions@\textbf{functions}!paste}
\index{paste}
\index{labels}

The \texttt{paste()} function is used to add characters together.
It also works with numbers and dates which will automatically be converted to characters before being pasted together into a single label.
See this example where we use all variables from \texttt{typesdata} to create a new column called \texttt{plot\_label} (we \texttt{select()} for printing space):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{typesdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{plot_label =} \KeywordTok{paste}\NormalTok{(id,}
                            \StringTok{"was last measured at"}\NormalTok{, date,}
                            \StringTok{", and the value was"}\NormalTok{,    measurement)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(plot_label)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 1
##   plot_label                                                          
##   <chr>                                                               
## 1 ID1 was last measured at 2017-01-02 12:00:00 , and the value was 1.8
## 2 ID2 was last measured at 2018-02-03 13:00:00 , and the value was 4.5
## 3 ID3 was last measured at 2019-03-04 14:00:00 , and the value was 3.7
\end{verbatim}

The paste is also useful when pieces of information are stored in different columns.
For example, consider this made-up tibble:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pastedata <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{year  =} \KeywordTok{c}\NormalTok{(}\DecValTok{2007}\NormalTok{, }\DecValTok{2008}\NormalTok{, }\DecValTok{2009}\NormalTok{),}
                   \DataTypeTok{month =} \KeywordTok{c}\NormalTok{(}\StringTok{"Jan"}\NormalTok{, }\StringTok{"Feb"}\NormalTok{, }\StringTok{"March"}\NormalTok{),}
                   \DataTypeTok{day   =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{))}

\NormalTok{pastedata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 3
##    year month   day
##   <dbl> <chr> <dbl>
## 1  2007 Jan       1
## 2  2008 Feb       2
## 3  2009 March     3
\end{verbatim}

We can use \texttt{paste()} to combine these into a single column:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pastedata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{date =} \KeywordTok{paste}\NormalTok{(day, month, year, }\DataTypeTok{sep =} \StringTok{"-"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##    year month   day date        
##   <dbl> <chr> <dbl> <chr>       
## 1  2007 Jan       1 1-Jan-2007  
## 2  2008 Feb       2 2-Feb-2008  
## 3  2009 March     3 3-March-2009
\end{verbatim}

By default, \texttt{paste()} adds a space between each value, but we can use the \texttt{sep\ =} argument to specify a different separator.
Sometimes it is useful to use \texttt{paste0()} which does not add anything between the values (no space, no dash, etc.).

We can now tell R that the date column should be parsed as such:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}

\NormalTok{pastedata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{date =} \KeywordTok{paste}\NormalTok{(day, month, year, }\DataTypeTok{sep =} \StringTok{"-"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{date =} \KeywordTok{dmy}\NormalTok{(date))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##    year month   day date      
##   <dbl> <chr> <dbl> <date>    
## 1  2007 Jan       1 2007-01-01
## 2  2008 Feb       2 2008-02-02
## 3  2009 March     3 2009-03-03
\end{verbatim}

\hypertarget{joining-multiple-datasets}{%
\section{Joining multiple datasets}\label{joining-multiple-datasets}}

\index{functions@\textbf{functions}!join}
\index{functions@\textbf{functions}!full\_join}
\index{functions@\textbf{functions}!inner\_join}
\index{functions@\textbf{functions}!left\_join}
\index{functions@\textbf{functions}!right\_join}
\index{join datasets@\textbf{join datasets}}

It is common for different pieces of information to be kept in different files or tables and you often want to combine them together.
For example, consider you have some demographic information (\texttt{id}, \texttt{sex}, \texttt{age}) in one file:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{patientdata <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/patient_data.csv"}\NormalTok{)}
\NormalTok{patientdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##      id sex      age
##   <dbl> <chr>  <dbl>
## 1     1 Female    24
## 2     2 Male      59
## 3     3 Female    32
## 4     4 Female    84
## 5     5 Male      48
## 6     6 Female    65
\end{verbatim}

And another one with some lab results (\texttt{id}, \texttt{measurement}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{labsdata <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/labs_data.csv"}\NormalTok{)}
\NormalTok{labsdata}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 2
##      id measurement
##   <dbl>       <dbl>
## 1     5        3.47
## 2     6        7.31
## 3     8        9.91
## 4     7        6.11
\end{verbatim}

Notice how these datasets are not only different sizes (6 rows in \texttt{patientdata}, 4 rows in \texttt{labsdata}), but include information on different patients: \texttt{patiendata} has ids 1, 2, 3, 4, 5, 6, \texttt{labsdata} has ids 5, 6, 8, 7.

A comprehensive way to join these is to use \texttt{full\_join()} retaining all information from both tibbles (and matching up rows by shared columns, in this case \texttt{id}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{full_join}\NormalTok{(patientdata, labsdata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "id"
\end{verbatim}

\begin{verbatim}
## # A tibble: 8 x 4
##      id sex      age measurement
##   <dbl> <chr>  <dbl>       <dbl>
## 1     1 Female    24       NA   
## 2     2 Male      59       NA   
## 3     3 Female    32       NA   
## 4     4 Female    84       NA   
## 5     5 Male      48        3.47
## 6     6 Female    65        7.31
## 7     8 <NA>      NA        9.91
## 8     7 <NA>      NA        6.11
\end{verbatim}

However, if we are only interested in matching information, we use the inner join:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{inner_join}\NormalTok{(patientdata, labsdata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "id"
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 4
##      id sex      age measurement
##   <dbl> <chr>  <dbl>       <dbl>
## 1     5 Male      48        3.47
## 2     6 Female    65        7.31
\end{verbatim}

And finally, if we want to retain all information from one tibble, we use either the \texttt{left\_join()} or the \texttt{right\_join()}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{left_join}\NormalTok{(patientdata, labsdata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "id"
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 4
##      id sex      age measurement
##   <dbl> <chr>  <dbl>       <dbl>
## 1     1 Female    24       NA   
## 2     2 Male      59       NA   
## 3     3 Female    32       NA   
## 4     4 Female    84       NA   
## 5     5 Male      48        3.47
## 6     6 Female    65        7.31
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{right_join}\NormalTok{(patientdata, labsdata)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "id"
\end{verbatim}

\begin{verbatim}
## # A tibble: 4 x 4
##      id sex      age measurement
##   <dbl> <chr>  <dbl>       <dbl>
## 1     5 Male      48        3.47
## 2     6 Female    65        7.31
## 3     8 <NA>      NA        9.91
## 4     7 <NA>      NA        6.11
\end{verbatim}

\hypertarget{further-notes-about-joins}{%
\subsection{Further notes about joins}\label{further-notes-about-joins}}

\begin{itemize}
\item
  The joins functions (\texttt{full\_join()}, \texttt{inner\_join()}, \texttt{left\_join()}, \texttt{right\_join()}) will automatically look for matching column names. You can use the \texttt{by\ =} argument to specify by hand. This is especially useful if the columns are named differently in the datasets, e.g., \texttt{left\_join(data1,\ data2,\ by\ =\ c("id"\ =\ "patient\_id"))}.
\item
  The rows do not have to be ordered, the joins match on values within the rows, not the order of the rows within the tibble.
\item
  Joins are used to combine different variables (columns) into a single tibble. \textbf{If you are getting more data of the same variables, use \texttt{bind\_rows()} instead}:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{patientdata_new <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/patient_data_updated.csv"}\NormalTok{)}
\NormalTok{patientdata_new}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 3
##      id sex      age
##   <dbl> <chr>  <dbl>
## 1     7 Female    38
## 2     8 Male      29
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{bind_rows}\NormalTok{(patientdata, patientdata_new)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 8 x 3
##      id sex      age
##   <dbl> <chr>  <dbl>
## 1     1 Female    24
## 2     2 Male      59
## 3     3 Female    32
## 4     4 Female    84
## 5     5 Male      48
## 6     6 Female    65
## 7     7 Female    38
## 8     8 Male      29
\end{verbatim}

Finally, it is important to understand how joins behave if there are multiple matches within the tibbles. For example, if patient id 4 had a second measurement as well:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{labsdata_updated <-}\StringTok{ }\NormalTok{labsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{add_row}\NormalTok{(}\DataTypeTok{id =} \DecValTok{5}\NormalTok{, }\DataTypeTok{measurement =} \FloatTok{2.49}\NormalTok{)}
\NormalTok{labsdata_updated}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##      id measurement
##   <dbl>       <dbl>
## 1     5        3.47
## 2     6        7.31
## 3     8        9.91
## 4     7        6.11
## 5     5        2.49
\end{verbatim}

When we now do a \texttt{left\_join()} with our main \texttt{tibble} - \texttt{patientdata}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{left_join}\NormalTok{(patientdata, labsdata_updated)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "id"
\end{verbatim}

\begin{verbatim}
## # A tibble: 7 x 4
##      id sex      age measurement
##   <dbl> <chr>  <dbl>       <dbl>
## 1     1 Female    24       NA   
## 2     2 Male      59       NA   
## 3     3 Female    32       NA   
## 4     4 Female    84       NA   
## 5     5 Male      48        3.47
## 6     5 Male      48        2.49
## 7     6 Female    65        7.31
\end{verbatim}

We get 7 rows, instead of 6 - as patient id 5 now appears twice with the two different measurements. So it is important to either know your datasets well or keep an eye on the number of rows to make sure any increases/decreases in the tibble sizes are as you expect them to be.

\hypertarget{summarising-data}{%
\chapter{Summarising data}\label{summarising-data}}

\index{summarising data@\textbf{summarising data}}

\begin{quote}
``The Answer to the Great Question \ldots{} Of Life, the Universe and Everything \ldots{} Is \ldots{} Forty-two,'' said Deep Thought, with infinite majesty and calm.\\
Douglas Adams, The Hitchhiker's Guide to the Galaxy
\end{quote}

In this chapter you will find out how to:

\begin{itemize}
\tightlist
\item
  summarise data using: \texttt{group\_by()}, \texttt{summarise()}, and \texttt{mutate()};
\item
  reshape data between the wide and long formats: \texttt{pivot\_wider()} and \texttt{pivot\_longer()};
\item
  \texttt{select()} columns and \texttt{arrange()} (sort) rows.
\end{itemize}

The exercises at the end of this chapter combine all of the above to give context and show you more worked examples.

\hypertarget{get-the-data}{%
\section{Get the data}\label{get-the-data}}

Dataset: Global Burden of Disease (year, cause, sex, income, deaths)

The Global Burden of Disease dataset used in this chapter is more detailed than the one we used previously.
For each year, the total number of deaths from the three broad disease categories are also separated into sex and World Bank income categories.
This means that we have 24 rows for each year, and that the total number of deaths per year is the sum of these 24 rows:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\NormalTok{gbd_full <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year-sex-income.csv"}\NormalTok{)}

\CommentTok{# Creating a single-year tibble for printing and simple examples:}
\NormalTok{gbd2017 <-}\StringTok{ }\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2017}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:chap3-tab-gbd2017}Deaths per year (2017) from three broad disease categories, sex, and World Bank country-level income groups.}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}[t]{lcrlc}
\toprule
cause & year & sex & income & deaths\_millions\\
\midrule
Communicable diseases & 2017 & Female & High & 0.26\\
Communicable diseases & 2017 & Female & Upper-Middle & 0.55\\
Communicable diseases & 2017 & Female & Lower-Middle & 2.92\\
Communicable diseases & 2017 & Female & Low & 1.18\\
\addlinespace
Communicable diseases & 2017 & Male & High & 0.29\\
Communicable diseases & 2017 & Male & Upper-Middle & 0.73\\
Communicable diseases & 2017 & Male & Lower-Middle & 3.10\\
Communicable diseases & 2017 & Male & Low & 1.35\\
\addlinespace
Injuries & 2017 & Female & High & 0.21\\
Injuries & 2017 & Female & Upper-Middle & 0.43\\
Injuries & 2017 & Female & Lower-Middle & 0.66\\
Injuries & 2017 & Female & Low & 0.12\\
\addlinespace
Injuries & 2017 & Male & High & 0.40\\
Injuries & 2017 & Male & Upper-Middle & 1.16\\
Injuries & 2017 & Male & Lower-Middle & 1.23\\
Injuries & 2017 & Male & Low & 0.26\\
\addlinespace
Non-communicable diseases & 2017 & Female & High & 4.68\\
Non-communicable diseases & 2017 & Female & Upper-Middle & 7.28\\
Non-communicable diseases & 2017 & Female & Lower-Middle & 6.27\\
Non-communicable diseases & 2017 & Female & Low & 0.92\\
\addlinespace
Non-communicable diseases & 2017 & Male & High & 4.65\\
Non-communicable diseases & 2017 & Male & Upper-Middle & 8.79\\
Non-communicable diseases & 2017 & Male & Lower-Middle & 7.30\\
Non-communicable diseases & 2017 & Male & Low & 1.00\\
\bottomrule
\end{tabular}
\end{table}

\clearpage

\hypertarget{plot-the-data}{%
\section{Plot the data}\label{plot-the-data}}

The best way to investigate a dataset is of course to plot it.
We have added a couple of notes as comments (the lines starting with a \texttt{\#}) for those who can't wait to get to the next chapter where the code for plotting will be introduced and explained in detail.
Overall, you shouldn't waste time trying to understand this code, but do look at the different groups within this new dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# without the mutate(... = fct_relevel()) }
\StringTok{  }\CommentTok{# the panels get ordered alphabetically}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{income =} \KeywordTok{fct_relevel}\NormalTok{(income,}
                              \StringTok{"Low"}\NormalTok{,}
                              \StringTok{"Lower-Middle"}\NormalTok{,}
                              \StringTok{"Upper-Middle"}\NormalTok{,}
                              \StringTok{"High"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# defining the variables using ggplot(aes(...)):}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sex, }\DataTypeTok{y =}\NormalTok{ deaths_millions, }\DataTypeTok{fill =}\NormalTok{ cause)) }\OperatorTok{+}
\StringTok{  }\CommentTok{# type of geom to be used: column (that's a type of barplot):}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{position =} \StringTok{"dodge"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# facets for the income groups:}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{income, }\DataTypeTok{ncol =} \DecValTok{4}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\CommentTok{# move the legend to the top of the plot (default is "right"):}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"top"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{03_summarising_files/figure-latex/chap03-fig-gbd-1.pdf}
\caption{\label{fig:chap03-fig-gbd}Global Burden of Disease data with subgroups: cause, sex, World Bank income group.}
\end{figure}

\hypertarget{aggregating-group_by-summarise}{%
\section{\texorpdfstring{Aggregating: \texttt{group\_by()}, \texttt{summarise()}}{Aggregating: group\_by(), summarise()}}\label{aggregating-group_by-summarise}}

\index{summarising data@\textbf{summarising data}!aggregation}
\index{functions@\textbf{functions}!group\_by}
\index{functions@\textbf{functions}!summarise}

Health data analysis is frequently concerned with making comparisons between groups.
Groups of genes, or diseases, or patients, or populations, etc.
An easy approach to the comparison of data by a categorical grouping is therefore essential.

We will introduce flexible functions from \textbf{tidyverse} that you can apply in any setting.
The examples intentionally get quite involved to demonstrate the different approaches that can be used.

To quickly calculate the total number of deaths in 2017, we can select the column and send it into the \texttt{sum()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017}\OperatorTok{$}\NormalTok{deaths_millions }\OperatorTok{%>%}\StringTok{ }\KeywordTok{sum}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 55.74
\end{verbatim}

But a much cleverer way of summarising data is using the \texttt{summarise()} function:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\KeywordTok{sum}\NormalTok{(deaths_millions))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   `sum(deaths_millions)`
##                    <dbl>
## 1                  55.74
\end{verbatim}

This is indeed equal to the number of deaths per year we saw in the previous chapter using the shorter version of this data (deaths from the three causes were 10.38, 4.47, 40.89 which adds to 55.74).

\texttt{sum()} is a function that adds numbers together, whereas \texttt{summarise()} is an efficient way of creating summarised tibbles.
The main strength of \texttt{summarise()} is how it works with the \texttt{group\_by()} function.
\texttt{group\_by()} and \texttt{summarise()} are like cheese and wine, a perfect complement for each other, seldom seen apart.

We use \texttt{group\_by()} to tell \texttt{summarise()} which subgroups to apply the calculations on.
In the above example, without \texttt{group\_by()}, summarise just works on the whole dataset, yielding the same result as just sending a single column into the \texttt{sum()} function.

We can subset on the cause variable using \texttt{group\_by()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\KeywordTok{sum}\NormalTok{(deaths_millions))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 3 x 2
##   cause                     `sum(deaths_millions)`
##   <chr>                                      <dbl>
## 1 Communicable diseases                      10.38
## 2 Injuries                                    4.47
## 3 Non-communicable diseases                  40.89
\end{verbatim}

Furthermore, \texttt{group\_by()} is happy to accept multiple grouping variables.
So by just copying and editing the above code, we can quickly get summarised totals across multiple grouping variables (by just adding \texttt{sex} inside the \texttt{group\_by()} after \texttt{cause}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\KeywordTok{sum}\NormalTok{(deaths_millions))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'cause' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 3
## # Groups:   cause [3]
##   cause                     sex    `sum(deaths_millions)`
##   <chr>                     <chr>                   <dbl>
## 1 Communicable diseases     Female                   4.91
## 2 Communicable diseases     Male                     5.47
## 3 Injuries                  Female                   1.42
## 4 Injuries                  Male                     3.05
## 5 Non-communicable diseases Female                  19.15
## 6 Non-communicable diseases Male                    21.74
\end{verbatim}

\hypertarget{add-new-columns-mutate}{%
\section{\texorpdfstring{Add new columns: \texttt{mutate()}}{Add new columns: mutate()}}\label{add-new-columns-mutate}}

\index{summarising data@\textbf{summarising data}!create columns}
\index{functions@\textbf{functions}!mutate}

We met \texttt{mutate()} in the last chapter.
Let's first give the summarised column a better name, e.g., \texttt{deaths\_per\_group}.
We can remove groupings by using \texttt{ungroup()}.
This is important to remember if you want to manipulate the dataset in its original format.
We can combine \texttt{ungroup()} with \texttt{mutate()} to add a total deaths column, which will be used below to calculate a percentage:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{deaths_per_group =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{deaths_total =} \KeywordTok{sum}\NormalTok{(deaths_per_group))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'cause' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 4
##   cause                     sex    deaths_per_group deaths_total
##   <chr>                     <chr>             <dbl>        <dbl>
## 1 Communicable diseases     Female             4.91        55.74
## 2 Communicable diseases     Male               5.47        55.74
## 3 Injuries                  Female             1.42        55.74
## 4 Injuries                  Male               3.05        55.74
## 5 Non-communicable diseases Female            19.15        55.74
## 6 Non-communicable diseases Male              21.74        55.74
\end{verbatim}

\hypertarget{percentages-formatting-percent}{%
\subsection{\texorpdfstring{Percentages formatting: \texttt{percent()}}{Percentages formatting: percent()}}\label{percentages-formatting-percent}}

\index{functions@\textbf{functions}!percent}

So \texttt{summarise()} condenses a tibble, whereas \texttt{mutate()} retains its current size and adds columns.
We can also further lines to \texttt{mutate()} to calculate the percentage of each group:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# percent() function for formatting percentages come from library(scales)}
\KeywordTok{library}\NormalTok{(scales)}
\NormalTok{gbd2017_summarised <-}\StringTok{ }\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{deaths_per_group =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ungroup}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{deaths_total    =} \KeywordTok{sum}\NormalTok{(deaths_per_group),}
         \DataTypeTok{deaths_relative =} \KeywordTok{percent}\NormalTok{(deaths_per_group}\OperatorTok{/}\NormalTok{deaths_total))}
\NormalTok{gbd2017_summarised}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   cause                     sex    deaths_per_group deaths_total deaths_relative
##   <chr>                     <chr>             <dbl>        <dbl> <chr>          
## 1 Communicable diseases     Female             4.91        55.74 8.8%           
## 2 Communicable diseases     Male               5.47        55.74 9.8%           
## 3 Injuries                  Female             1.42        55.74 2.5%           
## 4 Injuries                  Male               3.05        55.74 5.5%           
## 5 Non-communicable diseases Female            19.15        55.74 34.4%          
## 6 Non-communicable diseases Male              21.74        55.74 39.0%
\end{verbatim}

The \texttt{percent()} function comes from \texttt{library(scales)} and is a handy way of formatting percentages
You must keep in mind that it changes the column from a number (denoted \texttt{\textless{}dbl\textgreater{}}) to a character (\texttt{\textless{}chr\textgreater{}}).
The \texttt{percent()} function is equivalent to:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# using values from the first row as an example:}
\KeywordTok{round}\NormalTok{(}\DecValTok{100}\OperatorTok{*}\FloatTok{4.91}\OperatorTok{/}\FloatTok{55.74}\NormalTok{, }\DecValTok{1}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}\StringTok{"%"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "8.8%"
\end{verbatim}

This is convenient for final presentation of number, but if you intend to do further calculations/plot/sort the percentages just calculate them as fractions with:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017_summarised }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{deaths_relative =}\NormalTok{ deaths_per_group}\OperatorTok{/}\NormalTok{deaths_total)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   cause                     sex    deaths_per_group deaths_total deaths_relative
##   <chr>                     <chr>             <dbl>        <dbl>           <dbl>
## 1 Communicable diseases     Female             4.91        55.74         0.08809
## 2 Communicable diseases     Male               5.47        55.74         0.09813
## 3 Injuries                  Female             1.42        55.74         0.02548
## 4 Injuries                  Male               3.05        55.74         0.05472
## 5 Non-communicable diseases Female            19.15        55.74         0.3436 
## 6 Non-communicable diseases Male              21.74        55.74         0.3900
\end{verbatim}

and convert to nicely formatted percentages later with \texttt{mutate(deaths\_percentage\ =\ percent(deaths\_relative))}.

\hypertarget{summarise-vs-mutate}{%
\section{\texorpdfstring{\texttt{summarise()} vs \texttt{mutate()}}{summarise() vs mutate()}}\label{summarise-vs-mutate}}

So far we've shown you examples of using \texttt{summarise()} on grouped data (following \texttt{group\_by()}) and \texttt{mutate()} on the whole dataset (without using \texttt{group\_by()}).

But here's the thing: \texttt{mutate()} is also happy to work on grouped data.

Let's save the aggregated example from above in a new tibble.
We will then sort the rows using \texttt{arrange()} based on \texttt{sex}, just for easier viewing (it was previously sorted by \texttt{cause}).

The \texttt{arrange()} function sorts the rows within a tibble:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_summarised <-}\StringTok{ }\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{deaths_per_group =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'cause' (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_summarised}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
## # Groups:   cause [3]
##   cause                     sex    deaths_per_group
##   <chr>                     <chr>             <dbl>
## 1 Communicable diseases     Female             4.91
## 2 Injuries                  Female             1.42
## 3 Non-communicable diseases Female            19.15
## 4 Communicable diseases     Male               5.47
## 5 Injuries                  Male               3.05
## 6 Non-communicable diseases Male              21.74
\end{verbatim}

You should also notice that \texttt{summarise()} drops all variables that are not listed in \texttt{group\_by()} or created inside it.
So \texttt{year}, \texttt{income}, and \texttt{deaths\_millions} exist in \texttt{gbd2017}, but they do not exist in \texttt{gbd\_summarised}.

We now want to calculate the percentage of deaths from each cause for each gender.
We could use \texttt{summarise()} to calculate the totals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_summarised_sex <-}\StringTok{ }\NormalTok{gbd_summarised }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{deaths_per_sex =} \KeywordTok{sum}\NormalTok{(deaths_per_group))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_summarised_sex}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   sex    deaths_per_sex
##   <chr>           <dbl>
## 1 Female          25.48
## 2 Male            30.26
\end{verbatim}

But that drops the \texttt{cause} and \texttt{deaths\_per\_group} columns.
One way would be to now use a join on \texttt{gbd\_summarised} and \texttt{gbd\_summarised\_sex}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{full_join}\NormalTok{(gbd_summarised, gbd_summarised_sex)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Joining, by = "sex"
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 4
## # Groups:   cause [3]
##   cause                     sex    deaths_per_group deaths_per_sex
##   <chr>                     <chr>             <dbl>          <dbl>
## 1 Communicable diseases     Female             4.91          25.48
## 2 Injuries                  Female             1.42          25.48
## 3 Non-communicable diseases Female            19.15          25.48
## 4 Communicable diseases     Male               5.47          30.26
## 5 Injuries                  Male               3.05          30.26
## 6 Non-communicable diseases Male              21.74          30.26
\end{verbatim}

Joining different summaries together can be useful, especially if the individual pipelines are quite long (e.g., over 5 lines of \texttt{\%\textgreater{}\%}).
However, it does increase the chance of mistakes creeping in and is best avoided if possible.

An alternative is to use \texttt{mutate()} with \texttt{group\_by()} to achieve the same result as the \texttt{full\_join()} above:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_summarised }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{deaths_per_sex =} \KeywordTok{sum}\NormalTok{(deaths_per_group))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
## # Groups:   sex [2]
##   cause                     sex    deaths_per_group deaths_per_sex
##   <chr>                     <chr>             <dbl>          <dbl>
## 1 Communicable diseases     Female             4.91          25.48
## 2 Injuries                  Female             1.42          25.48
## 3 Non-communicable diseases Female            19.15          25.48
## 4 Communicable diseases     Male               5.47          30.26
## 5 Injuries                  Male               3.05          30.26
## 6 Non-communicable diseases Male              21.74          30.26
\end{verbatim}

So \texttt{mutate()} calculates the sums within each grouping variable (in this example just \texttt{group\_by(sex)}) and puts the results in a new column without condensing the tibble down or removing any of the existing columns.

Let's combine all of this together into a single pipeline and calculate the percentages per cause for each gender:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd2017 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(cause, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{deaths_per_group =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{deaths_per_sex  =} \KeywordTok{sum}\NormalTok{(deaths_per_group),}
         \DataTypeTok{sex_cause_perc =} \KeywordTok{percent}\NormalTok{(deaths_per_group}\OperatorTok{/}\NormalTok{deaths_per_sex)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(sex, deaths_per_group)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'cause' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 6 x 5
## # Groups:   sex [2]
##   cause                     sex   deaths_per_group deaths_per_sex sex_cause_perc
##   <chr>                     <chr>            <dbl>          <dbl> <chr>         
## 1 Injuries                  Fema~             1.42          25.48 6%            
## 2 Communicable diseases     Fema~             4.91          25.48 19%           
## 3 Non-communicable diseases Fema~            19.15          25.48 75%           
## 4 Injuries                  Male              3.05          30.26 10.1%         
## 5 Communicable diseases     Male              5.47          30.26 18.1%         
## 6 Non-communicable diseases Male             21.74          30.26 71.8%
\end{verbatim}

\hypertarget{common-arithmetic-functions---sum-mean-median-etc.}{%
\section{\texorpdfstring{Common arithmetic functions - \texttt{sum()}, \texttt{mean()}, \texttt{median()}, etc.}{Common arithmetic functions - sum(), mean(), median(), etc.}}\label{common-arithmetic-functions---sum-mean-median-etc.}}

\index{functions@\textbf{functions}!arithmetic}
\index{summarising data@\textbf{summarising data}!arithmetic functions}

Statistics is an R strength, so if there is an arithmetic function you can think of, it probably exists in R.

The most common ones are:

\begin{itemize}
\tightlist
\item
  \texttt{sum()}
\item
  \texttt{mean()}
\item
  \texttt{median()}
\item
  \texttt{min()}, \texttt{max()}
\item
  \texttt{sd()} - standard deviation
\item
  \texttt{IQR()} - interquartile range
\end{itemize}

An import thing to remember relates to missing data: if any of your values is NA (not available; missing), these functions will return an NA.
Either deal with your missing values beforehand (recommended) or add the \texttt{na.rm\ =\ TRUE} argument into any of the functions to ask R to ignore missing values.
More discussion and examples around missing data can be found in Chapters \ref{r-basics} and \ref{chap11-h1}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mynumbers <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\OtherTok{NA}\NormalTok{)}
\KeywordTok{sum}\NormalTok{(mynumbers)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] NA
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{sum}\NormalTok{(mynumbers, }\DataTypeTok{na.rm =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3
\end{verbatim}

Overall, R's unwillingness to implicitly average over observations with missing values should be considered helpful, not an unnecessary pain.
If you don't know exactly where your missing values are, you might end up comparing the averages of different groups.
So the \texttt{na.rm\ =\ TRUE} is fine to use if quickly exploring and cleaning data, or if you've already investigated missing values and are convinced the existing ones are representative.
But it is rightfully not a default so get used to typing \texttt{na.rm\ =\ TRUE} when using these functions.

\hypertarget{select-columns}{%
\section{\texorpdfstring{\texttt{select()} columns}{select() columns}}\label{select-columns}}

\index{summarising data@\textbf{summarising data}!select columns}
\index{functions@\textbf{functions}!select}

The \texttt{select()} function can be used to choose, rename, or reorder columns of a tibble.

For the following \texttt{select()} examples, let's create a new tibble called \texttt{gbd\_2rows} by taking the first 2 rows of \texttt{gbd\_full} (just for shorter printing):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows <-}\StringTok{ }\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{)}

\NormalTok{gbd_2rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   cause                  year sex    income       deaths_millions
##   <chr>                 <dbl> <chr>  <chr>                  <dbl>
## 1 Communicable diseases  1990 Female High                   0.21 
## 2 Communicable diseases  1990 Female Upper-Middle           1.150
\end{verbatim}

Let's \texttt{select()} two of these columns:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(cause, deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   cause                 deaths_millions
##   <chr>                           <dbl>
## 1 Communicable diseases           0.21 
## 2 Communicable diseases           1.150
\end{verbatim}

We can also use \texttt{select()} to rename the columns we are choosing:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(cause, }\DataTypeTok{deaths =}\NormalTok{ deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 2
##   cause                 deaths
##   <chr>                  <dbl>
## 1 Communicable diseases  0.21 
## 2 Communicable diseases  1.150
\end{verbatim}

There function \texttt{rename()} is similar to \texttt{select()}, but it keeps all variables whereas \texttt{select()} only kept the ones we mentioned:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{rename}\NormalTok{(}\DataTypeTok{deaths =}\NormalTok{ deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   cause                  year sex    income       deaths
##   <chr>                 <dbl> <chr>  <chr>         <dbl>
## 1 Communicable diseases  1990 Female High          0.21 
## 2 Communicable diseases  1990 Female Upper-Middle  1.150
\end{verbatim}

\texttt{select()} can also be used to reorder the columns in your tibble. Moving columns around is not relevant in data analysis (as any of the functions we showed you above, as well as plotting, only look at the column names, and not their positions in the tibble), but it is useful for organising your tibble for easier viewing.

So if we use select like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(year, sex, income, cause, deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##    year sex    income       cause                 deaths_millions
##   <dbl> <chr>  <chr>        <chr>                           <dbl>
## 1  1990 Female High         Communicable diseases           0.21 
## 2  1990 Female Upper-Middle Communicable diseases           1.150
\end{verbatim}

The columns are reordered.

If you want to move specific column(s) to the front of the tibble, do:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(year, sex, }\KeywordTok{everything}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##    year sex    cause                 income       deaths_millions
##   <dbl> <chr>  <chr>                 <chr>                  <dbl>
## 1  1990 Female Communicable diseases High                   0.21 
## 2  1990 Female Communicable diseases Upper-Middle           1.150
\end{verbatim}

And this is where the true power of \texttt{select()} starts to come out.
In addition to listing the columns explicitly (e.g., \texttt{mydata\ \%\textgreater{}\%\ select(year,\ cause...)}) there are several special functions that can be used inside \texttt{select()}.
These special functions are called select helpers, and the first select helper we used is \texttt{everything()}.

The most common select helpers are \texttt{starts\_with()}, \texttt{ends\_with()}, \texttt{contains()}, \texttt{matches()} (but there are several others that may be useful to you, so press F1 on \texttt{select()} for a full list, or search the web for more examples).

Let's say you can remember, whether the deaths column was called \texttt{deaths\_millions} or just \texttt{deaths} or \texttt{deaths\_mil}, or maybe there are other columns that include the word ``deaths'' that you want to \texttt{select()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_2rows }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{starts_with}\NormalTok{(}\StringTok{"deaths"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 1
##   deaths_millions
##             <dbl>
## 1           0.21 
## 2           1.150
\end{verbatim}

Note how ``deaths'' needs to be quoted inside \texttt{starts\_with()} - as it's a word to look for, not the real name of a column/variable.

\hypertarget{reshaping-data---long-vs-wide-format}{%
\section{Reshaping data - long vs wide format}\label{reshaping-data---long-vs-wide-format}}

\index{summarising data@\textbf{summarising data}!long vs wide data}

So far, all of the examples we've shown you have been using `tidy' data.
Data is `tidy' when it is in long format: \emph{each variable is in its own column}, and \emph{each observation is in its own row}.
This long format is efficient to use in data analysis and visualisation and can also be considered ``computer readable''.

But sometimes when presenting data in tables for humans to read, or when collecting data directly into a spreadsheet, it can be convenient to have data in a wide format.
Data is `wide' when \emph{some or all of the columns are levels of a factor}.
An example makes this easier to see.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_wide <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_wide-format.csv"}\NormalTok{)}
\NormalTok{gbd_long <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year-sex.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:chap3-tab-gbd-wide}Global Burden of Disease data in human-readable wide format. This is not tidy data.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lcccc}
\toprule
cause & Female\_1990 & Female\_2017 & Male\_1990 & Male\_2017\\
\midrule
Communicable diseases & 7.30 & 4.91 & 8.06 & 5.47\\
Injuries & 1.41 & 1.42 & 2.84 & 3.05\\
Non-communicable diseases & 12.80 & 19.15 & 13.91 & 21.74\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:chap3-tab-gbd-long}Global Burden of Disease data in analysis-friendly long format. This is tidy data.}
\centering
\fontsize{10}{12}\selectfont
\begin{tabular}[t]{lccc}
\toprule
cause & year & sex & deaths\_millions\\
\midrule
Communicable diseases & 1990 & Female & 7.30\\
Communicable diseases & 2017 & Female & 4.91\\
Communicable diseases & 1990 & Male & 8.06\\
Communicable diseases & 2017 & Male & 5.47\\
\addlinespace
Injuries & 1990 & Female & 1.41\\
Injuries & 2017 & Female & 1.42\\
Injuries & 1990 & Male & 2.84\\
Injuries & 2017 & Male & 3.05\\
\addlinespace
Non-communicable diseases & 1990 & Female & 12.80\\
Non-communicable diseases & 2017 & Female & 19.15\\
Non-communicable diseases & 1990 & Male & 13.91\\
Non-communicable diseases & 2017 & Male & 21.74\\
\bottomrule
\end{tabular}
\end{table}

Tables \ref{tab:chap3-tab-gbd-long} and \ref{tab:chap3-tab-gbd-wide} contain the exact same information, but in long (tidy) and wide formats, respectively.

\hypertarget{pivot-values-from-rows-into-columns-wider}{%
\subsection{Pivot values from rows into columns (wider)}\label{pivot-values-from-rows-into-columns-wider}}

\index{summarising data@\textbf{summarising data}!convert long to wide}
\index{functions@\textbf{functions}!pivot\_wider}

If we want to take the long data from \ref{tab:chap3-tab-gbd-long} and put some of the numbers next to each other for easier visualisation, then \texttt{pivot\_wider()} from the \textbf{tidyr} package is the function to do it.
It means we want to send a variable into columns, and it needs just two arguments: the variable we want to become the new columns, and the variable where the values currently are.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ year, }\DataTypeTok{values_from =}\NormalTok{ deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
##   cause                     sex    `1990` `2017`
##   <chr>                     <chr>   <dbl>  <dbl>
## 1 Communicable diseases     Female   7.3    4.91
## 2 Communicable diseases     Male     8.06   5.47
## 3 Injuries                  Female   1.41   1.42
## 4 Injuries                  Male     2.84   3.05
## 5 Non-communicable diseases Female  12.8   19.15
## 6 Non-communicable diseases Male    13.91  21.74
\end{verbatim}

This means we can quickly eyeball how the number of deaths has changed from 1990 to 2017 for each cause category and sex.
Whereas if we wanted to quickly look at the difference in the number of deaths for females and males, we can change the \texttt{names\_from\ =} argument from \texttt{=\ years} to \texttt{=\ sex}.
Furthermore, we can also add a \texttt{mutate()} to calculate the difference:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ sex, }\DataTypeTok{values_from =}\NormalTok{ deaths_millions) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(Male }\OperatorTok{-}\StringTok{ }\NormalTok{Female)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 5
##   cause                      year Female  Male `Male - Female`
##   <chr>                     <dbl>  <dbl> <dbl>           <dbl>
## 1 Communicable diseases      1990   7.3   8.06          0.76  
## 2 Communicable diseases      2017   4.91  5.47          0.5600
## 3 Injuries                   1990   1.41  2.84          1.430 
## 4 Injuries                   2017   1.42  3.05          1.63  
## 5 Non-communicable diseases  1990  12.8  13.91          1.110 
## 6 Non-communicable diseases  2017  19.15 21.74          2.59
\end{verbatim}

All of these differences are positive which means every year, more men die than women.
Which make sense, as more boys are born than girls.

And what if we want to look at both \texttt{year} and \texttt{sex} at the same time, so to create Table \ref{tab:chap3-tab-gbd-wide} from Table \ref{tab:chap3-tab-gbd-long}?
No problem, \texttt{pivot\_wider()} can deal with multiple variables at the same time, \texttt{names\_from\ =\ c(sex,\ year)}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =} \KeywordTok{c}\NormalTok{(sex, year), }\DataTypeTok{values_from =}\NormalTok{ deaths_millions)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 5
##   cause                     Female_1990 Female_2017 Male_1990 Male_2017
##   <chr>                           <dbl>       <dbl>     <dbl>     <dbl>
## 1 Communicable diseases            7.3         4.91      8.06      5.47
## 2 Injuries                         1.41        1.42      2.84      3.05
## 3 Non-communicable diseases       12.8        19.15     13.91     21.74
\end{verbatim}

\texttt{pivot\_wider()} has a few optional arguments that may be useful for you.
For example, \texttt{pivot\_wider(...,\ values\_fill\ =\ 0)} can be used to fill empty cases (if you have any) with a value you specified.
Or \texttt{pivot\_wider(...,\ names\_sep\ =\ ":\ ")} can be used to change the separator that gets put between the values (e.g., you may want ``Female: 1990'' instead of the default ``Female\_1990'').
Remember that pressing F1 when your cursor is on a function opens it up in the Help tab where these extra options are listed.

\hypertarget{pivot-values-from-columns-to-rows-longer}{%
\subsection{Pivot values from columns to rows (longer)}\label{pivot-values-from-columns-to-rows-longer}}

\index{summarising data@\textbf{summarising data}!convert wide to long}
\index{functions@\textbf{functions}!pivot\_longer}

The inverse of \texttt{pivot\_wider()} is \texttt{pivot\_longer()}.
If you're lucky enough, your data comes from a proper database and is already in the long and tidy format.
But if you do get landed with something that looks like Table \ref{tab:chap3-tab-gbd-wide}, you'll need to know how to wrangle the variables currently spread across different columns into the tidy format (where each column is a variable, each row is an observation).

\texttt{pivot\_longer()} can be a little bit more difficult to use as you need to describe all the columns to be collected using a \texttt{select\_helper}. Run `?select\_helpers and click on the first result in the Help tab for a reminder.

For example, here we want to collect all the columns that include the words Female or Male, the select helper for it is \texttt{matches("Female\textbar{}Male")}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_wide }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"Female|Male"}\NormalTok{), }\DataTypeTok{names_to =} \StringTok{"sex_year"}\NormalTok{, }\DataTypeTok{values_to =} \StringTok{"deaths_millions"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   cause                 sex_year    deaths_millions
##   <chr>                 <chr>                 <dbl>
## 1 Communicable diseases Female_1990            7.3 
## 2 Communicable diseases Female_2017            4.91
## 3 Communicable diseases Male_1990              8.06
## 4 Communicable diseases Male_2017              5.47
## 5 Injuries              Female_1990            1.41
## 6 Injuries              Female_2017            1.42
\end{verbatim}

You're probably looking at the example above and thinking that's all nice and simple on this miniature example dataset, but how on earth will I figure this out on a real-world example.
And you're right, we won't deny that \texttt{pivot\_longer()} is one of the most technically complicated functions in this book, and it can take a lot of trial and error to get it to work.
How to get started with your own \texttt{pivot\_longer()} transformation is to first play with the \texttt{select()} function to make sure you are telling R exactly which columns to pivot into the longer format.
For example, before working out the \texttt{pivot\_longer()} code for the above example, we would figure this out first:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_wide }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"Female|Male"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   Female_1990 Female_2017 Male_1990 Male_2017
##         <dbl>       <dbl>     <dbl>     <dbl>
## 1        7.3         4.91      8.06      5.47
## 2        1.41        1.42      2.84      3.05
## 3       12.8        19.15     13.91     21.74
\end{verbatim}

Then, knowing that \texttt{matches("Female\textbar{}Male")} works as expected inside our little \texttt{select()} test, we can copy-paste it into \texttt{pivot\_longer()} and add the \texttt{names\_to} and \texttt{values\_to} arguments. Both of these arguments are new column names that you can make up (in the above example, we are using ``sex\_year'' and ``deaths\_millions'').

\hypertarget{separate-a-column-into-multiple-columns}{%
\subsection{\texorpdfstring{\texttt{separate()} a column into multiple columns}{separate() a column into multiple columns}}\label{separate-a-column-into-multiple-columns}}

While \texttt{pivot\_longer()} did a great job fetching the different observations that were spread across multiple columns into a single one, it's still a combination of two variables - sex and year.
We can use the \texttt{separate()} function to deal with that.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_wide }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# same pivot_longer as before}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\KeywordTok{matches}\NormalTok{(}\StringTok{"Female|Male"}\NormalTok{), }\DataTypeTok{names_to =} \StringTok{"sex_year"}\NormalTok{, }\DataTypeTok{values_to =} \StringTok{"deaths_millions"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{separate}\NormalTok{(sex_year, }\DataTypeTok{into =} \KeywordTok{c}\NormalTok{(}\StringTok{"sex"}\NormalTok{, }\StringTok{"year"}\NormalTok{), }\DataTypeTok{sep =} \StringTok{"_"}\NormalTok{, }\DataTypeTok{convert =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 12 x 4
##    cause                     sex     year deaths_millions
##    <chr>                     <chr>  <int>           <dbl>
##  1 Communicable diseases     Female  1990            7.3 
##  2 Communicable diseases     Female  2017            4.91
##  3 Communicable diseases     Male    1990            8.06
##  4 Communicable diseases     Male    2017            5.47
##  5 Injuries                  Female  1990            1.41
##  6 Injuries                  Female  2017            1.42
##  7 Injuries                  Male    1990            2.84
##  8 Injuries                  Male    2017            3.05
##  9 Non-communicable diseases Female  1990           12.8 
## 10 Non-communicable diseases Female  2017           19.15
## 11 Non-communicable diseases Male    1990           13.91
## 12 Non-communicable diseases Male    2017           21.74
\end{verbatim}

We've also added \texttt{convert\ =\ TRUE} to \texttt{separate()} so \texttt{year} would get converted into a numeric variable.
The combination of, e.g., ``Female-1990'' is a character variable, so after separating them both \texttt{sex} and \texttt{year} would still be classified as characters.
But the \texttt{convert\ =\ TRUE} recognises that \texttt{year} is a number and will appropriately convert it into an integer.

\hypertarget{arrange-rows}{%
\section{\texorpdfstring{\texttt{arrange()} rows}{arrange() rows}}\label{arrange-rows}}

\index{summarising data@\textbf{summarising data}!arrange / order rows}
\index{functions@\textbf{functions}!arrange}

The \texttt{arrange()} function sorts rows based on the column(s) you want. By default, it arranges the tibble in ascending order:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(deaths_millions) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# first 3 rows just for printing:}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   cause     year sex    deaths_millions
##   <chr>    <dbl> <chr>            <dbl>
## 1 Injuries  1990 Female            1.41
## 2 Injuries  2017 Female            1.42
## 3 Injuries  1990 Male              2.84
\end{verbatim}

For numeric variables, we can just use a \texttt{-} to sort in descending order:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\OperatorTok{-}\NormalTok{deaths_millions) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 4
##   cause                      year sex    deaths_millions
##   <chr>                     <dbl> <chr>            <dbl>
## 1 Non-communicable diseases  2017 Male             21.74
## 2 Non-communicable diseases  2017 Female           19.15
## 3 Non-communicable diseases  1990 Male             13.91
\end{verbatim}

The \texttt{-} doesn't work for categorical variables, they need to be put in \texttt{desc()} for arranging in descending order:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{arrange}\NormalTok{(}\KeywordTok{desc}\NormalTok{(sex)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# printing rows 1, 2, 11, and 12}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{, }\DecValTok{11}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 4 x 4
##   cause                      year sex    deaths_millions
##   <chr>                     <dbl> <chr>            <dbl>
## 1 Communicable diseases      1990 Male              8.06
## 2 Communicable diseases      2017 Male              5.47
## 3 Non-communicable diseases  1990 Female           12.8 
## 4 Non-communicable diseases  2017 Female           19.15
\end{verbatim}

\hypertarget{factor-levels}{%
\subsection{Factor levels}\label{factor-levels}}

\index{summarising data@\textbf{summarising data}!factor levels}
\index{functions@\textbf{functions}!fct\_relevel}
\index{functions@\textbf{functions}!levels}

\texttt{arrange()} sorts characters alphabetically, whereas factors will be sorted by the order of their levels.
Let's make the cause column into a factor:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_factored <-}\StringTok{ }\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cause =} \KeywordTok{factor}\NormalTok{(cause))}
\end{Highlighting}
\end{Shaded}

When we first create a factor, its levels will be ordered alphabetically:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_factored}\OperatorTok{$}\NormalTok{cause }\OperatorTok{%>%}\StringTok{ }\KeywordTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Communicable diseases"     "Injuries"                 
## [3] "Non-communicable diseases"
\end{verbatim}

But we can now use \texttt{fct\_relevel()} inside \texttt{mutate()} to change the order of these levels:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_factored <-}\StringTok{ }\NormalTok{gbd_factored }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{cause =}\NormalTok{ cause }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_relevel}\NormalTok{(}\StringTok{"Injuries"}\NormalTok{))}

\NormalTok{gbd_factored}\OperatorTok{$}\NormalTok{cause }\OperatorTok{%>%}\StringTok{ }\KeywordTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Injuries"                  "Communicable diseases"    
## [3] "Non-communicable diseases"
\end{verbatim}

\texttt{fct\_relevel()} brings the level(s) listed in it to the front.

So if we use \texttt{arrange()} on \texttt{gbd\_factored}, the \texttt{cause} column will be sorted based on the order of its levels, not alphabetically.
This is especially useful in two places:

\begin{itemize}
\tightlist
\item
  plotting - categorical variables that are characters will be ordered alphabetically (e.g., think barplots), regardless of whether the rows are arranged or not;
\item
  statistical tests - the reference level of categorical variables that are characters is the alphabetically first (e.g., what the odds ratio is relative to).
\end{itemize}

However, making a character column into a factor gives us power to give its levels a non-alphabetical order, giving us control over plotting order or defining our reference levels for use in statistical tests.

\hypertarget{exercises}{%
\section{Exercises}\label{exercises}}

\hypertarget{exercise---pivot_wider}{%
\subsection{\texorpdfstring{Exercise - \texttt{pivot\_wider()}}{Exercise - pivot\_wider()}}\label{exercise---pivot_wider}}

Using the GBD dataset with variables \texttt{cause}, \texttt{year} (1990 and 2017 only), \texttt{sex} (as shown in Table \ref{tab:chap3-tab-gbd-long}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year-sex.csv"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Use \texttt{pivot\_wider()} to put the \texttt{cause} variable into columns using the \texttt{deaths\_millions} as values:

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-38}Exercise: putting the cause variable into the wide format.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lcccc}
\toprule
year & sex & Communicable diseases & Injuries & Non-communicable diseases\\
\midrule
1990 & Female & 7.30 & 1.41 & 12.80\\
2017 & Female & 4.91 & 1.42 & 19.15\\
1990 & Male & 8.06 & 2.84 & 13.91\\
2017 & Male & 5.47 & 3.05 & 21.74\\
\bottomrule
\end{tabular}}
\end{table}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_long =}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year-sex.csv"}\NormalTok{)}
\NormalTok{gbd_long }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ cause, }\DataTypeTok{values_from =}\NormalTok{ deaths_millions)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise---group_by-summarise}{%
\subsection{\texorpdfstring{Exercise - \texttt{group\_by()}, \texttt{summarise()}}{Exercise - group\_by(), summarise()}}\label{exercise---group_by-summarise}}

Read in the full GBD dataset with variables \texttt{cause}, \texttt{year}, \texttt{sex}, \texttt{income}, \texttt{deaths\_millions}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_full =}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}\StringTok{"data/global_burden_disease_cause-year-sex-income.csv"}\NormalTok{)}

\KeywordTok{glimpse}\NormalTok{(gbd_full)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 168
## Columns: 5
## $ cause           <chr> "Communicable diseases", "Communicable diseases", "...
## $ year            <dbl> 1990, 1990, 1990, 1990, 1990, 1990, 1990, 1990, 199...
## $ sex             <chr> "Female", "Female", "Female", "Female", "Male", "Ma...
## $ income          <chr> "High", "Upper-Middle", "Lower-Middle", "Low", "Hig...
## $ deaths_millions <dbl> 0.21, 1.15, 4.43, 1.51, 0.26, 1.35, 4.73, 1.72, 0.2...
\end{verbatim}

Year 2017 of this dataset was shown in Table \ref{tab:chap3-tab-gbd2017}, the full dataset has seven times as many observations as Table \ref{tab:chap3-tab-gbd2017} since it includes information about multiple years: 1990, 1995, 2000, 2005, 2010, 2015, 2017.

Investigate these code examples:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary_data1 <-}\StringTok{ }
\StringTok{  }\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(deaths_millions))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` ungrouping output (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary_data1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 7 x 2
##    year total_per_year
##   <dbl>          <dbl>
## 1  1990          46.32
## 2  1995          48.91
## 3  2000          50.38
## 4  2005          51.25
## 5  2010          52.63
## 6  2015          54.62
## 7  2017          55.74
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary_data2 <-}\StringTok{ }
\StringTok{  }\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, cause) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total_per_cause =} \KeywordTok{sum}\NormalTok{(deaths_millions))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{summary_data2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 21 x 3
## # Groups:   year [7]
##     year cause                     total_per_cause
##    <dbl> <chr>                               <dbl>
##  1  1990 Communicable diseases               15.36
##  2  1990 Injuries                             4.25
##  3  1990 Non-communicable diseases           26.71
##  4  1995 Communicable diseases               15.11
##  5  1995 Injuries                             4.53
##  6  1995 Non-communicable diseases           29.27
##  7  2000 Communicable diseases               14.81
##  8  2000 Injuries                             4.56
##  9  2000 Non-communicable diseases           31.01
## 10  2005 Communicable diseases               13.89
## # ... with 11 more rows
\end{verbatim}

You should recognise that:

\begin{itemize}
\tightlist
\item
  \texttt{summary\_data1} includes the total number of deaths per year.
\item
  \texttt{summary\_data2} includes the number of deaths per cause per year.
\item
  \texttt{summary\_data1\ =} means we are creating a new tibble called \texttt{summary\_data1} and saving (=) results into it. If \texttt{summary\_data1} was a tibble that already existed, it would get overwritten.
\item
  \texttt{gbd\_full} is the data being sent to the \texttt{group\_by()} and then \texttt{summarise()} functions.
\item
  \texttt{group\_by()} tells \texttt{summarise()} that we want aggregated results for each year.
\item
  \texttt{summarise()} then creates a new variable called \texttt{total\_per\_year} that sums the deaths from each different observation (subcategory) together.
\item
  Calling \texttt{summary\_data1} on a separate line gets it printed.
\item
  We then do something similar in \texttt{summary\_data2}.
\end{itemize}

Compare the number of rows (observations) and number of columns (variables) of \texttt{gbd\_full}, \texttt{summary\_data1}, and \texttt{summary\_data2}.

You should notice that:
* \texttt{summary\_data2} has exactly 3 times as many rows (observations) as \texttt{summary\_data1}. Why?
* \texttt{gbd\_full} has 5 variables, whereas the summarised tibbles have 2 and 3. Which variables got dropped? How?

\textbf{Answers}

\begin{itemize}
\tightlist
\item
  \texttt{gbd\_full} has 168 observations (rows),
\item
  \texttt{summary\_data1} has 7,
\item
  \texttt{summary\_data2} has 21.
\end{itemize}

\texttt{summary\_data1} was grouped by year, therefore it includes a (summarised) value for each year in the original dataset.
\texttt{summary\_data2} was grouped by year and cause (Communicable diseases, Injuries, Non-communicable diseases), so it has 3 values for each year.

The columns a \texttt{summarise()} function returns are: variables listed in \texttt{group\_by()} + variables created inside \texttt{summarise()} (e.g., in this case \texttt{deaths\_peryear}). All others get aggregated.

\hypertarget{exercise---full_join-percent}{%
\subsection{\texorpdfstring{Exercise - \texttt{full\_join()}, \texttt{percent()}}{Exercise - full\_join(), percent()}}\label{exercise---full_join-percent}}

For each cause, calculate its percentage to total deaths in each year.

Hint: Use \texttt{full\_join()} on \texttt{summary\_data1} and \texttt{summary\_data2}, and then use \texttt{mutate()} to add a new column called \texttt{percentage}.

Example result for a single year:

\begin{verbatim}
## Joining, by = "year"
\end{verbatim}

\begin{verbatim}
## # A tibble: 3 x 5
##    year total_per_year cause                     total_per_cause percentage
##   <dbl>          <dbl> <chr>                               <dbl> <chr>     
## 1  1990          46.32 Communicable diseases               15.36 33.161%   
## 2  1990          46.32 Injuries                             4.25 9.175%    
## 3  1990          46.32 Non-communicable diseases           26.71 57.664%
\end{verbatim}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(scales)}
\KeywordTok{full_join}\NormalTok{(summary_data1, summary_data2) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{percentage =} \KeywordTok{percent}\NormalTok{(total_per_cause}\OperatorTok{/}\NormalTok{total_per_year)) }
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise---mutate-summarise}{%
\subsection{\texorpdfstring{Exercise - \texttt{mutate()}, \texttt{summarise()}}{Exercise - mutate(), summarise()}}\label{exercise---mutate-summarise}}

Instead of creating the two summarised tibbles and using a \texttt{full\_join()}, achieve the same result as in the previous exercise with a single pipeline using \texttt{summarise()} and then \texttt{mutate()}.

Hint: you have to do it the other way round, so \texttt{group\_by(year,\ cause)\ \%\textgreater{}\%\ summarise(...)} first, then \texttt{group\_by(year)\ \%\textgreater{}\%\ mutate()}.

Bonus: \texttt{select()} columns \texttt{year}, \texttt{cause}, \texttt{percentage}, then \texttt{pivot\_wider()} the \texttt{cause} variable using \texttt{percentage} as values.

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# aggregate to deaths per cause per year using summarise()}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year, cause) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total_per_cause =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# then add a column of yearly totals using mutate()}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(year) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total_per_year =} \KeywordTok{sum}\NormalTok{(total_per_cause)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# add the percentage column}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{percentage =} \KeywordTok{percent}\NormalTok{(total_per_cause}\OperatorTok{/}\NormalTok{total_per_year)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# select the final variables for better vieweing}
\StringTok{  }\KeywordTok{select}\NormalTok{(year, cause, percentage) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ cause, }\DataTypeTok{values_from =}\NormalTok{ percentage)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'year' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 7 x 4
## # Groups:   year [7]
##    year `Communicable diseases` Injuries `Non-communicable diseases`
##   <dbl> <chr>                   <chr>    <chr>                      
## 1  1990 33%                     9%       58%                        
## 2  1995 31%                     9%       60%                        
## 3  2000 29%                     9%       62%                        
## 4  2005 27%                     9%       64%                        
## 5  2010 24%                     9%       67%                        
## 6  2015 20%                     8%       72%                        
## 7  2017 19%                     8%       73%
\end{verbatim}

Note that your pipelines shouldn't be much longer than this, and we often save interim results into separate tibbles for checking (like we did with \texttt{summary\_data1} and \texttt{summary\_data2}, making sure the number of rows are what we expect and spot checking that the calculation worked as expected).

\begin{quote}
R doesn't do what you want it to do, it does what you ask it to do. Testing and spot checking is essential as you will make mistakes. We sure do.
\end{quote}

Do not feel like you should be able to just bash out these clever pipelines without a lot of trial and error first.

\hypertarget{exercise---filter-summarise-pivot_wider}{%
\subsection{\texorpdfstring{Exercise - \texttt{filter()}, \texttt{summarise()}, \texttt{pivot\_wider()}}{Exercise - filter(), summarise(), pivot\_wider()}}\label{exercise---filter-summarise-pivot_wider}}

Still working with \texttt{gbd\_full}:

\begin{itemize}
\item
  Filter for 1990.
\item
  Calculate the total number of deaths in the different income groups (High, Upper-Middle, Lower-Middle, Low). Hint: use \texttt{group\_by(income)} and \texttt{summarise(new\_column\_name\ =\ sum(variable))}.
\item
  Calculate the total number of deaths within each income group for males and females. Hint: this is as easy as adding \texttt{,\ sex} to \texttt{group\_by(income)}.
\item
  \texttt{pivot\_wider()} the \texttt{income} column.
\end{itemize}

\textbf{Solution}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gbd_full }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{1990}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(income, sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{total_deaths =} \KeywordTok{sum}\NormalTok{(deaths_millions)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ income, }\DataTypeTok{values_from =}\NormalTok{ total_deaths)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `summarise()` regrouping output by 'income' (override with `.groups` argument)
\end{verbatim}

\begin{verbatim}
## # A tibble: 2 x 5
##   sex     High   Low `Lower-Middle` `Upper-Middle`
##   <chr>  <dbl> <dbl>          <dbl>          <dbl>
## 1 Female 4.140  2.22           8.47          6.68 
## 2 Male   4.46   2.57           9.83          7.950
\end{verbatim}

\hypertarget{chap04-h1}{%
\chapter{Different types of plots}\label{chap04-h1}}

\index{plots@\textbf{plots}}
\index{plots@\textbf{plots}!ggplot2}

\begin{quote}
What I cannot create, I do not understand.\\
Richard Feynman
\end{quote}

There are a few different plotting packages in R, but the most elegant and versatile one is \textbf{ggplot2}\footnote{The name of the package is \textbf{ggplot2}, but the function is called \texttt{ggplot()}. For everything you've ever wanted to know about the grammar of graphics in R, see \citet{wickham2016}.}.
\textbf{gg} stands for \textbf{g}rammar of \textbf{g}raphics which means that we can make a plot by describing it one component at a time.
In other words, we build a plot by adding layers to it.

This does not have to be many layers, the simplest \texttt{ggplot()} consists of just two components:

\begin{itemize}
\tightlist
\item
  the variables to be plotted;
\item
  a geometrical object (e.g., point, line, bar, box, etc.).
\end{itemize}

\texttt{ggplot()} calls geometrical objects \emph{geoms}.

Figure \ref{fig:chap04-fig-steps} shows some example steps for building a scatter plot, including changing its appearance (`theme') and faceting - an efficient way of creating separate plots for subgroups.

\index{functions@\textbf{functions}!ggplot}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-steps-1.pdf}
\caption{\label{fig:chap04-fig-steps}Example steps for building and modifying a ggplot. (1) Initialising the canvas and defining variables, (2) adding points, (3) colouring points by continent, (4) changing point type, (5) faceting, (6) changing the plot theme and the scale of the x variable.}
\end{figure}

\clearpage

\hypertarget{chap04-data}{%
\section{Get the data}\label{chap04-data}}

We are using the gapminder dataset (\url{https://www.gapminder.org/data}) that has been put into an R package by \citet{bryan2017} so we can load it with \texttt{library(gapminder)}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gapminder)}

\KeywordTok{glimpse}\NormalTok{(gapminder)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 1,704
## Columns: 6
## $ country   <fct> Afghanistan, Afghanistan, Afghanistan, Afghanistan, Afgha...
## $ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asi...
## $ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 199...
## $ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 4...
## $ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372,...
## $ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.113...
\end{verbatim}

The dataset includes 1704 observations (rows) of 6 variables (columns: country, continent, year, lifeExp, pop, gdpPercap).
\texttt{country}, \texttt{continent}, and \texttt{year} could be thought of as grouping variables, whereas lifeExp (life expectancy), pop (population), and gdpPercap (Gross Domestic Product per capita) are values.

The years in this dataset span 1952 to 2007 with 5-year intervals (so a total of 12 different years).
It includes 142 countries from 5 continents (Asia, Europe, Africa, Americas, Oceania).

You can check that all of the numbers quoted above are correct with these lines:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gapminder)}
\NormalTok{gapminder}\OperatorTok{$}\NormalTok{year }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{()}
\NormalTok{gapminder}\OperatorTok{$}\NormalTok{country }\OperatorTok{%>%}\StringTok{ }\KeywordTok{n_distinct}\NormalTok{()}
\NormalTok{gapminder}\OperatorTok{$}\NormalTok{continent }\OperatorTok{%>%}\StringTok{ }\KeywordTok{unique}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Let's create a new shorter tibble called \texttt{gapdata2007} that only includes data for the year 2007.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 <-}\StringTok{ }\NormalTok{gapminder }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{)}

\NormalTok{gapdata2007}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 142 x 6
##    country     continent  year lifeExp       pop gdpPercap
##    <fct>       <fct>     <int>   <dbl>     <int>     <dbl>
##  1 Afghanistan Asia       2007    43.8  31889923      975.
##  2 Albania     Europe     2007    76.4   3600523     5937.
##  3 Algeria     Africa     2007    72.3  33333216     6223.
##  4 Angola      Africa     2007    42.7  12420476     4797.
##  5 Argentina   Americas   2007    75.3  40301927    12779.
##  6 Australia   Oceania    2007    81.2  20434176    34435.
##  7 Austria     Europe     2007    79.8   8199783    36126.
##  8 Bahrain     Asia       2007    75.6    708573    29796.
##  9 Bangladesh  Asia       2007    64.1 150448339     1391.
## 10 Belgium     Europe     2007    79.4  10392226    33693.
## # ... with 132 more rows
\end{verbatim}

The new tibble - \texttt{gapdata2007} - now shows up in your Environment tab, whereas \texttt{gapminder} does not.
Running \texttt{library(gapminder)} makes it available to use (so the funny line below is not necessary for any of the code in this chapter to work), but to have it appear in your normal Environment tab you'll need to run this funny looking line:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# loads the gapminder dataset from the package environment}
\CommentTok{# into your Global Environment}
\NormalTok{gapdata <-}\StringTok{ }\NormalTok{gapminder}
\end{Highlighting}
\end{Shaded}

Both \texttt{gapdata} and \texttt{gapdata2007} now show up in the Environment tab and can be clicked on/quickly viewed as usual.

\hypertarget{chap04-gganatomy}{%
\section{Anatomy of ggplot explained}\label{chap04-gganatomy}}

\index{plots@\textbf{plots}!anatomy of a plot}
\index{plots@\textbf{plots}!aes}

We will now explain the six steps shown in Figure \ref{fig:chap04-fig-steps}.
Note that you only need the first two to make a plot, the rest are just to show you further functionality and optional customisations.

\textbf{(1)} Start by defining the variables, e.g., \texttt{ggplot(aes(x\ =\ var1,\ y\ =\ var2))}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp))}
\end{Highlighting}
\end{Shaded}

This creates the first plot in Figure \ref{fig:chap04-fig-steps}.

Although the above code is equivalent to:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggplot}\NormalTok{(gapdata2007, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp))}
\end{Highlighting}
\end{Shaded}

We tend to put the data first and then use the pipe (\texttt{\%\textgreater{}\%}) to send it to the \texttt{ggplot()} function.
This becomes useful when we add further data wrangling functions between the data and the \texttt{ggplot()}.
For example, our plotting pipelines often look like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{data }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(...) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(...) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(...)) }\OperatorTok{+}
\StringTok{  }\NormalTok{...}
\end{Highlighting}
\end{Shaded}

The lines that come before the \texttt{ggplot()} function are piped, whereas from \texttt{ggplot()} onwards you have to use +.
This is because we are now adding different layers and customisations to the same plot.

\texttt{aes()} stands for \textbf{aes}thetics - things we can see.
Variables are always inside the \texttt{aes()} function, which in return is inside a \texttt{ggplot()}.
Take a moment to appreciate the double closing brackets \texttt{))} - the first one belongs to \texttt{aes()}, the second one to \texttt{ggplot()}.

\textbf{(2)} Choose and add a geometrical object

Let's ask \texttt{ggplot()} to draw a point for each observation by adding \texttt{geom\_point()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

We have now created the second plot in Figure \ref{fig:chap04-fig-steps}, a scatter plot.

If we copy the above code and change just one thing - the \texttt{x} variable from \texttt{gdpPercap} to \texttt{continent} (which is a categorical variable) - we get what's called a strip plot.
This means we are now plotting a continuous variable (\texttt{lifeExp}) against a categorical one (\texttt{continent}).
But the thing to note is that the rest of the code stays exactly the same, all we did was change the \texttt{x\ =}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-stripplot-1.pdf}
\caption{\label{fig:chap04-fig-stripplot}A strip plot using \texttt{geom\_point()}.}
\end{figure}

\textbf{(3)} specifying further variables inside \texttt{aes()}

Going back to the scatter plot (\texttt{lifeExp} vs \texttt{gdpPercap}), let's use \texttt{continent} to give the points some colour.
We can do this by adding \texttt{colour\ =\ continent} inside the \texttt{aes()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This creates the third plot in Figure \ref{fig:chap04-fig-steps}. It uses the default colour scheme and will automatically include a legend.
Still with just two lines of code (\texttt{ggplot(...)} + \texttt{geom\_point()}).

\textbf{(4)} specifying aesthetics outside \texttt{aes()}

It is very important to understand the difference between including \texttt{ggplot} arguments inside or outside of the \texttt{aes()} function.

The main aesthetics (things we can see) are: \textbf{x}, \textbf{y}, \textbf{colour}, \textbf{fill}, \textbf{shape}, \textbf{size}, and any of these could appear inside or outside the \texttt{aes()} function.
Press F1 on, e.g., \texttt{geom\_point()}, to see the full list of aesthetics that can be used with this geom (this opens the Help tab).
If F1 is hard to summon on your keyboard, type in and run \texttt{?geom\_point}.

Variables (so columns of your dataset) have to be defined inside \texttt{aes()}.
Whereas to apply a modification on everything, we can set an aesthetic to a constant value outside of \texttt{aes()}.

For example, Figure \ref{fig:chap04-fig-shapes} shows a selection of the point shapes built into R. The default shape used by \texttt{geom\_point()} is number 16.

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-shapes-1.pdf}
\caption{\label{fig:chap04-fig-shapes}A selection of shapes for plotting. Shapes 0, 1, and 2 are hollow, whereas for shapes 21, 22, and 23 we can define both a colour and a fill (for the shapes, colour is the border around the fill).}
\end{figure}

To make all of the points in our figure hollow, let's set their shape to 1.
We do this by adding \texttt{shape\ =\ 1} inside the \texttt{geom\_point()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This creates the fourth plot in Figure \ref{fig:chap04-fig-steps}.

\textbf{(5)} From one plot to multiple with a single extra line

Faceting is a way to efficiently create the same plot for subgroups within the dataset.
For example, we can separate each continent into its own facet by adding \texttt{facet\_wrap(\textasciitilde{}continent)} to our plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{continent)}
\end{Highlighting}
\end{Shaded}

This creates the fifth plot in Figure \ref{fig:chap04-fig-steps}.
Note that we have to use the tilde (\textasciitilde) in \texttt{facet\_wrap()}.
There is a similar function called \texttt{facet\_grid()} that will create a grid of plots based on two grouping variables, e.g., \texttt{facet\_grid(var1\textasciitilde{}var2)}.
Furthermore, facets are happy to quickly separate data based on a condition (so something you would usually use in a filter).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{pop }\OperatorTok{>}\StringTok{ }\DecValTok{50000000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-facetcond-1.pdf}
\caption{\label{fig:chap04-fig-facetcond}Using a filtering condition (e.g., population \textgreater{} 50 million) directly inside a \texttt{facet\_wrap()}.}
\end{figure}

On this plot, the facet \texttt{FALSE} includes countries with a population less than 50 million people, and the facet \texttt{TRUE} includes countries with a population greater than 50 million people.

The tilde (\textasciitilde) in R denotes dependency.
It is mostly used by statistical models to define dependent and explanatory variables and you will see it a lot in the second part of this book.

\textbf{(6)} Grey to white background - changing the theme

Overall, we can customise every single thing on a ggplot.
Font type, colour, size or thickness or any lines or numbers, background, you name it.
But a very quick way to change the appearance of a ggplot is to apply a different theme.
The signature ggplot theme has a light grey background and white grid lines (Figure \ref{fig:chap04-fig-themes}).

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-themes-1.pdf}
\caption{\label{fig:chap04-fig-themes}Some of the built-in ggplot themes (1) default (2) \texttt{theme\_bw()}, (3) \texttt{theme\_dark()}, (4) \texttt{theme\_classic()}.}
\end{figure}

As a final step, we are adding \texttt{theme\_bw()} (``background white'') to give the plot a different look.
We have also divided the gdpPercap by 1000 (making the units ``thousands of dollars per capita'').
Note that you can apply calculations directly on ggplot variables (so how we've done \texttt{x\ =\ gdpPercap/1000} here).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap}\OperatorTok{/}\DecValTok{1000}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{continent) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This creates the last plot in Figure \ref{fig:chap04-fig-steps}.

This is how \texttt{ggplot()} works - you can build a plot by adding or modifying things one by one.

\hypertarget{set-your-theme---grey-vs-white}{%
\section{Set your theme - grey vs white}\label{set-your-theme---grey-vs-white}}

If you find yourself always adding the same theme to your plot (i.e., we really like the \texttt{+\ theme\_bw()}), you can use \texttt{theme\_set()} so your chosen theme is applied to every plot you draw:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

In fact, we usually have these two lines at the top of every script:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

Furthermore, we can customise anything that appears in a \texttt{ggplot()} from axis fonts to the exact grid lines, and much more.
That's what Chapter \ref{finetuning}: Fine tuning plots is all about, but here we are focussing on the basic functionality and how different geoms work.
But from now on,\texttt{+\ theme\_bw()} is automatically applied on everything we make.

\hypertarget{scatter-plotsbubble-plots}{%
\section{Scatter plots/bubble plots}\label{scatter-plotsbubble-plots}}

\index{plots@\textbf{plots}!scatter}
\index{plots@\textbf{plots}!bubble}

The ggplot anatomy (Section \ref{chap04-gganatomy}) covered both scatter and strip plots (both created with \texttt{geom\_point()}).
Another cool thing about this geom is that adding a size aesthetic makes it into a bubble plot.
For example, let's size the points by population.

As you would expect from a ``grammar of graphics plot'', this is as simple as adding \texttt{size\ =\ pop} as an aesthetic:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap}\OperatorTok{/}\DecValTok{1000}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{size =}\NormalTok{ pop)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

With increased bubble sizes, there is some overplotting, so let's make the points hollow (\texttt{shape\ =\ 1}) and slightly transparent (\texttt{alpha\ =\ 0.5}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ gdpPercap}\OperatorTok{/}\DecValTok{1000}\NormalTok{, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{size =}\NormalTok{ pop)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{1}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The resulting bubble plots are shown in Figure \ref{fig:chap04-fig-bubble}.

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-bubble-1.pdf}
\caption{\label{fig:chap04-fig-bubble}Turn the scatter plot from Figure \ref{fig:chap04-fig-steps}:(2) to a bubble plot by (1) adding \texttt{size\ =\ pop} inside the \texttt{aes()}, (2) make the points hollow and transparent.}
\end{figure}

Alpha is an aesthetic to make geoms transparent, its values can range from 0 (invisible) to 1 (solid).

\hypertarget{line-plotstime-series-plots}{%
\section{Line plots/time series plots}\label{line-plotstime-series-plots}}

\index{plots@\textbf{plots}!line}
\index{plots@\textbf{plots}!path}
\index{plots@\textbf{plots}!time-series}

Let's plot the life expectancy in the United Kingdom over time (Figure \ref{fig:chap04-fig-lineplot}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "United Kingdom"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-lineplot-1.pdf}
\caption{\label{fig:chap04-fig-lineplot}\texttt{geom\_line()}- Life expectancy in the United Kingdom over time.}
\end{figure}

As a recap, the steps in the code above are:

\begin{itemize}
\tightlist
\item
  Send \texttt{gapdata} into a \texttt{filter()};
\item
  inside the \texttt{filter()}, our condition is \texttt{country\ ==\ "United\ Kingdom"};
\item
  We initialise \texttt{ggplot()} and define our main variables: \texttt{aes(x\ =\ year,\ y\ =\ lifeExp)};
\item
  we are using a new geom - \texttt{geom\_line()}.
\end{itemize}

This is identical to how we used \texttt{geom\_point()}.
In fact, by just changing \texttt{line} to \texttt{point} in the code above works - and instead of a continuous line you'll get a point at every 5 years as in the dataset.

But what if we want to draw multiple lines, e.g., for each country in the dataset?
Let's send the whole dataset to \texttt{ggplot()} and \texttt{geom\_line()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

The reason you see this weird zigzag in Figure \ref{fig:chap04-fig-zigzag} (1) is that, using the above code, \texttt{ggplot()} does not know which points to connect with which.
Yes, you know you want a line for each country, but you haven't told it that.
So for drawing multiple lines, we need to add a \texttt{group} aesthetic, in this case \texttt{group\ =\ country}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{group =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-zigzag-1.pdf}
\caption{\label{fig:chap04-fig-zigzag}The `zig-zag plot' is a common mistake: Using \texttt{geom\_line()} (1) without a \texttt{group} specified, (2) after adding \texttt{group\ =\ country}.}
\end{figure}

This code works as expected (Figure \ref{fig:chap04-fig-zigzag} (2)) - yes there is a lot of overplotting but that's just because we've included 142 lines on a single plot.

\hypertarget{chap04-ex-lineplot}{%
\subsection{Exercise}\label{chap04-ex-lineplot}}

Follow the step-by-step instructions to transform Figure \ref{fig:chap04-fig-zigzag}(2) into \ref{fig:chap04-fig-lineplot2}.

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-lineplot2-1.pdf}
\caption{\label{fig:chap04-fig-lineplot2}Lineplot exercise.}
\end{figure}

\begin{itemize}
\tightlist
\item
  Colour lines by continents: add \texttt{colour\ =\ continent} inside \texttt{aes()};
\item
  Continents on separate facets: \texttt{+\ facet\_wrap(\textasciitilde{}continent)};
\item
  Use a nicer colour scheme: \texttt{+\ scale\_colour\_brewer(palette\ =\ "Paired")}.
\end{itemize}

\hypertarget{bar-plots}{%
\section{Bar plots}\label{bar-plots}}

\index{plots@\textbf{plots}!bar}
\index{plots@\textbf{plots}!column}

There are two geoms for making bar plots - \texttt{geom\_col()} and \texttt{geom\_bar()} and the examples below will illustrate when to use which one.
In short: if your data is already summarised or includes values for \texttt{y} (height of the bars), use \texttt{geom\_col()}.
If, however, you want \texttt{ggplot()} to count up the number of rows in your dataset, use \texttt{geom\_bar()}.
For example, with patient-level data (each row is a patient) you'll probably want to use \texttt{geom\_bar()}, with data that is already somewhat aggregated, you'll use \texttt{geom\_col()}.
There is no harm in trying one, and if it doesn't work, trying the other.

\hypertarget{summarised-data}{%
\subsection{Summarised data}\label{summarised-data}}

\begin{itemize}
\tightlist
\item
  \texttt{geom\_col()} requires two variables \texttt{aes(x\ =\ ,\ y\ =\ )}
\item
  \texttt{x} is categorical, \texttt{y} is continuous (numeric)
\end{itemize}

Let's plot the life expectancies in 2007 in these three countries:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"United Kingdom"}\NormalTok{, }\StringTok{"France"}\NormalTok{, }\StringTok{"Germany"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ country, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

This gives us Figure \ref{fig:chap04-fig-col}:1.
We have also created another cheeky one using the same code but changing the scale of the y axis to be more dramatic (Figure \ref{fig:chap04-fig-col}:2).

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-col-1.pdf}
\caption{\label{fig:chap04-fig-col}Bar plots using \texttt{geom\_col()}: (1) using the code example, (2) same plot but with \texttt{+\ coord\_cartesian(ylim=c(79,\ 81))} to manipulate the scale into something a lot more dramatic.}
\end{figure}

\FloatBarrier

\hypertarget{countable-data}{%
\subsection{Countable data}\label{countable-data}}

\begin{itemize}
\tightlist
\item
  \texttt{geom\_bar()} requires a single variable \texttt{aes(x\ =\ )}
\item
  this \texttt{x} should be a categorical variable
\item
  \texttt{geom\_bar()} then counts up the number of observations (rows) for this variable and plots them as bars.
\end{itemize}

Our \texttt{gapdata2007} tibble has a row for each country (see end of Section \ref{chap04-data} to remind yourself).
Therefore, if we use the \texttt{count()} function on the \texttt{continent} variable, we are counting up the number of countries on each continent (in this dataset\footnote{The number of countries in this dataset is 142, whereas the United Nations have 193 member states.}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{count}\NormalTok{(continent)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 2
##   continent     n
##   <fct>     <int>
## 1 Africa       52
## 2 Americas     25
## 3 Asia         33
## 4 Europe       30
## 5 Oceania       2
\end{verbatim}

So \texttt{geom\_bar()} basically runs the \texttt{count()} function and plots it (see how the bars on Figure \ref{fig:chap04-fig-bar} are the same height as the values from \texttt{count(continent)}).

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-bar-1.pdf}
\caption{\label{fig:chap04-fig-bar}\texttt{geom\_bar()} counts up the number of observations for each group. (1) \texttt{gapdata2007\ \%\textgreater{}\%\ ggplot(aes(x\ =\ continent))\ +\ geom\_bar()}, (2) same + a little bit of magic to reveal the underlying data.}
\end{figure}

The first barplot in Figure \ref{fig:chap04-fig-bar} is produced with just this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Whereas on the second one, we've asked \texttt{geom\_bar()} to reveal the components (countries) in a colourful way:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{fill =} \OtherTok{NA}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We have added \texttt{theme(legend.position\ =\ "none")} to remove the legend - it includes all 142 countries and is not very informative in this case.
We're only including the colours for a bit of fun.

We're also removing the fill by setting it to NA (\texttt{fill\ =\ NA}).
Note how we defined \texttt{colour\ =\ country} inside the \texttt{aes()} (as it's a variable), but we put the fill inside \texttt{geom\_bar()} as a constant.
This was explained in more detail in steps (3) and (4) in the ggplot anatomy Section (\ref{chap04-gganatomy}).

\hypertarget{colour-vs-fill}{%
\subsection{\texorpdfstring{\texttt{colour} vs \texttt{fill}}{colour vs fill}}\label{colour-vs-fill}}

\index{plots@\textbf{plots}!colour}
\index{plots@\textbf{plots}!fill}

Figure \ref{fig:chap04-fig-bar} also reveals the difference between a colour and a fill.
Colour is the border around a geom, whereas fill is inside it.
Both can either be set based on a variable in your dataset (this means \texttt{colour\ =} or \texttt{fill\ =} needs to be inside the \texttt{aes()} function), or they could be set to a fixed colour.

R has an amazing knowledge of colour.
In addition to knowing what is ``white'', ``yellow'', ``red'', ``green'' etc. (meaning we can simply do \texttt{geom\_bar(fill\ =\ "green")}), it also knows what ``aquamarine'', ``blanchedalmond'', ``coral'', ``deeppink'', ``lavender'', ``deepskyblue'' look like (amongst many many others; search the internet for ``R colours'' for a full list).

We can also use Hex colour codes, for example, \texttt{geom\_bar(fill\ =\ "\#FF0099")} is a very pretty pink.
Every single colour in the world can be represented with a Hex code, and the codes are universally known by most plotting or image making programmes.
Therefore, you can find Hex colour codes from a lot of places on the internet, or \url{https://www.color-hex.com} just to name one.

\hypertarget{chap04-proportions}{%
\subsection{Proportions}\label{chap04-proportions}}

Whether using \texttt{geom\_bar()} or \texttt{geom\_col()}, we can use fill to display proportions within bars.
Furthermore, sometimes it's useful to set the x value to a constant - to get everything plotted together rather than separated by a variable.
So we are using \texttt{aes(x\ =\ "Global",\ fill\ =\ continent)}.
Note that ``Global'' could be any word - since it's quoted \texttt{ggplot()} won't go looking for it in the dataset (Figure \ref{fig:chap04-fig-proportions}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Global"}\NormalTok{, }\DataTypeTok{fill =}\NormalTok{ continent)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-proportions-1.pdf}
\caption{\label{fig:chap04-fig-proportions}Number of countries in the gapminder datatset with proportions using the \texttt{fill\ =\ continent} aesthetic.}
\end{figure}

There are more examples of bar plots in Chapter \ref{chap08-h1}.

\hypertarget{chap04-ex-barplot}{%
\subsection{Exercise}\label{chap04-ex-barplot}}

Create Figure \ref{fig:chap04-fig-bar-exercise} of life expectancies in European countries (year 2007).

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-bar-exercise-1.pdf}
\caption{\label{fig:chap04-fig-bar-exercise}Barplot exercise. Life expectancies in European countries in year 2007 from the gapminder dataset.}
\end{figure}

Hints:

\begin{itemize}
\tightlist
\item
  If \texttt{geom\_bar()} doesn't work try \texttt{geom\_col()} or vice versa.
\item
  \texttt{coord\_flip()} to make the bars horizontal (it flips the \texttt{x} and \texttt{y} axes).
\item
  \texttt{x\ =\ country} gets the country bars plotted in alphabetical order, use \texttt{x\ =\ fct\_reorder(country,\ lifeExp)} still inside the \texttt{aes()} to order the bars by their \texttt{lifeExp} values. Or try one of the other variables (\texttt{pop}, \texttt{gdpPercap}) as the second argument to \texttt{fct\_reorder()}.
\item
  when using \texttt{fill\ =\ NA}, you also need to include a colour; we're using \texttt{colour\ =\ "deepskyblue"} inside the \texttt{geom\_col()}.
\end{itemize}

\FloatBarrier

\hypertarget{histograms}{%
\section{Histograms}\label{histograms}}

\index{plots@\textbf{plots}!histogram}

A histogram displays the distribution of values within a continuous variable.
In the example below, we are taking the life expectancy (\texttt{aes(x\ =\ lifeExp)}) and telling the histogram to count the observations up in ``bins'' of 10 years (\texttt{geom\_histogram(binwidth\ =\ 10)}, Figure \ref{fig:chap04-fig-hist}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{binwidth =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-hist-1.pdf}
\caption{\label{fig:chap04-fig-hist}\texttt{geom\_histogram()} - The distribution of life expectancies in different countries around the world in year 2007.}
\end{figure}

We can see that most countries in the world have a life expectancy of \textasciitilde70-80 years (in 2007), and that the distribution of life expectancies globally is not normally distributed.
Setting the binwidth is optional, using just \texttt{geom\_histogram()} works well too - by default, it will divide your data into 30 bins.

There are more examples of histograms in Chapter \ref{chap06-h1}. There are two other geoms that are useful for plotting distributions: \texttt{geom\_density()} and \texttt{geom\_freqpoly()}.

\hypertarget{box-plots}{%
\section{Box plots}\label{box-plots}}

\index{plots@\textbf{plots}!boxplot}

Box plots are our go to method for quickly visualising summary statistics of a continuous outcome variable (such as life expectancy in the gapminder dataset, Figure \ref{fig:chap04-fig-boxplot}).

Box plots include:

\begin{itemize}
\tightlist
\item
  the median (middle line in the box)
\item
  inter-quartile range (IQR, top and bottom parts of the boxes - this is where 50\% of your data is)
\item
  whiskers (the black lines extending to the lowest and highest values that are still within 1.5*IQR)
\item
  outliers (any observations out with the whiskers)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-boxplot-1.pdf}
\caption{\label{fig:chap04-fig-boxplot}\texttt{geom\_boxplot()} - Boxplots of life expectancies within each continent in year 2007.}
\end{figure}

\hypertarget{multiple-geoms-multiple-aes}{%
\section{\texorpdfstring{Multiple geoms, multiple \texttt{aes()}}{Multiple geoms, multiple aes()}}\label{multiple-geoms-multiple-aes}}

One of the coolest things about \texttt{ggplot()} is that we can plot multiple geoms on top of each other!

Let's add individual data points on top of the box plots:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

This makes Figure \ref{fig:chap04-fig-multigeoms}(1).

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-multigeoms-1.pdf}
\caption{\label{fig:chap04-fig-multigeoms}Multiple geoms together. (1) \texttt{geom\_boxplot()\ +\ geom\_point()}, (2) \texttt{geom\_boxplot()\ +\ geom\_jitter()}, (3) colour aesthetic inside \texttt{ggplot(aes())}, (4) colour aesthetic inside \texttt{geom\_jitter(aes())}.}
\end{figure}

The only thing we've changed in (2) is replacing \texttt{geom\_point()} with \texttt{geom\_jitter()} - this spreads the points out to reduce overplotting.

But what's really exciting is the difference between (3) and (4) in Figure \ref{fig:chap04-fig-multigeoms}. Spot it!

\index{plots@\textbf{plots}!jitter}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# (3)}
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{()}

\CommentTok{# (4)}
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{colour =}\NormalTok{ continent))}
\end{Highlighting}
\end{Shaded}

This is new: \texttt{aes()} inside a geom, not just at the top!
In the code for (4) you can see \texttt{aes()} in two places - at the top and inside the \texttt{geom\_jitter()}.
And \texttt{colour\ =\ continent} was only included in the second \texttt{aes()}.
This means that the jittered points get a colour, but the box plots will be drawn without (so just black).
This is exactly* what we see on \ref{fig:chap04-fig-multigeoms}.

*Nerd alert: the variation added by \texttt{geom\_jitter()} is random, which means that when you recreate the same plots the points will appear in slightly different locations to ours. To make identical ones, add \texttt{position\ =\ position\_jitter(seed\ =\ 1)} inside \texttt{geom\_jitter()}.

\hypertarget{worked-example---three-geoms-together}{%
\subsection{Worked example - three geoms together}\label{worked-example---three-geoms-together}}

Let's combine three geoms by including text labels on top of the box plot + points from above.

We are creating a new tibble called \texttt{label\_data} filtering for the maximum life expectancy countries at each continent (\texttt{group\_by(continent)}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{label_data <-}\StringTok{ }\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(lifeExp }\OperatorTok{==}\StringTok{ }\KeywordTok{max}\NormalTok{(lifeExp)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(country, continent, lifeExp)}

\CommentTok{# since we filtered for lifeExp == max(lifeExp)}
\CommentTok{# these are the maximum life expectancy countries at each continent:}
\NormalTok{label_data}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 3
## # Groups:   continent [5]
##   country   continent lifeExp
##   <fct>     <fct>       <dbl>
## 1 Australia Oceania      81.2
## 2 Canada    Americas     80.7
## 3 Iceland   Europe       81.8
## 4 Japan     Asia         82.6
## 5 Reunion   Africa       76.4
\end{verbatim}

The first two geoms are from the previous example (\texttt{geom\_boxplot()} and \texttt{geom\_jitter()}).
Note that \texttt{ggplot()} plots them in the order they are in the code - so box plots at the bottom, jittered points on the top.
We are then adding \texttt{geom\_label()} with its own data option (\texttt{data\ =\ label\_data}) as well as a new aesthetic (\texttt{aes(label\ =\ country)}, Figure \ref{fig:chap04-fig-labels}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\CommentTok{# First geom - boxplot}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\CommentTok{# Second geom - jitter with its own aes(colour = )}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\CommentTok{# Third geom - label, with its own dataset (label_data) and aes(label = )}
\StringTok{  }\KeywordTok{geom_label}\NormalTok{(}\DataTypeTok{data =}\NormalTok{ label_data, }\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ country))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-labels-1.pdf}
\caption{\label{fig:chap04-fig-labels}Three geoms together on a single plot: \texttt{geom\_boxplot()}, \texttt{geom\_jitter()}, and \texttt{geom\_label()}.}
\end{figure}

A few suggested experiments to try with the 3-geom plot code above:

\begin{itemize}
\tightlist
\item
  remove \texttt{data\ =\ label\_data,} from \texttt{geom\_label()} and you'll get all 142 labels (so it will plot a label for the whole \texttt{gapdata2007} dataset);
\item
  change from \texttt{geom\_label()} to \texttt{geom\_text()} - it works similarly but doesn't have the border and background behind the country name;
\item
  change \texttt{label\ =\ country} to \texttt{label\ =\ lifeExp}, this plots the maximum value, rather than the country name.
\end{itemize}

\hypertarget{all-other-types-of-plots}{%
\section{All other types of plots}\label{all-other-types-of-plots}}

In this chapter we have introduced some of the most common geoms, as well as explained how \texttt{ggplot()} works.
In fact, ggplot has 56 different geoms for you to use; see its documentation for a full list: \url{https://ggplot2.tidyverse.org}.

With the ability of combining multiple geoms together on the same plot, the possibilities really are endless.
Furthermore, the plotly Graphic Library (\url{https://plot.ly/ggplot2/}) can make some of your ggplots interactive, meaning you can use your mouse to hover over the point or zoom and subset interactively.

The two most important things to understand about \texttt{ggplot()} are:

\begin{itemize}
\tightlist
\item
  Variables (columns in your dataset) need to be inside \texttt{aes()};
\item
  \texttt{aes()} can be both at the top - \texttt{data\ \%\textgreater{}\%\ ggplot(aes())} - as well as inside a geom (e.g., \texttt{geom\_point(aes())}).
  This distinction is useful when combining multiple geoms.
  All your geoms will ``know about'' the top-level \texttt{aes()} variables, but including \texttt{aes()} variables inside a specific geom means it only applies to that one.
\end{itemize}

\hypertarget{solutions}{%
\section{Solutions}\label{solutions}}

Solution to Exercise \ref{chap04-ex-lineplot}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gapminder)}

\NormalTok{gapminder }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x      =}\NormalTok{ year,}
             \DataTypeTok{y      =}\NormalTok{ lifeExp,}
             \DataTypeTok{group  =}\NormalTok{ country,}
             \DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{continent) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Paired"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Solution to Exercise \ref{chap04-ex-barplot}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gapminder)}

\NormalTok{gapminder }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{fct_reorder}\NormalTok{(country, lifeExp), }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_col}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"deepskyblue"}\NormalTok{, }\DataTypeTok{fill =} \OtherTok{NA}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_flip}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_classic}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{extra-advanced-examples}{%
\section{Extra: Advanced examples}\label{extra-advanced-examples}}

There are two examples of how just a few lines of \texttt{ggplot()} code and the basic geoms introduced in this chapter can be used to make very different things.
Let your imagination fly free when using \texttt{ggplot()}!

Figure \ref{fig:chap04-fig-adv1} shows how the life expectancies in European countries have increased by plotting a square (\texttt{geom\_point(shape\ =\ 15)}) for each observation (year) in the dataset.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y      =} \KeywordTok{fct_reorder}\NormalTok{(country, lifeExp, }\DataTypeTok{.fun=}\NormalTok{max),}
             \DataTypeTok{x      =}\NormalTok{ lifeExp,}
             \DataTypeTok{colour =}\NormalTok{ year)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{shape =} \DecValTok{15}\NormalTok{, }\DataTypeTok{size =} \DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_distiller}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Greens"}\NormalTok{, }\DataTypeTok{direction =} \DecValTok{1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-adv1-1.pdf}
\caption{\label{fig:chap04-fig-adv1}Increase in European life expectancies over time. Using \texttt{fct\_reorder()} to order the countries on the y-axis by life expectancy (rather than alphabetically which is the default).}
\end{figure}

In Figure \ref{fig:chap04-fig-adv2}, we're using \texttt{group\_by(continent)} followed by \texttt{mutate(country\_number\ =\ seq\_along(country))} to create a new column with numbers 1, 2, 3, etc., for countries within continents.
We are then using these as \texttt{y} coordinates for the text labels (\texttt{geom\_text(aes(y\ =\ country\_number...}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata2007 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{country_number =} \KeywordTok{seq_along}\NormalTok{(country)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{colour =}\NormalTok{ continent), }\DataTypeTok{fill =} \OtherTok{NA}\NormalTok{, }\DataTypeTok{show.legend =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_text}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ country_number, }\DataTypeTok{label =}\NormalTok{ country), }\DataTypeTok{vjust =} \DecValTok{1}\NormalTok{)}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_label}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{label =}\NormalTok{ continent), }\DataTypeTok{y =} \DecValTok{-1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{04_plotting_files/figure-latex/chap04-fig-adv2-1.pdf}
\caption{\label{fig:chap04-fig-adv2}List of countries on each continent as in the gapminder dataset.}
\end{figure}

\hypertarget{finetuning}{%
\chapter{Fine tuning plots}\label{finetuning}}

\index{plots@\textbf{plots}!finetuning}

\hypertarget{get-the-data-1}{%
\section{Get the data}\label{get-the-data-1}}

We can save a \texttt{ggplot()} object into a variable (we usually call it \texttt{p} but it can be any name).
This then appears in the Environment tab.
To plot it it needs to be recalled on a separate line to get drawn (Figure \ref{fig:chap05-fig-p0}).
Saving a plot into a variable allows us to modify it later (e.g., \texttt{p\ +\ theme\_bw()}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(gapminder)}
\KeywordTok{library}\NormalTok{(tidyverse)}

\NormalTok{p0 <-}\StringTok{ }\NormalTok{gapminder }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{x =}\NormalTok{ gdpPercap, }\DataTypeTok{colour =}\NormalTok{ continent)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme_bw}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_colour_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Set1"}\NormalTok{)}

\NormalTok{p0}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p0-1.pdf}
\caption{\label{fig:chap05-fig-p0}p0: Starting plot for the examples in this chapter.}
\end{figure}

\hypertarget{scales}{%
\section{Scales}\label{scales}}

\index{plots@\textbf{plots}!scales}
\index{plots@\textbf{plots}!log scales}
\index{plots@\textbf{plots}!transformations}
\index{plots@\textbf{plots}!sub}

\hypertarget{logarithmic}{%
\subsection{Logarithmic}\label{logarithmic}}

Transforming an axis to a logarithmic scale can be done by adding on \texttt{scale\_x\_log10()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}\StringTok{ }\KeywordTok{scale_x_log10}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\texttt{scale\_x\_log10()} and \texttt{scale\_x\_log10()} are shortcuts for the base-10 logarithmic transformation of an axis.
The same could be achieved by using, e.g., \texttt{scale\_x\_continuous(trans\ =\ "log10")}.
The latter can take a selection of options, namely \texttt{"reverse"}, \texttt{"log2"}, or \texttt{"sqrt"}.
Check the Help tab for \texttt{scale\_continuous()} or look up its online documentation for a full list.

\hypertarget{expand-limits}{%
\subsection{Expand limits}\label{expand-limits}}

\index{plots@\textbf{plots}!expand limits}

A quick way to expand the limits of your plot is to specify the value you want to be included:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p2 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}\StringTok{ }\KeywordTok{expand_limits}\NormalTok{(}\DataTypeTok{y =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Or two values for extending to both sides of the plot:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p3 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}\StringTok{ }\KeywordTok{expand_limits}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

By default, \texttt{ggplot()} adds some padding around the included area (see how the scale doesn't start from 0, but slightly before).
This ensures points on the edges don't get overlapped with the axes, but in some cases - especially if you've already expanded the scale, you might want to remove this extra padding.
You can remove this padding with the \texttt{expand} argument:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p4 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{expand_limits}\NormalTok{(}\DataTypeTok{y =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_cartesian}\NormalTok{(}\DataTypeTok{expand =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We are now using a new library - \textbf{patchwork} - to print all 4 plots together (Figure \ref{fig:chap05-fig-p1234}).
Its syntax is very simple - it allows us to add ggplot objects together.
(Trying to do \texttt{p1\ +\ p2} without loading the \textbf{patchwork} package will not work, R will say ``Error: Don't know how to add p2 to a plot''.)

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(patchwork)}
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2 }\OperatorTok{+}\StringTok{ }\NormalTok{p3 }\OperatorTok{+}\StringTok{ }\NormalTok{p4 }\OperatorTok{+}\StringTok{ }\KeywordTok{plot_annotation}\NormalTok{(}\DataTypeTok{tag_levels =} \StringTok{"1"}\NormalTok{, }\DataTypeTok{tag_prefix =} \StringTok{"p"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p1234-1.pdf}
\caption{\label{fig:chap05-fig-p1234}p1: Using a logarithmic scale for the x axis. p2: Expanding the limits of the y axis to include 0. p3: Expanding the limits of the y axis to include 0 and 100. p4: Removing extra padding around the limits.}
\end{figure}

\hypertarget{zoom-in}{%
\subsection{Zoom in}\label{zoom-in}}

\index{plots@\textbf{plots}!zoom}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_cartesian}\NormalTok{(}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{70}\NormalTok{, }\DecValTok{85}\NormalTok{), }\DataTypeTok{xlim =} \KeywordTok{c}\NormalTok{(}\DecValTok{20000}\NormalTok{, }\DecValTok{40000}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\hypertarget{exercise}{%
\subsection{Exercise}\label{exercise}}

How is this one different to the previous (Figure \ref{fig:chap05-fig-p56})?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p6 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{70}\NormalTok{, }\DecValTok{85}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}\DataTypeTok{limits =} \KeywordTok{c}\NormalTok{(}\DecValTok{20000}\NormalTok{, }\DecValTok{40000}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

Answer: the first one zooms in, still retaining information about the excluded points when calculating the linear regression lines.
The second one removes the data (as the warnings say), calculating the linear regression lines only for the visible points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p5 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p5"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{p6 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p6"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 114 rows containing non-finite values (stat_smooth).
\end{verbatim}

\begin{verbatim}
## Warning: Removed 114 rows containing missing values (geom_point).
\end{verbatim}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p56-1.pdf}
\caption{\label{fig:chap05-fig-p56}p5: Using \texttt{coord\_cartesian()} vs p6: Using \texttt{scale\_x\_continuous()} and \texttt{scale\_y\_continuous()} for setting the limits of plot axes.}
\end{figure}

Preivously we used \textbf{patchwork}'s \texttt{plot\_annotation()} function to create our multiplot tags.
Since our exmaples no longer start the count from 1, we're using \texttt{ggplot()}'s tags instead, e.g., \texttt{labs(tag\ =\ "p5")}.
The \texttt{labs()} function iwill be covered in more detail later in this chapter.

\hypertarget{axis-ticks}{%
\subsection{Axis ticks}\label{axis-ticks}}

\index{plots@\textbf{plots}!axes}

\texttt{ggplot()} does a good job deciding how many and which values include on the axis (e.g., 70/75/80/85 for the y axes in Figure \ref{fig:chap05-fig-p56}).
But sometimes you'll want to specify these, for example, to indicate threshold values or a maximum (Figure \ref{fig:chap05-fig-p78}).
We can do so by using the \texttt{breaks} argument:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# calculating the maximum value to be included in the axis breaks:}
\NormalTok{max_value =}\StringTok{ }\NormalTok{gapminder }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summarise}\NormalTok{(}\DataTypeTok{max_lifeExp =} \KeywordTok{max}\NormalTok{(lifeExp)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pull}\NormalTok{(max_lifeExp) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{round}\NormalTok{(}\DecValTok{1}\NormalTok{)}

\CommentTok{# using scale_y_continuous(breaks = ...):}
\NormalTok{p7 <-}\StringTok{  }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_cartesian}\NormalTok{(}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{), }\DataTypeTok{expand =} \DecValTok{0}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{50}\NormalTok{, max_value))}

\CommentTok{# we may also include custom labels for our breaks:}
\NormalTok{p8 <-}\StringTok{  }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_cartesian}\NormalTok{(}\DataTypeTok{ylim =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{100}\NormalTok{), }\DataTypeTok{expand =} \DecValTok{0}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_y_continuous}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{18}\NormalTok{, }\DecValTok{50}\NormalTok{, max_value), }\DataTypeTok{labels =} \KeywordTok{c}\NormalTok{(}\StringTok{"Adults"}\NormalTok{, }\StringTok{"50"}\NormalTok{, }\StringTok{"MAX"}\NormalTok{))}

\NormalTok{p7 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p7"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{p8 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p8"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p78-1.pdf}
\caption{\label{fig:chap05-fig-p78}p7: Specifiying y axis breaks. p8: Adding custom labels for our breaks.}
\end{figure}

\hypertarget{colours}{%
\section{Colours}\label{colours}}

\index{plots@\textbf{plots}!colours}

\hypertarget{using-the-brewer-palettes}{%
\subsection{Using the Brewer palettes:}\label{using-the-brewer-palettes}}

The easiest way to change the colour palette of your \texttt{ggplot()} is to specify a Brewer palette (\citet{brewer2003}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p9 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_brewer}\NormalTok{(}\DataTypeTok{palette =} \StringTok{"Paired"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that \url{http://colorbrewer2.org/} also has options for \emph{Colourblind safe} and \emph{Print friendly}.

\hypertarget{legend-title}{%
\subsection{Legend title}\label{legend-title}}

\index{plots@\textbf{plots}!legend}

\texttt{scale\_colour\_brewer()} is also a convenient place to change the legend title (Figure \ref{fig:chap05-fig-p910}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p10 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_brewer}\NormalTok{(}\StringTok{"Continent - }\CharTok{\textbackslash{}n}\StringTok{ one of 5"}\NormalTok{, }\DataTypeTok{palette =} \StringTok{"Paired"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note the \texttt{\textbackslash{}n} inside the new legend title - new line.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p9 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p9"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{p10 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p10"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p910-1.pdf}
\caption{\label{fig:chap05-fig-p910}p9: Choosing a Brewer palette for your colours. p10: Changing the legend title.}
\end{figure}

\hypertarget{choosing-colours-manually}{%
\subsection{Choosing colours manually}\label{choosing-colours-manually}}

R also knows the names of many colours, so we can use words to specify colours:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p11 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{, }\StringTok{"green"}\NormalTok{, }\StringTok{"blue"}\NormalTok{, }\StringTok{"purple"}\NormalTok{, }\StringTok{"pink"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

The same function can also be used to use HEX codes for specifying colours:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p12 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{scale_color_manual}\NormalTok{(}\DataTypeTok{values =} \KeywordTok{c}\NormalTok{(}\StringTok{"#8dd3c7"}\NormalTok{, }\StringTok{"#ffffb3"}\NormalTok{, }\StringTok{"#bebada"}\NormalTok{,}
                                \StringTok{"#fb8072"}\NormalTok{, }\StringTok{"#80b1d3"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p11 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p11"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{p12 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p12"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p1112-1.pdf}
\caption{\label{fig:chap05-fig-p1112}Colours can also be specified using words (\texttt{"red"}, \texttt{"green"}, etc.), or HEX codes (\texttt{"\#8dd3c7"}, \texttt{"\#ffffb3"}, etc.).}
\end{figure}

\hypertarget{titles-and-labels}{%
\section{Titles and labels}\label{titles-and-labels}}

\index{plots@\textbf{plots}!titles}
\index{plots@\textbf{plots}!labels}

We've been using the \texttt{labs(tag\ =\ )} function to add tags to plots.
But the \texttt{labs()} function can also be used to modify axis labels, or to add a title, subtitle, or a caption to your plot (Figure \ref{fig:chap05-fig-p13}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p13 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x =} \StringTok{"Gross domestic product per capita"}\NormalTok{,}
       \DataTypeTok{y =} \StringTok{"Life expectancy"}\NormalTok{,}
       \DataTypeTok{title =} \StringTok{"Health and economics"}\NormalTok{,}
       \DataTypeTok{subtitle =} \StringTok{"Gapminder dataset, 2007"}\NormalTok{,}
       \DataTypeTok{caption =} \KeywordTok{Sys.Date}\NormalTok{(),}
       \DataTypeTok{tag =} \StringTok{"p13"}\NormalTok{)}

\NormalTok{p13}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p13-1.pdf}
\caption{\label{fig:chap05-fig-p13}p13: Adding on a title, subtitle, caption using \texttt{labs()}.}
\end{figure}

\hypertarget{annotation}{%
\subsection{Annotation}\label{annotation}}

\index{plots@\textbf{plots}!annotate}

In the previous chapter, we showed how use \texttt{geom\_text()} and \texttt{geom\_label()} to add text elements to a plot.
Using geoms make sense when the values are based on data and variables mapped in \texttt{aes()}.
They are efficient for including multiple pieces of text or labels on your data.
For `hand' annotating a plot, the \texttt{annotate()} function makes more sense, as you can quickly insert the type, location and label of your annotation (Figure \ref{fig:chap05-fig-p141516}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p14 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{,}
           \DataTypeTok{x =} \DecValTok{25000}\NormalTok{,}
           \DataTypeTok{y =} \DecValTok{50}\NormalTok{,}
           \DataTypeTok{label =} \StringTok{"No points here!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p15 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"label"}\NormalTok{,}
           \DataTypeTok{x =} \DecValTok{25000}\NormalTok{,}
           \DataTypeTok{y =} \DecValTok{50}\NormalTok{,}
           \DataTypeTok{label =} \StringTok{"No points here!"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p16 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"label"}\NormalTok{,}
           \DataTypeTok{x =} \DecValTok{25000}\NormalTok{, }
           \DataTypeTok{y =} \DecValTok{50}\NormalTok{,}
           \DataTypeTok{label =} \StringTok{"No points here!"}\NormalTok{, }
           \DataTypeTok{hjust =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p14 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p14"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{(p15 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p15"}\NormalTok{))}\OperatorTok{/}\StringTok{ }\NormalTok{(p16 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p16"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p141516-1.pdf}
\caption{\label{fig:chap05-fig-p141516}p14: \texttt{annotate("text",\ ...)} to quickly add a text on your plot. p15: \texttt{annotate("label")} is similar but draws a box around your text (making it a label). p16: Using \texttt{hjust} to control the horizontal justification of the annotation.}
\end{figure}

\texttt{hjust} stands for horizontal justification. Its default value is 0.5 (see how the label was centred at 25,000 - our chosen x location), 0 means the label goes to the right from 25,000, 1 would make it end at 25,000.

\hypertarget{annotation-with-a-superscript-and-a-variable}{%
\subsection{Annotation with a superscript and a variable}\label{annotation-with-a-superscript-and-a-variable}}

\index{plots@\textbf{plots}!superscript}

This is an advanced example on how to annotate your plot with something that has a superscipt and is based on a single value read in from a variable (Figure \ref{fig:chap05-fig-p17}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# a value we made up for this example}
\CommentTok{# a real analysis would get it from the linear model object}
\NormalTok{fit_glance <-}\StringTok{ }\KeywordTok{tibble}\NormalTok{(}\DataTypeTok{r.squared =} \FloatTok{0.7693465}\NormalTok{)}


\NormalTok{plot_rsquared <-}\StringTok{ }\KeywordTok{paste0}\NormalTok{(}
  \StringTok{"R^2 == "}\NormalTok{,}
\NormalTok{  fit_glance}\OperatorTok{$}\NormalTok{r.squared }\OperatorTok{%>%}\StringTok{ }\KeywordTok{round}\NormalTok{(}\DecValTok{2}\NormalTok{))}


\NormalTok{p17 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{annotate}\NormalTok{(}\StringTok{"text"}\NormalTok{,}
           \DataTypeTok{x =} \DecValTok{25000}\NormalTok{, }
           \DataTypeTok{y =} \DecValTok{50}\NormalTok{,}
           \DataTypeTok{label =}\NormalTok{ plot_rsquared, }\DataTypeTok{parse =} \OtherTok{TRUE}\NormalTok{,}
           \DataTypeTok{hjust =} \DecValTok{0}\NormalTok{)}

\NormalTok{p17 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p17"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p17-1.pdf}
\caption{\label{fig:chap05-fig-p17}p17: Using a superscript in your plot annotation.}
\end{figure}

\hypertarget{overall-look---theme}{%
\section{\texorpdfstring{Overall look - \texttt{theme()}}{Overall look - theme()}}\label{overall-look---theme}}

And finally, everything else on a plot - from font to background to the space between facets, can be changed using the \texttt{theme()} function.
As you saw in the previous chapter, in addition to its default grey background, \texttt{ggplot2} also comes with a few built-in themes, namely, \texttt{theme\_bw()} or \texttt{theme\_classic()}.
These produce good looking plots that may already be publication ready.
But if we do decide to tweak them, then the main \texttt{theme()} arguments we use are \texttt{axis.text}, \texttt{axis.title}, and \texttt{legend.position}.\footnote{To see a full list of possible arguments to \texttt{theme()}, navigate to it in the Help tab or find its online documentation at \url{https://ggplot2.tidyverse.org/}.}
Note that all of these go inside the \texttt{theme()}, and that the \texttt{axis.text} and \texttt{axis.title} arguments are usually followed by \texttt{=\ element\_text()} as shown in the examples below.

\hypertarget{text-size}{%
\subsection{Text size}\label{text-size}}

\index{plots@\textbf{plots}!text size}

The way the \texttt{axis.text} and \texttt{axis.title} arguments of \texttt{theme()} work is that if you specify \texttt{.x} or \texttt{.y} it gets applied on that axis alone.
But not specifying these, applies the change on both.
Both the \texttt{angle} and \texttt{vjust} (vertical justification) options can be useful if your axis text doesn't fit well and overlaps.
It doesn't usually make sense to change the colour of the font to anything other than \texttt{"black"}, we are using green and red here to indicate which parts of the plot get changed with each line (Figure \ref{fig:chap05-fig-p18}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p18 <-}\StringTok{  }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{axis.text.y =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"green"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{14}\NormalTok{),}
        \DataTypeTok{axis.text.x =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"red"}\NormalTok{,  }\DataTypeTok{angle =} \DecValTok{45}\NormalTok{, }\DataTypeTok{vjust =} \FloatTok{0.5}\NormalTok{),}
        \DataTypeTok{axis.title  =} \KeywordTok{element_text}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"blue"}\NormalTok{, }\DataTypeTok{size =} \DecValTok{16}\NormalTok{)}
\NormalTok{        )}

\NormalTok{p18 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p18"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p18-1.pdf}
\caption{\label{fig:chap05-fig-p18}p18: Using \texttt{axis.text} and \texttt{axis.title} within \texttt{theme()} to tweak the appearance of your plot, including font size and angle. Coloured font is used to indicate which part of the code was used to change each element.}
\end{figure}

\hypertarget{legend-position}{%
\subsection{Legend position}\label{legend-position}}

\index{plots@\textbf{plots}!legend}

The position of the legend can be changed using the \texttt{legend.position} argument within \texttt{theme()}. It can be positioned using the following words: \texttt{"right",\ "left",\ "top",\ "bottom"}.
Or to remove the legend completely, use \texttt{"none"}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p19 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Alternatively, we can use relative coordinates (0--1) to give the legend a relative x-y location (Figure \ref{fig:chap05-fig-p1920}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p20 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position      =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{), }\CommentTok{#bottom-right corner}
        \DataTypeTok{legend.justification =} \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{)) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p19 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p19"}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{p20 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p20"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p1920-1.pdf}
\caption{\label{fig:chap05-fig-p1920}p19: Setting \texttt{theme(legend.position\ =\ "none")} removes it. p20: Relative coordinates such as \texttt{theme(legend.position\ =\ c(1,0)} can by used to place the legend within the plot area.}
\end{figure}

Further \texttt{theme(legend.)} options can be used to change the size, background, spacing, etc., of the legend.
However, for modifying the content of the legend, you'll have to use the \texttt{guides()} function.
Again, \texttt{ggplot()}'s defaults are very good, and we rarely need to go into this much tweaking using both the \texttt{theme()} and \texttt{guides()} functions. But it is good to know what is possible.

For example, this is how to change the number of columns within the legend (Figure \ref{fig:chap05-fig-p21}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p21 <-}\StringTok{ }\NormalTok{p0 }\OperatorTok{+}
\StringTok{  }\KeywordTok{guides}\NormalTok{(}\DataTypeTok{colour =} \KeywordTok{guide_legend}\NormalTok{(}\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"top"}\NormalTok{) }\CommentTok{# moving to the top optional}

\NormalTok{p21 }\OperatorTok{+}\StringTok{ }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{tag =} \StringTok{"p21"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{05_fine_tuning_plots_files/figure-latex/chap05-fig-p21-1.pdf}
\caption{\label{fig:chap05-fig-p21}p21: Changing the number of columns within a legend.}
\end{figure}

\hypertarget{saving-your-plot}{%
\section{Saving your plot}\label{saving-your-plot}}

\index{plots@\textbf{plots}!saving}

In Chapters \ref{chap12-h1} and \ref{chap13-h1} we'll show you how to export descriptive text, figures, and tables directly from R to Word/PDF/HTML using the power of R Markdown.
The \texttt{ggsave()} function, however, can be used to save a single plot into a variety of formats, namely \texttt{"pdf"} or \texttt{"png"}:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggsave}\NormalTok{(p0, }\DataTypeTok{file =} \StringTok{"my_saved_plot.pdf"}\NormalTok{, }\DataTypeTok{width =} \DecValTok{5}\NormalTok{, }\DataTypeTok{height =} \DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

If you omit the first argument - the plot object - and call, e.g., \texttt{ggsave(file\ =\ "plot.png)} it will just save the last plot that got printed.

Text size tip: playing around with the width and height options (they're in inches) can be a convenient way to increase or decrease the relative size of the text on the plot.
Look at the relative font sizes of the two versions of the \texttt{ggsave()} call, one 5x4, the other one 10x8 (Figure \ref{fig:chap05-fig-ggsave}):

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ggsave}\NormalTok{(p0, }\DataTypeTok{file =} \StringTok{"my_saved_plot_larger.pdf"}\NormalTok{, }\DataTypeTok{width =} \DecValTok{10}\NormalTok{, }\DataTypeTok{height =} \DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\includegraphics[width=1\linewidth]{images/chapter05/healthyr_ggsave} \caption{Experimenting with the width and height options within `ggsave()` can be used to quickly change how big or small some of the text on your plot looks.}\label{fig:chap05-fig-ggsave}
\end{figure}

\hypertarget{part-data-analysis}{%
\part{Data analysis}\label{part-data-analysis}}

In the second part of this book, we focus specifically on the business of data analysis, that is, formulating clear questions and seeking to answer them using available datasets.

Again, we emphasise the importance of understanding the underlying data through visualisation, rather than relying on statistical tests or, heaven forbid, the \emph{p}-value alone.

There are five chapters.
Testing for continuous outcome variables (6) leads naturally into linear regression (7).
We would expect the majority of actual analysis done by readers to be using the methods in chapter 7 rather than 6.
Similarly, testing for categorical outcome variables (8) leads naturally to logistic regression (9), where we would expect the majority of work to focus.

Chapters 6 and 8 however do provide helpful reminders of how to prepare data for these analyses and shouldn't be skipped.
time-to-event data (10) introduces survival analysis and includes sections on the manipulation of dates.

\hypertarget{chap06-h1}{%
\chapter{Working with continuous outcome variables}\label{chap06-h1}}

\index{continuous data@\textbf{continuous data}}

\begin{quote}
Continuous data can be measured.\\
Categorical data can be counted.
\end{quote}

\hypertarget{continuous-data}{%
\section{Continuous data}\label{continuous-data}}

Continuous data is everywhere in healthcare.
From physiological measures in patients such as systolic blood pressure or pulmonary function tests, through to population measures like life expectancy or disease incidence, the analysis of continuous outcome measures is common and important.

Our goal in most health data questions, is to draw a conclusion on a comparison between groups.
For instance, understanding differences in life expectancy between the year 2002 and 2007 is more useful than simply describing the average life expectancy across all of time.

The basis for comparisons between continuous measures is the \emph{distribution} of the data.
That word, as many which have a statistical flavour, brings on the sweats in many people.
It needn't.
By distribution, we are simply referring to the shape of the data.

\hypertarget{the-question}{%
\section{The Question}\label{the-question}}

The examples in this chapter all use the data introduced previously from the amazing \href{https://www.gapminder.org/}{Gapminder project}.
We will start by looking at the life expectancy of populations over time and in different geographical regions.

\hypertarget{chap06-h2-check}{%
\section{Get and check the data}\label{chap06-h2-check}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Load packages}
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}
\KeywordTok{library}\NormalTok{(gapminder)}

\CommentTok{# Create object gapdata from object gapminder}
\NormalTok{gapdata <-}\StringTok{ }\NormalTok{gapminder}
\end{Highlighting}
\end{Shaded}

It is vital that datasets be carefully inspected when first read (for help reading data into R see \ref{chap02-h2-reading-data-into-r}).
The three functions below provide a clear summary, allowing errors or miscoding to be quickly identified.
It is particularly important to ensure that any missing data is identified (see Chapter \ref{chap11-h1}).
If you don't do this you will regret it!
There are many times when an analysis has got to a relatively advanced stage before the researcher was hit by the realisation that the dataset was far from complete.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(gapdata) }\CommentTok{# each variable as line, variable type, first values}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 1,704
## Columns: 6
## $ country   <fct> Afghanistan, Afghanistan, Afghanistan, Afghanistan, Afgha...
## $ continent <fct> Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asia, Asi...
## $ year      <int> 1952, 1957, 1962, 1967, 1972, 1977, 1982, 1987, 1992, 199...
## $ lifeExp   <dbl> 28.801, 30.332, 31.997, 34.020, 36.088, 38.438, 39.854, 4...
## $ pop       <int> 8425333, 9240934, 10267083, 11537966, 13079460, 14880372,...
## $ gdpPercap <dbl> 779.4453, 820.8530, 853.1007, 836.1971, 739.9811, 786.113...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{missing_glimpse}\NormalTok{(gapdata) }\CommentTok{# missing data for each variable}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##               label var_type    n missing_n missing_percent
## country     country    <fct> 1704         0             0.0
## continent continent    <fct> 1704         0             0.0
## year           year    <int> 1704         0             0.0
## lifeExp     lifeExp    <dbl> 1704         0             0.0
## pop             pop    <int> 1704         0             0.0
## gdpPercap gdpPercap    <dbl> 1704         0             0.0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{ff_glimpse}\NormalTok{(gapdata) }\CommentTok{# summary statistics for each variable}
\end{Highlighting}
\end{Shaded}

\index{functions@\textbf{functions}!glimpse}
\index{functions@\textbf{functions}!missing\_glimpse}
\index{functions@\textbf{functions}!ff\_glimpse}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-5}Gapminder dataset, ff\_glimpse: continuous.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}llrrrr}
\toprule
label & var\_type & n & missing\_n & mean & sd & median\\
\midrule
year & <int> & 1704 & 0 & 1979.5 & 17.3 & 1979.5\\
lifeExp & <dbl> & 1704 & 0 & 59.5 & 12.9 & 60.7\\
pop & <int> & 1704 & 0 & 29601212.3 & 106157896.7 & 7023595.5\\
\addlinespace
gdpPercap & <dbl> & 1704 & 0 & 7215.3 & 9857.5 & 3531.8\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-6}Gapminder dataset, ff\_glimpse: categorical.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lllrr>{\raggedleft\arraybackslash}p{3cm}>{\raggedleft\arraybackslash}p{3cm}}
\toprule
label & var\_type & n & missing\_n & levels\_n & levels & levels\_count\\
\midrule
country & <fct> & 1704 & 0 & 142 & - & -\\
continent & <fct> & 1704 & 0 & 5 & "Africa", "Americas", "Asia", "Europe", "Oceania" & 624, 300, 396, 360, 24\\
\bottomrule
\end{tabular}}
\end{table}

As can be seen, there are 6 variables, 4 are continuous and 2 are categorical. The categorical variables are already identified as \texttt{factors}. There are no missing data. Note that by default, the maximum number of factor levels shown is give, which is why 142 country names are not printed. This can be adjusted using \texttt{ff\_glimpse(gapdata,\ levels\_cut\ =\ 142)}

\hypertarget{plot-the-data-1}{%
\section{Plot the data}\label{plot-the-data-1}}

We will start by comparing life expectancy between the 5 continents of the world in two different years.
Always plot your data first.
Never skip this step!
We are particularly interested in the distribution.
There's that word again.
The shape of the data.
Is it normal?
Is it skewed?
Does it differ between regions and years?

There are three useful plots which can help here:

\begin{itemize}
\tightlist
\item
  Histograms: examine shape of data and compare groups;
\item
  Q-Q plots: are data normally distributed?
\item
  Box-plots: identify outliers, compare shape and groups.
\end{itemize}

\hypertarget{chap06-h3-hist-plot}{%
\subsection{Histogram}\label{chap06-h3-hist-plot}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2002}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{       }\CommentTok{# remember aes()}
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{20}\NormalTok{) }\OperatorTok{+}\StringTok{      }\CommentTok{# histogram with 20 bars}
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(year }\OperatorTok{~}\StringTok{ }\NormalTok{continent)     }\CommentTok{# optional: add scales="free"                                 }
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/chap06-fig-hist-life-year-1.pdf}
\caption{\label{fig:chap06-fig-hist-life-year}Histogram: Country life expectancy by continent and year.}
\end{figure}

What can we see?
That life expectancy in Africa is lower than in other regions.
That we have little data for Oceania given there are only two countries included, Australia and New Zealand.
That Africa and Asia have greater variability in life expectancy by country than in the Americas or Europe.
That the data follow a reasonably normal shape, with Africa 2002 a little right skewed.

\hypertarget{chap06-h3-qq-plot}{%
\subsection{Quantile-quantile (Q-Q) plot}\label{chap06-h3-qq-plot}}

Quantile-quantile sounds more complicated than it really is.
It is a graphical method for comparing the distribution (think shape) of our own data to a theoretical distribution, such as the normal distribution.
In this context, quantiles are just cut points which divide our data into bins each containing the same number of observations.
For example, if we have the life expectancy for 100 countries, then quartiles (note the quar-) for life expectancy are the three ages which split the observations into 4 groups each containing 25 countries.
A Q-Q plot simply plots the quantiles for our data against the theoretical quantiles for a particular distributions (the default shown below is the normal distribution).
If our data follow that distribution (e.g., normal), then our data points fall on the theoretical straight line.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2002}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{      }\CommentTok{# Q-Q plot requires 'sample'}
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{                          }\CommentTok{# defaults to normal distribution}
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"blue"}\NormalTok{) }\OperatorTok{+}\StringTok{      }\CommentTok{# add the theoretical line}
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(year }\OperatorTok{~}\StringTok{ }\NormalTok{continent)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/chap06-fig-qq-life-year-1.pdf}
\caption{\label{fig:chap06-fig-qq-life-year}Q-Q plot: Country life expectancy by continent and year.}
\end{figure}

\index{plotting@\textbf{plotting}!geom\_qq}
\index{plotting@\textbf{plotting}!geom\_qq\_line}

What can we see?
We are looking to see if the data (dots) follow the straight line which we included in the plot.
These do reasonably, except for Africa which is curved upwards at each end.
This is the right skew we could see on the histograms too.
If your data do not follow a normal distribution, then you should avoid using a \emph{t}-test or ANOVA when comparing groups.
Non-parametric tests are one alternative and are described in Section \ref{chap06-non-param-tests}.

We are frequently asked about the pros and cons of checking for normality using a statistical test, such as the Shapiro-Wilk normality test.
We don't recommend it.
The test is often non-significant when the number of observations is small but the data look skewed, and often significant when the number of observations is high but the data look reasonably normal on inspection of plots.
It is therefore not useful in practice - common sense should prevail.

\hypertarget{boxplot}{%
\subsection{Boxplot}\label{boxplot}}

\index{plotting@\textbf{plotting}!geom\_boxplot}
\index{plotting@\textbf{plotting}!boxplot}

Boxplots are our preferred method for comparing a continuous variable such as life expectancy across a categorical explanatory variable.
For continuous data, box plots are a lot more appropriate than bar plots with error bars (also known as dynamite plots).
We intentionally do not even show you how to make dynamite plots.

The box represents the median (bold horizontal line in the middle) and interquartile range (where 50\% of the data sits).
The lines (whiskers) extend to the lowest and highest values that are still within 1.5 times the interquartile range.
Outliers (anything outwith the whiskers) are represented as points.

The beautiful boxplot thus contains information not only on central tendency (median), but on the variation in the data and the distribution of the data, for instance a skew should be obvious.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2002}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{year)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/chap06-fig-boxplot-life-year-1.pdf}
\caption{\label{fig:chap06-fig-boxplot-life-year}Boxplot: Country life expectancy by continent and year.}
\end{figure}

What can we see?
The median life expectancy is lower in Africa than in any other continent.
The variation in life expectancy is greatest in Africa and smallest in Oceania.
The data in Africa looks skewed, particularly in 2002 - the lines/whiskers are unequal lengths.

\FloatBarrier

We can add further arguments to adjust the plot to our liking.
We particularly encourage the inclusion of the actual data points, here using \texttt{geom\_jitter()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2002}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{factor}\NormalTok{(year), }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =}\NormalTok{ continent)) }\OperatorTok{+}\StringTok{     }\CommentTok{# add colour to boxplots}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\OperatorTok{+}\StringTok{                }\CommentTok{# alpha = transparency}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{ncol =} \DecValTok{5}\NormalTok{) }\OperatorTok{+}\StringTok{       }\CommentTok{# spread by continent}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\OperatorTok{+}\StringTok{         }\CommentTok{# remove legend}
\StringTok{  }\KeywordTok{xlab}\NormalTok{(}\StringTok{"Year"}\NormalTok{) }\OperatorTok{+}\StringTok{                            }\CommentTok{# label x-axis}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"Life expectancy (years)"}\NormalTok{) }\OperatorTok{+}\StringTok{         }\CommentTok{# label y-axis}
\StringTok{  }\KeywordTok{ggtitle}\NormalTok{(}
    \StringTok{"Life expectancy by continent in 2002 v 2007"}\NormalTok{) }\CommentTok{# add title}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/chap06-fig-boxplot-jitter-1.pdf}
\caption{\label{fig:chap06-fig-boxplot-jitter}Boxplot with jitter points: Country life expectancy by continent and year.}
\end{figure}

\hypertarget{compare-the-means-of-two-groups}{%
\section{Compare the means of two groups}\label{compare-the-means-of-two-groups}}

\hypertarget{t-test}{%
\subsection{\texorpdfstring{\emph{t}-test}{t-test}}\label{t-test}}

\index{t-test@\textbf{t-test}}
A \emph{t}-test is used to compare the means of two groups of continuous measurements.
Volumes have been written about this elsewhere, and we won't rehearse it here.

There are a few variations of the \emph{t}-test.
We will use two here.
The most useful in our context is a two-sample test of independent groups.
Repeated-measures data, such as comparing the same countries in different years, can be analysed using a paired \emph{t}-test.

\hypertarget{two-sample-t-tests}{%
\subsection{\texorpdfstring{Two-sample \emph{t}-tests}{Two-sample t-tests}}\label{two-sample-t-tests}}

\index{t-test@\textbf{t-test}!two-sample}

Referring to Figure \ref{fig:chap06-fig-boxplot-life-year}, let's compare life expectancy between Asia and Europe for 2007.
What is imperative is that you decide what sort of difference exists by looking at the boxplot, rather than relying on the \emph{t}-test output.
The median for Europe is clearly higher than in Asia.
The distributions overlap, but it looks likely that Europe has a higher life expectancy than Asia.

By running the two-sample \emph{t}-test here, we make the assumption that life expectancy in each country represents an independent measurement of life expectancy in the continent as a whole.
This isn't quite right if you think about it carefully.

Imagine a room full of enthusiastic geniuses learning R.
They arrived today from various parts of the country.
For reasons known only to you, you want to know whether the average (mean) height of those wearing glasses is different to those with perfect vision.

You measure the height of each person in the room, check them for glasses, and run a two-sample \emph{t}-test.

In statistical terms, your room represents a sample from an underlying population.
Your ability to answer the question accurately relies on a number of factors.
For instance, how many people are in the room?
The more there are, the more certain you can be about the mean measurement in your groups being close to the mean measurement in the overall population.

What is also crucial is that your room is a representative sample of the population.
Are the observations independent, i.e., is each observation unrelated to the others?

If you have inadvertently included a family of bespectacled nerdy giants, not typical of those in the country as a whole, your estimate will be wrong and your conclusion incorrect.

So in our example of countries and continents, you have to assume that the mean life expectancy of each country does not depend on the life expectancies of other countries in the group. In other words, that each measurement is independent.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ttest_data <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{                    }\CommentTok{# save as object ttest_data}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{                   }\CommentTok{# 2007 only}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Asia"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{)) }\CommentTok{# Asia/Europe only}

\NormalTok{ttest_result <-}\StringTok{ }\NormalTok{ttest_data }\OperatorTok{%>%}\StringTok{               }\CommentTok{# example using pipe}
\StringTok{  }\KeywordTok{t.test}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{data =}\NormalTok{ .)      }\CommentTok{# note data = ., see below}
\NormalTok{ttest_result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  lifeExp by continent
## t = -4.6468, df = 41.529, p-value = 3.389e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -9.926525 -3.913705
## sample estimates:
##   mean in group Asia mean in group Europe 
##             70.72848             77.64860
\end{verbatim}

\index{functions@\textbf{functions}!t.test}

The Welch two-sample \emph{t}-test is the most flexible and copes with differences in variance (variability) between groups, as in this example.
The difference in means is provided at the bottom of the output.
The \emph{t}-value, degrees of freedom (df) and \emph{p}-value are all provided.
The \emph{p}-value is 0.00003.

We used the assignment arrow to save the results of the \emph{t}-test into a new object called \texttt{ttest\_result}.
If you look at the Environment tab, you should see \texttt{ttest\_result} there.
If you click on it - to view it - you'll realise that it's not structured like a table, but a list of different pieces of information.
The structure of the \emph{t}-test object is shown in Figure \ref{fig:chap06-ttest-object}.

\begin{figure}
\includegraphics[width=1\linewidth]{images/chapter06/ttest-object} \caption{A list object that is the result of a t-test in R. We will show you ways to access these numbers and how to wrangle them into more familiar tables/tibbles.}\label{fig:chap06-ttest-object}
\end{figure}

The \emph{p}-value, for instance, can be accessed like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ttest_result}\OperatorTok{$}\NormalTok{p.value }\CommentTok{# Extracted element of result object}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 3.38922e-05
\end{verbatim}

The confidence interval of the difference in mean life expectancy between the two continents:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ttest_result}\OperatorTok{$}\NormalTok{conf.int }\CommentTok{# Extracted element of result object}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -9.926525 -3.913705
## attr(,"conf.level")
## [1] 0.95
\end{verbatim}

The \textbf{broom} package provides useful methods for `tidying' common model outputs into a \texttt{tibble}.
So instead of accessing the various bits of information by checking the \texttt{names()} and then using the \texttt{\$} operator, we can use functions called \texttt{tidy()} and \texttt{glance()} to wrangle the statistical output into a table:

\begin{table}

\caption{\label{tab:chap06-tab-ttest}Results of a t-test wrangled into a table using library(broom).}
\centering
\fontsize{9}{11}\selectfont
\begin{tabular}[t]{rrrrrrrr}
\toprule
estimate & estimate1 & estimate2 & statistic & p.value & parameter & conf.low & conf.high\\
\midrule
-6.920115 & 70.72848 & 77.6486 & -4.646757 & 3.39e-05 & 41.52851 & -9.926525 & -3.913705\\
\bottomrule
\end{tabular}
\end{table}

\textbf{Reminder: When the pipe sends data to the wrong place: use \texttt{data\ =\ .} to redirect it}

In the code above, the \texttt{data\ =\ .} bit is necessary because the pipe usually sends data to the beginning of function brackets.
So \texttt{gapdata\ \%\textgreater{}\%\ t.test(lifeExp\ \textasciitilde{}\ continent)} would be equivalent to \texttt{t.test(gapdata,\ lifeExp\ \textasciitilde{}\ continent)}.
However, this is not an order that \texttt{t.test()} will accept.
\texttt{t.test()} wants us to specify the formula first, and then wants the data these variables are present in.
So we have to use the \texttt{.} to tell the pipe to send the data to the second argument of \texttt{t.test()}, not the first.

\hypertarget{ttest_paired}{%
\subsection{\texorpdfstring{Paired \emph{t}-tests}{Paired t-tests}}\label{ttest_paired}}

\index{t-test@\textbf{t-test}!paired}

Consider that we want to compare the difference in life expectancy in Asian countries between 2002 and 2007.
The overall difference is not impressive in the boxplot.

We can plot differences at the country level directly.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{paired_data <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{             }\CommentTok{# save as object paired_data}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{2002}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# 2002 and 2007 only}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Asia"}\NormalTok{)          }\CommentTok{# Asia only}

\NormalTok{paired_data }\OperatorTok{%>%}\StringTok{      }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }
             \DataTypeTok{group =}\NormalTok{ country)) }\OperatorTok{+}\StringTok{       }\CommentTok{# for individual country lines}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/chap06-fig-line-life-asia-1.pdf}
\caption{\label{fig:chap06-fig-line-life-asia}Line plot: Change in life expectancy in Asian countries from 2002 to 2007.}
\end{figure}

\index{plotting@\textbf{plotting}!geom\_line}

What is the difference in life expectancy for each individual country?
We don't usually have to produce this directly, but here is one method.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{paired_table <-}\StringTok{ }\NormalTok{paired_data }\OperatorTok{%>%}\StringTok{        }\CommentTok{# save object paired_data}
\StringTok{  }\KeywordTok{select}\NormalTok{(country, year, lifeExp) }\OperatorTok{%>%}\StringTok{   }\CommentTok{# select vars interest}
\StringTok{  }\KeywordTok{pivot_wider}\NormalTok{(}\DataTypeTok{names_from =}\NormalTok{ year,       }\CommentTok{# put years in columns}
              \DataTypeTok{values_from =}\NormalTok{ lifeExp) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{dlifeExp =} \StringTok{`}\DataTypeTok{2007}\StringTok{`} \OperatorTok{-}\StringTok{ `}\DataTypeTok{2002}\StringTok{`}         \CommentTok{# difference in means}
\NormalTok{  )}
\NormalTok{paired_table}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 33 x 4
##    country          `2002` `2007` dlifeExp
##    <fct>             <dbl>  <dbl>    <dbl>
##  1 Afghanistan        42.1   43.8    1.70 
##  2 Bahrain            74.8   75.6    0.84 
##  3 Bangladesh         62.0   64.1    2.05 
##  4 Cambodia           56.8   59.7    2.97 
##  5 China              72.0   73.0    0.933
##  6 Hong Kong, China   81.5   82.2    0.713
##  7 India              62.9   64.7    1.82 
##  8 Indonesia          68.6   70.6    2.06 
##  9 Iran               69.5   71.0    1.51 
## 10 Iraq               57.0   59.5    2.50 
## # ... with 23 more rows
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Mean of difference in years}
\NormalTok{paired_table }\OperatorTok{%>%}\StringTok{ }\KeywordTok{summarise}\NormalTok{( }\KeywordTok{mean}\NormalTok{(dlifeExp) )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 1
##   `mean(dlifeExp)`
##              <dbl>
## 1             1.49
\end{verbatim}

On average, therefore, there is an increase in life expectancy of 1.5 years in Asian countries between 2002 and 2007.
Let's test whether this number differs from zero with a paired \emph{t}-test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{paired_data }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{t.test}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{paired =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  lifeExp by year
## t = -14.338, df = 32, p-value = 1.758e-15
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -1.706941 -1.282271
## sample estimates:
## mean of the differences 
##               -1.494606
\end{verbatim}

\index{functions@\textbf{functions}!t.test}

The results show a highly significant difference (\emph{p}-value = 0.000000000000002).
The average difference of 1.5 years is highly consistent between countries, as shown on the line plot, and this differs from zero.
It is up to you the investigator to interpret the relevance of the effect size of 1.5 years in reporting the finding.
A highly significant \emph{p}-value does not necessarily mean there is a (clinically) significant change between the two groups (or in this example, two time points).

\hypertarget{what-if-i-run-the-wrong-test}{%
\subsection{What if I run the wrong test?}\label{what-if-i-run-the-wrong-test}}

As an exercise, we can repeat this analysis comparing these data in an unpaired manner.
The resulting (unpaired) \emph{p}-value is 0.460.
Remember, a paired \emph{t}-test of the same data (life expectancies of Asian countries in 2002 and 2007) showed a very different, significant result.
In this case, running an unpaired two-sample \emph{t}-test is just wrong - as the data are indeed paired.
It is important that the investigator really understands the data and the underlying processes/relationships within it.
R will not know and therefore cannot warn you if you run the wrong test.

\hypertarget{compare-the-mean-of-one-group-one-sample-t-tests}{%
\section{\texorpdfstring{Compare the mean of one group: one sample \emph{t}-tests}{Compare the mean of one group: one sample t-tests}}\label{compare-the-mean-of-one-group-one-sample-t-tests}}

\index{t-test@\textbf{t-test}!one-sample}

We can use a \emph{t}-test to determine whether the mean of a distribution is different to a specific value.
For instance, we can test whether the mean life expectancy in each continent was significantly different from 77 years in 2007.
We have included some extra code here to demonstrate how to run multiple tests in one pipe function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{          }\CommentTok{# 2007 only}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{           }\CommentTok{# split by continent}
\StringTok{  }\KeywordTok{do}\NormalTok{(                               }\CommentTok{# dplyr function}
    \KeywordTok{t.test}\NormalTok{(.}\OperatorTok{$}\NormalTok{lifeExp, }\DataTypeTok{mu =} \DecValTok{77}\NormalTok{) }\OperatorTok{%>%}\StringTok{  }\CommentTok{# compare mean to 77 years }
\StringTok{      }\KeywordTok{tidy}\NormalTok{()                        }\CommentTok{# tidy into tibble}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 9
## # Groups:   continent [5]
##   continent estimate statistic  p.value parameter conf.low conf.high method
##   <fct>        <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr> 
## 1 Africa        54.8    -16.6  3.15e-22        51     52.1      57.5 One S~
## 2 Americas      73.6     -3.82 8.32e- 4        24     71.8      75.4 One S~
## 3 Asia          70.7     -4.52 7.88e- 5        32     67.9      73.6 One S~
## 4 Europe        77.6      1.19 2.43e- 1        29     76.5      78.8 One S~
## 5 Oceania       80.7      7.22 8.77e- 2         1     74.2      87.3 One S~
## # ... with 1 more variable: alternative <chr>
\end{verbatim}

The mean life expectancy for Europe and Oceania do not significantly differ from 77, while the others do.
In particular, look at the confidence intervals of the results above (\texttt{conf.low} and \texttt{conf.high} columns) and whether they include or exclude 77.
For instance, Oceania's confidence intervals are especially wide as the dataset only includes two countries.
Therefore, we can't conclude that its value isn't different to 77, but that we don't have enough observations and the estimate is uncertain.
It doesn't make sense to report the results of a statistical test - whether the \emph{p}-value is significant or not - without assessing the confidence intervals.

\hypertarget{interchangeability-of-t-tests}{%
\subsection{\texorpdfstring{Interchangeability of \emph{t}-tests}{Interchangeability of t-tests}}\label{interchangeability-of-t-tests}}

Furthermore, remember how we calculated the table of differences in the paired \emph{t}-test section?
We can use these differences for each pair of observations (country's life expectancy in 2002 and 2007) to run a simple one-sample \emph{t}-test instead:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# note that we're using dlifeExp}
\CommentTok{# so the differences we calculated above}
\KeywordTok{t.test}\NormalTok{(paired_table}\OperatorTok{$}\NormalTok{dlifeExp, }\DataTypeTok{mu =} \DecValTok{0}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  paired_table$dlifeExp
## t = 14.338, df = 32, p-value = 1.758e-15
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  1.282271 1.706941
## sample estimates:
## mean of x 
##  1.494606
\end{verbatim}

Notice how this result is identical to the paired \emph{t}-test.

\hypertarget{compare-the-means-of-more-than-two-groups}{%
\section{Compare the means of more than two groups}\label{compare-the-means-of-more-than-two-groups}}

It may be that our question is set around a hypothesis involving more than two groups.
For example, we may be interested in comparing life expectancy across 3 continents such as the Americas, Europe and Asia.

\hypertarget{plot-the-data-2}{%
\subsection{Plot the data}\label{plot-the-data-2}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }
\StringTok{           }\KeywordTok{c}\NormalTok{(}\StringTok{"Americas"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ continent, }\DataTypeTok{y=}\NormalTok{lifeExp)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-15-1.pdf}
\caption{\label{fig:unnamed-chunk-15}Boxplot: Life expectancy in selected continents for 2007.}
\end{figure}

\hypertarget{anova}{%
\subsection{ANOVA}\label{anova}}

\index{analysis of variance (ANOVA)}

Analysis of variance is a collection of statistical tests which can be used to test the difference in means between two or more groups.

In base R form, it produces an ANOVA table which includes an F-test.
This so-called omnibus test tells you whether there are any differences in the comparison of means of the included groups.
Again, it is important to plot carefully and be clear what question you are asking.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{aov_data <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Americas"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{))}

\NormalTok{fit =}\StringTok{ }\KeywordTok{aov}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{continent, }\DataTypeTok{data =}\NormalTok{ aov_data) }
\KeywordTok{summary}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             Df Sum Sq Mean Sq F value   Pr(>F)    
## continent    2  755.6   377.8   11.63 3.42e-05 ***
## Residuals   85 2760.3    32.5                     
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
\end{verbatim}

\index{functions@\textbf{functions}!aov}

We can conclude from the significant F-test that the mean life expectancy across the three continents is not the same.
This does not mean that all included groups are significantly different from each other.
As above, the output can be neatened up using the \texttt{tidy} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Americas"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{aov}\NormalTok{(lifeExp}\OperatorTok{~}\NormalTok{continent, }\DataTypeTok{data =}\NormalTok{ .) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 6
##   term         df sumsq meansq statistic    p.value
##   <chr>     <dbl> <dbl>  <dbl>     <dbl>      <dbl>
## 1 continent     2  756.  378.       11.6  0.0000342
## 2 Residuals    85 2760.   32.5      NA   NA
\end{verbatim}

\hypertarget{assumptions}{%
\subsection{Assumptions}\label{assumptions}}

As with the normality assumption of the \emph{t}-test (for example, Sections \ref{chap06-h3-hist-plot} and \ref{chap06-h3-qq-plot}), there are assumptions of the ANOVA model.
These assumptions are shared with linear regression and are covered in the next chapter, as linear regression lends itself to illustrate and explain these concepts well.
Suffice to say that diagnostic plots can be produced to check that the assumptions are fulfilled.
\texttt{library(ggfortify)} includes a function called \texttt{autoplot()} that can be used to quickly create diagnostic plots, including the Q-Q plot that we showed before:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggfortify)}
\KeywordTok{autoplot}\NormalTok{(fit)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: `arrange_()` is deprecated as of dplyr 0.7.0.
## Please use `arrange()` instead.
## See vignette('programming') for more help
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.
\end{verbatim}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-18-1.pdf}
\caption{\label{fig:unnamed-chunk-18}Diagnostic plots: ANOVA model of life expectancy by continent for 2007.}
\end{figure}

\FloatBarrier

\hypertarget{multiple-testing}{%
\section{Multiple testing}\label{multiple-testing}}

\index{multiple testing}

\hypertarget{pairwise-testing-and-multiple-comparisons}{%
\subsection{Pairwise testing and multiple comparisons}\label{pairwise-testing-and-multiple-comparisons}}

\index{pairwise testing}

When the F-test is significant, we will often want to determine where the differences lie.
This should of course be obvious from the boxplot you have made.
However, some are fixated on the \emph{p}-value!

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairwise.t.test}\NormalTok{(aov_data}\OperatorTok{$}\NormalTok{lifeExp, aov_data}\OperatorTok{$}\NormalTok{continent, }
                \DataTypeTok{p.adjust.method =} \StringTok{"bonferroni"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  aov_data$lifeExp and aov_data$continent 
## 
##        Americas Asia   
## Asia   0.180    -      
## Europe 0.031    1.9e-05
## 
## P value adjustment method: bonferroni
\end{verbatim}

\index{functions@\textbf{functions}!pairwise.t.test}

A matrix of pairwise \emph{p}-values can be produced using the code above.
Here we can see that there is good evidence of a difference in means between Europe and Asia.

We have to keep in mind that the \emph{p}-value's significance level of 0.05 means we have a 5\% chance of finding a difference in our samples which doesn't exist in the overall population.

Therefore, the more statistical tests performed, the greater the chances of a false positive result.
This is also known as type I error - finding a difference when no difference exists.

There are three approaches to dealing with situations where multiple statistical tests are performed.
The first is not to perform any correction at all.
Some advocate that the best approach is simply to present the results of all the tests that were performed, and let sceptical readers make adjustments for themselves.
This is attractive, but presupposes a sophisticated readership who will take the time to consider the results in their entirety.

The second and classical approach is to control for the so-called family-wise error rate.
The ``Bonferroni'' correction is the most famous and most conservative, where the threshold for significance is lowered in proportion to the number of comparisons made.
For example, if three comparisons are made, the threshold for significance should be lowered to 0.017.
Equivalently, all \emph{p}-values should be multiplied by the number of tests performed (in this case 3).
The adjusted values can then be compared to a threshold of 0.05, as is the case above.
The Bonferroni method is particularly conservative, meaning that type II errors may occur (failure to identify true differences, or false negatives) in favour or minimising type I errors (false positives).
\index{Bonferroni correction}

The third approach controls for something called false-discovery rate.
The development of these methods has been driven in part by the needs of areas of science where many different statistical tests are performed at the same time, for instance, examining the influence of 1000 genes simultaneously.
In these hypothesis-generating settings, a higher tolerance to type I errors may be preferable to missing potential findings through type II errors.
\index{false discovery rate}
You can see in our example, that the \emph{p}-values are lower with the \texttt{fdr} correction than the \texttt{Bonferroni} correction ones.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{pairwise.t.test}\NormalTok{(aov_data}\OperatorTok{$}\NormalTok{lifeExp, aov_data}\OperatorTok{$}\NormalTok{continent, }
                \DataTypeTok{p.adjust.method =} \StringTok{"fdr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  aov_data$lifeExp and aov_data$continent 
## 
##        Americas Asia   
## Asia   0.060    -      
## Europe 0.016    1.9e-05
## 
## P value adjustment method: fdr
\end{verbatim}

\index{functions@\textbf{functions}!pairwise.t.test}

Try not to get too hung up on this.
Be sensible.
Plot the data and look for differences.
Focus on effect size.
For instance, what is the actual difference in life expectancy in years, rather than the \emph{p}-value of a comparison test.
Choose a method which fits with your overall aims.
If you are generating hypotheses which you will proceed to test with other methods, the \texttt{fdr} approach may be preferable.
If you are trying to capture robust effects and want to minimise type II errors, use a family-wise approach.

If your head is spinning at this point, don't worry.
The rest of the book will continuously revisit these and other similar concepts, e.g., ``know your data'', ``be sensible, look at the effect size'', using several different examples and datasets.
So do not feel like you should be able to understand everything immediately.
Furthermore, these things are easier to conceptualise when using your own dataset - especially if that's something you've put your blood, sweat and tears into collecting.

\hypertarget{chap06-non-param-tests}{%
\section{Non-parametric tests}\label{chap06-non-param-tests}}

\index{non-parametric tests@\textbf{non-parametric tests}}

What if your data is a different shape to normal, or the ANOVA assumptions are not fulfilled (see linear regression chapter)?
As always, be sensible and think what drives your measurements in the first place.
Would your data be expected to be normally distributed given the data-generating process?

For instance, if you are examining length of hospital stay it is likely that your data are highly right skewed - most patients are discharged from hospital in a few days while a smaller number stay for a long time.
Is a comparison of means ever going to be the correct approach here?
Perhaps you should consider a time-to-event analysis for instance (see Chapter \ref{chap10-h1}).

If a comparison of means approach is reasonable, but the normality assumption is not fulfilled there are two approaches,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Transform the data;
\item
  Perform non-parametric tests.
\end{enumerate}

\hypertarget{chap06-transform}{%
\subsection{Transforming data}\label{chap06-transform}}

\index{transformations}

Remember, the Welch \emph{t}-test is reasonably robust to divergence from the normality assumption, so small deviations can be safely ignored.

Otherwise, the data can be transformed to another scale to deal with a skew.
A natural \texttt{log} scale is common.

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-21}Transformations that can be applied to skewed data. For left skewed data, subtract all values from a constant greater than the maximum value.}
\centering
\begin{tabular}[t]{lll}
\toprule
Distribution & Transformation & Function\\
\midrule
Moderate right skew (+) & Square-root & sqrt()\\
Substantial right skew (++) & Natural log* & log()\\
Substantial right skew (+++) & Base-10 log* & log10()\\
\bottomrule
\multicolumn{3}{l}{\textit{Note: }}\\
\multicolumn{3}{l}{If data contain zero values, add a small constant to all values.}\\
\end{tabular}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa2002 <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{              }\CommentTok{# save as africa2002}
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2002}\NormalTok{) }\OperatorTok{%>%}\StringTok{             }\CommentTok{# only 2002}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Africa"}\NormalTok{) }\OperatorTok{%>%}\StringTok{    }\CommentTok{# only Africa}
\StringTok{  }\KeywordTok{select}\NormalTok{(country, lifeExp) }\OperatorTok{%>%}\StringTok{         }\CommentTok{# only these variables}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{lifeExp_log =} \KeywordTok{log}\NormalTok{(lifeExp)         }\CommentTok{# log life expectancy}
\NormalTok{  )}
\KeywordTok{head}\NormalTok{(africa2002)                       }\CommentTok{# inspect}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 3
##   country      lifeExp lifeExp_log
##   <fct>          <dbl>       <dbl>
## 1 Algeria         71.0        4.26
## 2 Angola          41.0        3.71
## 3 Benin           54.4        4.00
## 4 Botswana        46.6        3.84
## 5 Burkina Faso    50.6        3.92
## 6 Burundi         47.4        3.86
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa2002 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\CommentTok{# pivot lifeExp and lifeExp_log values to same column (for easy plotting):}
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\KeywordTok{contains}\NormalTok{(}\StringTok{"lifeExp"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ value)) }\OperatorTok{+}\StringTok{             }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{15}\NormalTok{) }\OperatorTok{+}\StringTok{          }\CommentTok{# make histogram}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{name, }\DataTypeTok{scales =} \StringTok{"free"}\NormalTok{)    }\CommentTok{# facet with axes free to vary}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-22-1.pdf}
\caption{\label{fig:unnamed-chunk-22}Histogram: Log transformation of life expectancy for countries in Africa 2002.}
\end{figure}

This has worked well here.
The right skew on the Africa data has been dealt with by the transformation.
A parametric test such as a \emph{t}-test can now be performed.

\hypertarget{non-parametric-test-for-comparing-two-groups}{%
\subsection{Non-parametric test for comparing two groups}\label{non-parametric-test-for-comparing-two-groups}}

\index{non-parametric tests@\textbf{non-parametric tests}!Mann-Whitney U}
\index{non-parametric tests@\textbf{non-parametric tests}!Wilcoxon rank sum}

The Mann-Whitney U test is also called the Wilcoxon rank-sum test and uses a rank-based method to compare two groups (note the Wilcoxon signed-rank test is for paired data).
Rank-based just means ordering your grouped continuous data from smallest to largest value and assigning a rank (1, 2, 3 \ldots) to each measurement.

We can use it to test for a difference in life expectancies for African countries between 1982 and 2007.
Let's do a histogram, Q-Q plot and boxplot first.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa_data <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{                          }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1982}\NormalTok{, }\DecValTok{2007}\NormalTok{)) }\OperatorTok{%>%}\StringTok{      }\CommentTok{# only 1982 and 2007}
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Africa"}\NormalTok{))       }\CommentTok{# only Africa}

\NormalTok{p1 <-}\StringTok{ }\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{                      }\CommentTok{# save plot as p1}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{15}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{year)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{                      }\CommentTok{# save plot as p2}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{          }\CommentTok{# `sample` for Q-Q plot}
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"blue"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{year)}

\NormalTok{p3 <-}\StringTok{ }\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{                      }\CommentTok{# save plot as p3}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{factor}\NormalTok{(year),             }\CommentTok{# try without factor(year) to}
             \DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{               }\CommentTok{# see the difference}
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =} \KeywordTok{factor}\NormalTok{(year))) }\OperatorTok{+}\StringTok{ }\CommentTok{# colour boxplot}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\OperatorTok{+}\StringTok{               }\CommentTok{# add data points}
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)          }\CommentTok{# remove legend}

\KeywordTok{library}\NormalTok{(patchwork)                         }\CommentTok{# great for combining plots}
\NormalTok{p1 }\OperatorTok{/}\StringTok{ }\NormalTok{p2 }\OperatorTok{|}\StringTok{ }\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-23-1.pdf}
\caption{\label{fig:unnamed-chunk-23}Panels plots: Histogram, Q-Q, boxplot for life expectancy in Africa 1992 v 2007.}
\end{figure}

\index{plotting@\textbf{plotting}!patchwork}

The data is a little skewed based on the histograms and Q-Q plots.
The difference between 1982 and 2007 is not particularly striking on the boxplot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{wilcox.test}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Wilcoxon rank sum test with continuity correction
## 
## data:  lifeExp by year
## W = 1130, p-value = 0.1499
## alternative hypothesis: true location shift is not equal to 0
\end{verbatim}

\index{functions@\textbf{functions}!wilcox.test}

\hypertarget{non-parametric-test-for-comparing-more-than-two-groups}{%
\subsection{Non-parametric test for comparing more than two groups}\label{non-parametric-test-for-comparing-more-than-two-groups}}

\index{non-parametric tests@\textbf{non-parametric tests}!!Kruskal-Wallis}

The non-parametric equivalent to ANOVA, is the Kruskal-Wallis test.
It can be used in base R, or via the \textbf{finalfit} package below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Americas"}\NormalTok{, }\StringTok{"Europe"}\NormalTok{, }\StringTok{"Asia"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{kruskal.test}\NormalTok{(lifeExp}\OperatorTok{~}\NormalTok{continent, }\DataTypeTok{data =}\NormalTok{ .) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 4
##   statistic   p.value parameter method                      
##       <dbl>     <dbl>     <int> <chr>                       
## 1      21.6 0.0000202         2 Kruskal-Wallis rank sum test
\end{verbatim}

\index{functions@\textbf{functions}!kruskal.test}

\hypertarget{finalfit-approach}{%
\section{Finalfit approach}\label{finalfit-approach}}

The \textbf{finalfit} package provides an easy to use interface for performing non-parametric hypothesis tests.
Any number of explanatory variables can be tested against a so-called dependent variable.
In this case, this is equivalent to a typical Table 1 in healthcare study.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "year"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"lifeExp"}\NormalTok{, }\StringTok{"pop"}\NormalTok{, }\StringTok{"gdpPercap"}\NormalTok{)}
\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{         }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{year =} \KeywordTok{factor}\NormalTok{(year)}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent, explanatory,}
                     \DataTypeTok{cont =} \StringTok{"median"}\NormalTok{, }\DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note that the \emph{p}-values above have not been corrected for multiple testing.

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-27}Life expectancy, population and GDPperCap in Africa 1982 vs 2007.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
label & levels & 1982 & 2007 & p\\
\midrule
lifeExp & Median (IQR) & 50.8 (11.0) & 52.9 (11.6) & 0.149\\
pop & Median (IQR) & 5668228.5 (8218654.0) & 10093310.5 (16454428.0) & 0.033\\
gdpPercap & Median (IQR) & 1323.7 (1958.9) & 1452.3 (3130.6) & 0.503\\
\bottomrule
\end{tabular}}
\end{table}

\index{functions@\textbf{functions}!summary\_factorlist}

There are many other options available for this function which are covered throughout this book.
For instance,
If you wish to consider only some variables as non-parametric and summarise with a median, then this can be specified using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "year"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"lifeExp"}\NormalTok{, }\StringTok{"pop"}\NormalTok{, }\StringTok{"gdpPercap"}\NormalTok{)}
\NormalTok{africa_data }\OperatorTok{%>%}\StringTok{         }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{year =} \KeywordTok{factor}\NormalTok{(year)}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent, explanatory,}
                     \DataTypeTok{cont_nonpara =}  \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{),         }\CommentTok{# variable 1&3 are non-parametric}
                     \DataTypeTok{cont_range =} \OtherTok{TRUE}\NormalTok{,               }\CommentTok{# lower and upper quartile}
                     \DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{,                        }\CommentTok{# include hypothesis test}
                     \DataTypeTok{p_cont_para =} \StringTok{"t.test"}\NormalTok{,          }\CommentTok{# use t.test/aov for parametric}
                     \DataTypeTok{add_row_totals =} \OtherTok{TRUE}\NormalTok{,           }\CommentTok{# row totals}
                     \DataTypeTok{include_row_missing_col =} \OtherTok{FALSE}\NormalTok{, }\CommentTok{# missing values row totals}
                     \DataTypeTok{add_dependent_label =} \OtherTok{TRUE}\NormalTok{)      }\CommentTok{# dependent label }
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-29}Life expectancy, population and GDPperCap in Africa 1982 vs 2007.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Dependent: year & Total N &   & 1982 & 2007 & p\\
\midrule
lifeExp & 104 & Median (IQR) & 50.8 (45.6 to 56.6) & 52.9 (47.8 to 59.4) & 0.149\\
pop & 104 & Mean (SD) & 9602857.4 (13456243.4) & 17875763.3 (24917726.2) & 0.038\\
gdpPercap & 104 & Median (IQR) & 1323.7 (828.7 to 2787.6) & 1452.3 (863.0 to 3993.5) & 0.503\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{conclusions}{%
\section{Conclusions}\label{conclusions}}

Continuous data is frequently encountered in a healthcare setting.
Liberal use of plotting is required to really understand the underlying data.
Comparisons can be easily made between two or more groups of data, but always remember what you are actually trying to analyse and don't become fixated on the \emph{p}-value.
In the next chapter, we will explore the comparison of two continuous variables together with multivariable models of datasets.

\hypertarget{exercises-1}{%
\section{Exercises}\label{exercises-1}}

\hypertarget{chap06-ex1}{%
\subsection{Exercise}\label{chap06-ex1}}

Make a histogram, Q-Q plot, and a box-plot for the life expectancy for a continent of your choice, but for all years.
Do the data appear normally distributed?

\hypertarget{chap06-ex2}{%
\subsection{Exercise}\label{chap06-ex2}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Select any 2 years in any continent and perform a \emph{t}-test to determine whether mean life expectancy is significantly different.
  Remember to plot your data first.
\item
  Extract only the \emph{p}-value from your \texttt{t.test()} output.
\end{enumerate}

\hypertarget{chap06-ex3}{%
\subsection{Exercise}\label{chap06-ex3}}

In 2007, in which continents did mean life expectancy differ from 70?

\hypertarget{chap06-ex4}{%
\subsection{Exercise}\label{chap06-ex4}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Use ANOVA to determine if the population changed significantly through the 1990s/2000s in individual continents.
\end{enumerate}

\hypertarget{solutions-1}{%
\section{Solutions}\label{solutions-1}}

Solution to Exercise \ref{chap06-ex1}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Make a histogram, Q-Q plot, and a box-plot for the life expectancy}
\CommentTok{## for a continent of your choice, but for all years. }
\CommentTok{## Do the data appear normally distributed?}

\NormalTok{asia_data <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{                          }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Asia"}\NormalTok{))              }

\NormalTok{p1 <-}\StringTok{ }\NormalTok{asia_data }\OperatorTok{%>%}\StringTok{                              }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{15}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{asia_data }\OperatorTok{%>%}\StringTok{                          }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{             }\CommentTok{# sample =  for Q-Q plot}
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"blue"}\NormalTok{)}

\NormalTok{p3 <-}\StringTok{ }\NormalTok{asia_data }\OperatorTok{%>%}\StringTok{                              }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{  }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =} \KeywordTok{factor}\NormalTok{(year))) }\OperatorTok{+}\StringTok{  }\CommentTok{# optional: year as factor}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\OperatorTok{+}\StringTok{                    }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)               }

\KeywordTok{library}\NormalTok{(patchwork)                              }
\NormalTok{p1 }\OperatorTok{/}\StringTok{ }\NormalTok{p2 }\OperatorTok{|}\StringTok{ }\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-30-1.pdf}

Solution to Exercise \ref{chap06-ex2}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Select any 2 years in any continent and perform a *t*-test to }
\CommentTok{## determine whether mean life expectancy is significantly different. }
\CommentTok{## Remember to plot your data first.}

\NormalTok{asia_2years <-}\StringTok{ }\NormalTok{asia_data }\OperatorTok{%>%}\StringTok{   }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\DecValTok{1952}\NormalTok{, }\DecValTok{1972}\NormalTok{)) }

\NormalTok{p1 <-}\StringTok{ }\NormalTok{asia_2years }\OperatorTok{%>%}\StringTok{   }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{(}\DataTypeTok{bins =} \DecValTok{15}\NormalTok{) }\OperatorTok{+}\StringTok{                 }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{year)                          }

\NormalTok{p2 <-}\StringTok{ }\NormalTok{asia_2years }\OperatorTok{%>%}\StringTok{   }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{sample =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{              }
\StringTok{  }\KeywordTok{geom_qq}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_qq_line}\NormalTok{(}\DataTypeTok{colour =} \StringTok{"blue"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{year)                        }

\NormalTok{p3 <-}\StringTok{ }\NormalTok{asia_2years }\OperatorTok{%>%}\StringTok{         }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{factor}\NormalTok{(year), }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{fill =} \KeywordTok{factor}\NormalTok{(year))) }\OperatorTok{+}\StringTok{      }
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.4}\NormalTok{) }\OperatorTok{+}\StringTok{                    }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)               }

\KeywordTok{library}\NormalTok{(patchwork)                              }
\NormalTok{p1 }\OperatorTok{/}\StringTok{ }\NormalTok{p2 }\OperatorTok{|}\StringTok{ }\NormalTok{p3}
\end{Highlighting}
\end{Shaded}

\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-31-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{asia_2years }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{t.test}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Welch Two Sample t-test
## 
## data:  lifeExp by year
## t = -4.7007, df = 63.869, p-value = 1.428e-05
## alternative hypothesis: true difference in means is not equal to 0
## 95 percent confidence interval:
##  -15.681981  -6.327769
## sample estimates:
## mean in group 1952 mean in group 1972 
##           46.31439           57.31927
\end{verbatim}

Solution to Exercise \ref{chap06-ex3}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## In 2007, in which continents did mean life expectancy differ from 70}
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{==}\StringTok{ }\DecValTok{2007}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{do}\NormalTok{(}
    \KeywordTok{t.test}\NormalTok{(.}\OperatorTok{$}\NormalTok{lifeExp, }\DataTypeTok{mu =} \DecValTok{70}\NormalTok{) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{tidy}\NormalTok{()                         }
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 9
## # Groups:   continent [5]
##   continent estimate statistic  p.value parameter conf.low conf.high method
##   <fct>        <dbl>     <dbl>    <dbl>     <dbl>    <dbl>     <dbl> <chr> 
## 1 Africa        54.8   -11.4   1.33e-15        51     52.1      57.5 One S~
## 2 Americas      73.6     4.06  4.50e- 4        24     71.8      75.4 One S~
## 3 Asia          70.7     0.525 6.03e- 1        32     67.9      73.6 One S~
## 4 Europe        77.6    14.1   1.76e-14        29     76.5      78.8 One S~
## 5 Oceania       80.7    20.8   3.06e- 2         1     74.2      87.3 One S~
## # ... with 1 more variable: alternative <chr>
\end{verbatim}

Solution to Exercise \ref{chap06-ex4}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Use Kruskal-Wallis to determine if the mean population changed }
\CommentTok{## significantly through the 1990s/2000s in individual continents. }

\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{>=}\StringTok{ }\DecValTok{1990}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{factor}\NormalTok{(year), }\DataTypeTok{y =}\NormalTok{ pop)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{continent)}
\end{Highlighting}
\end{Shaded}

\includegraphics{06_working_continuous_files/figure-latex/unnamed-chunk-33-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(year }\OperatorTok{>=}\StringTok{ }\DecValTok{1990}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(continent) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{do}\NormalTok{(}
    \KeywordTok{kruskal.test}\NormalTok{(pop }\OperatorTok{~}\StringTok{ }\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{tidy}\NormalTok{()}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 5 x 5
## # Groups:   continent [5]
##   continent statistic p.value parameter method                      
##   <fct>         <dbl>   <dbl>     <int> <chr>                       
## 1 Africa        2.10    0.553         3 Kruskal-Wallis rank sum test
## 2 Americas      0.847   0.838         3 Kruskal-Wallis rank sum test
## 3 Asia          1.57    0.665         3 Kruskal-Wallis rank sum test
## 4 Europe        0.207   0.977         3 Kruskal-Wallis rank sum test
## 5 Oceania       1.67    0.644         3 Kruskal-Wallis rank sum test
\end{verbatim}

\hypertarget{chap07-h1}{%
\chapter{Linear regression}\label{chap07-h1}}

\index{linear regression@\textbf{linear regression}}

\begin{quote}
Smoking is one of the leading causes of statistics.\\
Fletcher Knebel
\end{quote}

\hypertarget{regression}{%
\section{Regression}\label{regression}}

Regression is a method by which we can determine the existence and strength of the relationship between two or more variables.
This can be thought of as drawing lines, ideally straight lines, through data points.

Linear regression is our method of choice for examining continuous outcome variables.
Broadly, there are often two separate goals in regression:

\begin{itemize}
\tightlist
\item
  Prediction: fitting a predictive model to an observed dataset, then using that model to make predictions about an outcome from a new set of explanatory variables;
\item
  Explanation: fit a model to explain the inter-relationships between a set of variables.
\end{itemize}

Figure \ref{fig:chap07-fig-regression} unifies the terms we will use throughout.
A clear scientific question should define our \texttt{explanatory\ variable\ of\ interest} \((x)\), which sometimes gets called an exposure, predictor, or independent variable.
Our outcome of interest will be referred to as the \texttt{dependent} variable or outcome \((y)\); it is sometimes referred to as the response.
In simple linear regression, there is a single explanatory variable and a single dependent variable, and we will sometimes refer to this as \emph{univariable linear regression}.
When there is more than one explanatory variable, we will call this \emph{multivariable regression}.
Avoid the term \emph{multivariate regression}, which means more than one dependent variable.
We don't use this method and we suggest you don't either!

Note that in linear regression, the dependent variable is always continuous; it cannot be a categorical variable.
The explanatory variables can be either continuous or categorical.

\hypertarget{the-question-1}{%
\subsection{The Question (1)}\label{the-question-1}}

We will illustrate our examples of linear regression using a classical question which is important to many of us!
This is the relationship between coffee consumption and blood pressure (and therefore cardiovascular events, such as myocardial infarction and stroke).
There has been a lot of backwards and forwards over the decades about whether coffee is harmful, has no effect, or is in fact beneficial.

Figure \ref{fig:chap07-fig-regression} shows a linear regression example.
Each point is a person.
The explanatory variable is average number of cups of coffee per day \((x)\) and systolic blood pressure is the dependent variable \((y)\).
This next bit is important!
\textbf{These data are made up, fake, randomly generated, fabricated, not real.\footnote{These data are created on the fly by the Shiny apps that are linked and explained in this chapter. This enables you to explore the different concepts using the same variables.
  For example, if you tell the multivariable app that coffee and smoking should be confounded, it will change the underlying dataset to conform.
  You can then investigate the output of the regression model to see how that corresponds to the ``truth'' (that in this case, you control).}}
So please do not alter your coffee habit on the basis of these plots!

\begin{figure}
\centering
\includegraphics{images/chapter07/1_regression_terms.pdf}
\caption{\label{fig:chap07-fig-regression}The anatomy of a regression plot. A - univariable linear regression, B - multivariable linear regression.}
\end{figure}

\hypertarget{chap07-linreg-fit}{%
\subsection{Fitting a regression line}\label{chap07-linreg-fit}}

\index{linear regression@\textbf{linear regression}!fitted line}

Simple linear regression uses the \emph{ordinary least squares} method for fitting.
The details are beyond the scope of this book, but if you want to get out the linear algebra/matrix maths you did in high school, an enjoyable afternoon can be spent proving to yourself how it actually works.

Figure \ref{fig:chap07-fig-residuals} aims to make this easy to understand.
The maths defines a line which best fits the data provided.
For the line to fit best, the distances between it and the observed data should be as small as possible.
The distance from each observed point to the line is called a \emph{residual} - one of those statistical terms that bring on the sweats.
It refers to the residual difference left over after the line is fitted.

You can use the \href{https://argoshare.is.ed.ac.uk/simple_regression}{simple regression Shiny app} to explore the concept.
We want the residuals to be as small as possible.
We can square each residual (to get rid of minuses and make the algebra more convenient) and add them up.
If this number is as small as possible, the line is fitting as best it can.
Or in more formal language, we want to minimise the sum of squared residuals.

The regression apps and example figures in this chapter have been adapted from \url{https://github.com/mwaskom/ShinyApps} and \url{https://github.com/ShinyEd/intro-stats} with permission from Michael Waskom and Mine Çetinkaya-Rundel, thank you to them.

\begin{figure}
\centering
\includegraphics{images/chapter07/2_residuals.pdf}
\caption{\label{fig:chap07-fig-residuals}How a regression line is fitted. A - residuals are the green lines: the distance between each data point and the fitted line. B - the green circle indicates the minimum for these data; its absolute value is not meaningful or comparable with other datasets. Follow the ``simple regression Shiny app'' link to interact with the fitted line. A new sum of squares of residuals (the black cross) is calculated every time you move the line. C - Distribution of the residuals. App and plots adapted from \url{https://github.com/mwaskom/ShinyApps} with permission.}
\end{figure}

\hypertarget{when-the-line-fits-well}{%
\subsection{When the line fits well}\label{when-the-line-fits-well}}

Linear regression modelling has four main assumptions:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Linear relationship between predictors and outcome;
\item
  Independence of residuals;
\item
  Normal distribution of residuals;
\item
  Equal variance of residuals.
  \index{linear regression@\textbf{linear regression}!assumptions}
\end{enumerate}

You can use the \href{https://argoshare.is.ed.ac.uk/simple_regression_diagnostics}{simple regression diagnostics shiny app} to get a handle on these.

Figure \ref{fig:chap07-fig-diags} shows diagnostic plots from the app, which we will run ourselves below Figure \ref{fig:chap07-diags-example}.

\emph{Linear relationship}

A simple scatter plot should show a linear relationship between the explanatory and the dependent variable, as in Figure \ref{fig:chap07-fig-diags}A.
If the data describe a non-linear pattern (Figure \ref{fig:chap07-fig-diags}B), then a straight line is not going to fit it well.
In this situation, an alternative model should be considered, such as including a quadratic (squared, \(x^2\)) term.

\emph{Independence of residuals}

The observations and therefore the residuals should be independent.
This is more commonly a problem in time series data, where observations may be correlated across time with each other (autocorrelation).

\emph{Normal distribution of residuals}

The observations should be normally distributed around the fitted line.
This means that the residuals should show a normal distribution with a mean of zero (Figure \ref{fig:chap07-fig-diags}A).
If the observations are not equally distributed around the line, the histogram of residuals will be skewed and a normal Q-Q plot will show residuals diverging from the straight line (Figure \ref{fig:chap07-fig-diags}B) (see Section \ref{chap06-h3-qq-plot}).

\emph{Equal variance of residuals}

The distance of the observations from the fitted line should be the same on the left side as on the right side.
Look at the fan-shaped data on the simple regression diagnostics Shiny app.
This fan shape can be seen on the residuals vs.~fitted values plot.

Everything we talk about in this chapter is really about making sure that the line you draw through your data points is valid.
It is about ensuring that the regression line is appropriate across the range of the explanatory variable and dependent variable.
It is about understanding the underlying data, rather than relying on a fancy statistical test that gives you a \emph{p}-value.

\begin{figure}
\centering
\includegraphics{images/chapter07/3_diags.pdf}
\caption{\label{fig:chap07-fig-diags}Regression diagnostics. A - this is what a linear fit should look like. B - this is not approriate; a non-linear model should be used instead. App and plots adapted from \url{https://github.com/ShinyEd/intro-stats} with permission.}
\end{figure}

\hypertarget{the-fitted-line-and-the-linear-equation}{%
\subsection{The fitted line and the linear equation}\label{the-fitted-line-and-the-linear-equation}}

We promised to keep the equations to a minimum, but this one is so important it needs to be included.
But it is easy to understand, so fear not.

Figure \ref{fig:chap07-fig-equation} links the fitted line, the linear equation, and the output from R. Some of this will likely be already familiar to you.

Figure \ref{fig:chap07-fig-equation}A shows a scatter plot with fitted lines from a multivariable linear regression model.
The plot is taken from the \href{https://argoshare.is.ed.ac.uk/multi_regression/}{multivariable regression Shiny app}.
Remember, these data are simulated and are not real.
This app will really help you understand different regression models; more on this below.
The app allows us to specify ``the truth'' with the sliders on the left-hand side.
For instance, we can set the \(intercept=1\), meaning that when \(x=0\), the value of the dependent variable, \(y=1\).

Our model has a continuous explanatory variable of interest (average coffee consumption) and a further categorical variable (smoking).
In the example the truth is set as \(intercept=1\), \(\beta_1=1\) (true effect of coffee on blood pressure, slope of line), and \(\beta_2=2\) (true effect of smoking on blood pressure).
The points on the plot are simulated and include random noise.

What does \(\beta_1=1\) mean?
This is the slope of the line.
So for each unit on the x-axis, there is a corresponding increase of one unit on the y-axis.

Figure \ref{fig:chap07-fig-equation}B shows the default output in R for this linear regression model.
Look carefully and make sure you are clear how the fitted lines, the linear equation, and the R output fit together.
In this example, the random sample from our true population specified above shows \(intercept=0.67\), \(\beta_1=1.00\) (coffee), and \(\beta_2=2.48\) (smoking).
A \emph{p}-value is provided (\(Pr(> \left| t \right|)\)), which is the result of a null hypothesis significance test for the slope of the line being equal to zero.

\begin{figure}
\centering
\includegraphics{images/chapter07/4_equation.pdf}
\caption{\label{fig:chap07-fig-equation}Linking the fitted line, regression equation and R output.}
\end{figure}

\hypertarget{effect-modification}{%
\subsection{Effect modification}\label{effect-modification}}

\index{linear regression@\textbf{linear regression}!effect modification}
\index{effect modification}

Effect modification occurs when the size of the effect of the explanatory variable of interest (exposure) on the outcome (dependent variable) differs depending on the level of a third variable.
Said another way, this is a situation in which an explanatory variable differentially (positively or negatively) modifies the observed effect of another explanatory variable on the outcome.

Figure \ref{fig:chap07-fig-dags} shows three potential causal pathways using examples from the \href{https://argoshare.is.ed.ac.uk/multi_regression/}{multivariable regression Shiny app}.

In the first, smoking is not associated with the outcome (blood pressure) or our explanatory variable of interest (coffee consumption).

In the second, smoking is associated with elevated blood pressure, but not with coffee consumption.
This is an example of effect modification.

In the third, smoking is associated with elevated blood pressure and with coffee consumption.
This is an example of confounding.

\begin{figure}
\centering
\includegraphics{images/chapter07/5_dags.pdf}
\caption{\label{fig:chap07-fig-dags}Causal pathways, effect modification and confounding.}
\end{figure}

\emph{Additive vs.~multiplicative effect modification (interaction)}
\index{linear regression@\textbf{linear regression}!interactions}
\index{interaction terms}

The name for these concepts differs depending on the field you work in.
Effect modification can be additive or multiplicative.
We can refer to multiplicative effect modification as ``a statistical interaction''.

Figure \ref{fig:chap07-fig-types} should make it clear exactly how these work.
The data have been set up to include an interaction between the two explanatory variables.
What does this mean?

\begin{itemize}
\tightlist
\item
  \(intercept=1\): the blood pressure (\(\hat{y}\)) for non-smokers who drink no coffee (all \(x=0\));
\item
  \(\beta_1=1\) (\texttt{coffee}): the additional blood pressure for each cup of coffee drunk by non-smokers (slope of the line when \(x_2=0\));
\item
  \(\beta_2=1\) (\texttt{smoking}): the difference in blood pressure between non-smokers and smokers who drink no coffee (\(x_1=0\));
\item
  \(\beta_3=1\) (\texttt{coffee:smoking} interaction): the blood pressure (\(\hat{y}\)) in addition to \(\beta_1\) and \(\beta_2\), for each cup of coffee drunk by smokers (\(x_2=1)\).
\end{itemize}

You may have to read that a couple of times in combination with looking at Figure \ref{fig:chap07-fig-types}.

With the additive model, the fitted lines for non-smoking vs smoking must always be parallel (the statistical term is `constrained').
Look at the equation in Figure \ref{fig:chap07-fig-types}B and convince yourself that the lines can never be anything other than parallel.

A statistical interaction (or multiplicative effect modification) is a situation where the effect of an explanatory variable on the outcome is modified in non-additive manner.
In other words using our example, the fitted lines are no longer constrained to be parallel.

If we had not checked for an interaction effect, we would have inadequately described the true relationship between these three variables.

What does this mean back in reality?
Well it may be biologically plausible for the effect of smoking on blood pressure to increase multiplicatively due to a chemical interaction between cigarette smoke and caffeine, for example.

Note, we are just trying to find a model which best describes the underlying data.
All models are approximations of reality.

\begin{figure}
\centering
\includegraphics{images/chapter07/6_types.pdf}
\caption{\label{fig:chap07-fig-types}Multivariable linear regression with additive and multiplicative effect modification.}
\end{figure}

\hypertarget{r-squared-and-model-fit}{%
\subsection{R-squared and model fit}\label{r-squared-and-model-fit}}

\index{linear regression@\textbf{linear regression}!r-squared}

Figure \ref{fig:chap07-fig-types} includes a further metric from the R output: \texttt{Adjusted\ R-squared}.

R-squared is another measure of how close the data are to the fitted line.
It is also known as the \emph{coefficient of determination} and represents the proportion of the dependent variable which is explained by the explanatory variable(s).
So 0.0 indicates that none of the variability in the dependent is explained by the explanatory (no relationship between data points and fitted line) and 1.0 indicates that the model explains all of the variability in the dependent (fitted line follows data points exactly).

R provides the \texttt{R-squared} and the \texttt{Adjusted\ R-squared}.
The adjusted R-squared includes a penalty the more explanatory variables are included in the model.
So if the model includes variables which do not contribute to the description of the dependent variable, the adjusted R-squared will be lower.

Looking again at Figure \ref{fig:chap07-fig-types}, in A, a simple model of coffee alone does not describe the data well (adjusted R-squared 0.38).
Adding smoking to the model improves the fit as can be seen by the fitted lines (0.87).
But a true interaction exists in the actual data.
By including this interaction in the model, the fit is very good indeed (0.93).

\hypertarget{chap07-confound}{%
\subsection{Confounding}\label{chap07-confound}}

\index{linear regression@\textbf{linear regression}!confounding}
\index{confounding}

The last important concept to mention here is confounding.
Confounding is a situation in which the association between an explanatory variable (exposure) and outcome (dependent variable) is distorted by the presence of another explanatory variable.

In our example, confounding exists if there is an association between smoking and blood pressure AND smoking and coffee consumption (Figure \ref{fig:chap07-fig-dags}C).
This exists if smokers drink more coffee than non-smokers.

Figure \ref{fig:chap07-fig-confounding} shows this really clearly.
The underlying data have now been altered so that those who drink more than two cups of coffee per day also smoke and those who drink fewer than two cups per day do not smoke.
A true effect of smoking on blood pressure is simulated, but there is NO effect of coffee on blood pressure in this example.

If we only fit blood pressure by coffee consumption (Figure \ref{fig:chap07-fig-confounding}A), then we may mistakenly conclude a relationship between coffee consumption and blood pressure.
But this does not exist, because the ground truth we have set is that no relationship exists between coffee and blood pressure.
We are actually looking at the effect of smoking on blood pressure, which is confounding the effect of coffee on blood pressure.

If we include the confounder in the model by adding smoking, the true relationship becomes apparent.
Two parallel flat lines indicating no effect of coffee on blood pressure, but a relationship between smoking and blood pressure.
This procedure is referred to as controlling for or adjusting for confounders.

\begin{figure}
\centering
\includegraphics{images/chapter07/7_confounding.pdf}
\caption{\label{fig:chap07-fig-confounding}Multivariable linear regression with confounding of coffee drinking by smoking.}
\end{figure}

\hypertarget{summary}{%
\subsection{Summary}\label{summary}}

We have intentionally spent some time going through the principles and applications of linear regression because it is so important.
A firm grasp of these concepts leads to an understanding of other regression procedures, such as logistic regression and Cox Proportional Hazards regression.

We will now perform all this ourselves in R using the gapminder dataset which you are familiar with from preceding chapters.

\hypertarget{fitting-simple-models}{%
\section{Fitting simple models}\label{fitting-simple-models}}

\hypertarget{the-question-2}{%
\subsection{The Question (2)}\label{the-question-2}}

We are interested in modelling the change in life expectancy for different countries over the past 60 years.

\hypertarget{get-the-data-2}{%
\subsection{Get the data}\label{get-the-data-2}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(gapminder) }\CommentTok{# dataset}
\KeywordTok{library}\NormalTok{(finalfit)}
\KeywordTok{library}\NormalTok{(broom)}

\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\NormalTok{gapdata <-}\StringTok{ }\NormalTok{gapminder}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-the-data}{%
\subsection{Check the data}\label{check-the-data}}

Always check a new dataset, as described in Section \ref{chap06-h2-check}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(gapdata) }\CommentTok{# each variable as line, variable type, first values}
\KeywordTok{missing_glimpse}\NormalTok{(gapdata) }\CommentTok{# missing data for each variable}
\KeywordTok{ff_glimpse}\NormalTok{(gapdata) }\CommentTok{# summary statistics for each variable}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot-the-data-3}{%
\subsection{Plot the data}\label{plot-the-data-3}}

Let's plot the life expectancies in European countries over the past 60 years, focussing on the UK and Turkey.
We can add in simple best fit lines using \texttt{geom\_smooth()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{                        }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{) }\OperatorTok{%>%}\StringTok{    }\CommentTok{# Europe only}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp)) }\OperatorTok{+}\StringTok{ }\CommentTok{# lifeExp~year  }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{                       }\CommentTok{# plot points}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{country) }\OperatorTok{+}\StringTok{              }\CommentTok{# facet by country}
\StringTok{  }\KeywordTok{scale_x_continuous}\NormalTok{(}
    \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{1960}\NormalTok{, }\DecValTok{2000}\NormalTok{)) }\OperatorTok{+}\StringTok{          }\CommentTok{# adjust x-axis }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{)           }\CommentTok{# add regression lines}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-4-1.pdf}
\caption{\label{fig:unnamed-chunk-4}Scatter plots with linear regression lines: Life expectancy by year in European countries.}
\end{figure}

\hypertarget{simple-linear-regression}{%
\subsection{Simple linear regression}\label{simple-linear-regression}}

\index{functions@\textbf{functions}!lm}

As you can see, \texttt{ggplot()} is very happy to run and plot linear regression models for us.
While this is convenient for a quick look, we usually want to build, run, and explore these models ourselves.
We can then investigate the intercepts and the slope coefficients (linear increase per year):

First let's plot two countries to compare, Turkey and United Kingdom:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Turkey"}\NormalTok{, }\StringTok{"United Kingdom"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-5-1.pdf}
\caption{\label{fig:unnamed-chunk-5}Scatter plot: Life expectancy by year: Turkey and United Kingdom}
\end{figure}

The two non-parallel lines may make you think of what has been discussed above (Figure \ref{fig:chap07-fig-types}).

First, let's model the two countries separately.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# United Kingdom}
\NormalTok{fit_uk <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "United Kingdom"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp}\OperatorTok{~}\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .)}

\NormalTok{fit_uk }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ year, data = .)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.69767 -0.31962  0.06642  0.36601  0.68165 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -2.942e+02  1.464e+01  -20.10 2.05e-09 ***
## year         1.860e-01  7.394e-03   25.15 2.26e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4421 on 10 degrees of freedom
## Multiple R-squared:  0.9844, Adjusted R-squared:  0.9829 
## F-statistic: 632.5 on 1 and 10 DF,  p-value: 2.262e-10
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Turkey}
\NormalTok{fit_turkey <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "Turkey"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp}\OperatorTok{~}\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .)}

\NormalTok{fit_turkey }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ year, data = .)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -2.4373 -0.3457  0.1653  0.9008  1.1033 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(>|t|)    
## (Intercept) -924.58989   37.97715  -24.35 3.12e-10 ***
## year           0.49724    0.01918   25.92 1.68e-10 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 1.147 on 10 degrees of freedom
## Multiple R-squared:  0.9853, Adjusted R-squared:  0.9839 
## F-statistic: 671.8 on 1 and 10 DF,  p-value: 1.681e-10
\end{verbatim}

\emph{Accessing the coefficients of linear regression}
\index{linear regression@\textbf{linear regression}!coefficients}

A simple linear regression model will return two coefficients - the intercept and the slope (the second returned value).
Compare these coefficients to the \texttt{summary()} output above to see where these numbers came from.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_uk}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  (Intercept)         year 
## -294.1965876    0.1859657
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_turkey}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  (Intercept)         year 
## -924.5898865    0.4972399
\end{verbatim}

The slopes make sense - the results of the linear regression say that in the UK, life expectancy increases by 0.186 every year, whereas in Turkey the change is 0.497 per year.
The reason the intercepts are negative, however, may be less obvious.

In this example, the intercept is telling us that life expectancy at year 0 in the United Kingdom (some 2000 years ago) was -294 years.
While this is mathematically correct (based on the data we have), it obviously makes no sense in practice.
It is important to think about the range over which you can extend your model predictions, and where they just become unrealistic.

To make the intercepts meaningful, we will add in a new column called \texttt{year\_from1952} and re-run \texttt{fit\_uk} and \texttt{fit\_turkey} using \texttt{year\_from1952} instead of \texttt{year}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{year_from1952 =}\NormalTok{ year }\OperatorTok{-}\StringTok{ }\DecValTok{1952}\NormalTok{)}

\NormalTok{fit_uk <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "United Kingdom"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year_from1952, }\DataTypeTok{data =}\NormalTok{ .)}

\NormalTok{fit_turkey <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{==}\StringTok{ "Turkey"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year_from1952, }\DataTypeTok{data =}\NormalTok{ .)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_uk}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   (Intercept) year_from1952 
##    68.8085256     0.1859657
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_turkey}\OperatorTok{$}\NormalTok{coefficients}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   (Intercept) year_from1952 
##    46.0223205     0.4972399
\end{verbatim}

Now, the updated results tell us that in year 1952, the life expectancy in the United Kingdom was 69 years.
Note that the slopes do not change.
There was nothing wrong with the original model and the results were correct, the intercept was just not meaningful.

\emph{Accessing all model information \texttt{tidy()} and \texttt{glance()}}
\index{functions@\textbf{functions}!tidy}
\index{functions@\textbf{functions}!glance}

In the fit\_uk and fit\_turkey examples above, we were using \texttt{fit\_uk\ \%\textgreater{}\%\ summary()} to get R to print out a summary of the model.
This summary is not, however, in a rectangular shape so we can't easily access the values or put them in a table/use as information on plot labels.

We use the \texttt{tidy()} function from \texttt{library(broom)} to get the variable(s) and specific values in a nice tibble:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_uk }\OperatorTok{%>%}\StringTok{ }\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 5
##   term          estimate std.error statistic  p.value
##   <chr>            <dbl>     <dbl>     <dbl>    <dbl>
## 1 (Intercept)     68.8     0.240       287.  6.58e-21
## 2 year_from1952    0.186   0.00739      25.1 2.26e-10
\end{verbatim}

In the \texttt{tidy()} output, the column \texttt{estimate} includes both the intercepts and slopes.

And we use the \texttt{glance()} function to get overall model statistics (mostly the r.squared).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_uk }\OperatorTok{%>%}\StringTok{ }\KeywordTok{glance}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.984         0.983 0.442      633. 2.26e-10     1  -6.14  18.3  19.7
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

\hypertarget{multivariable-linear-regression}{%
\subsection{Multivariable linear regression}\label{multivariable-linear-regression}}

\index{linear regression@\textbf{linear regression}!multivariable}

Multivariable linear regression includes more than one explanatory variable.
There are a few ways to include more variables, depending on whether they should share the intercept and how they interact:

Simple linear regression (exactly one predictor variable):

\texttt{myfit\ =\ lm(lifeExp\ \textasciitilde{}\ year,\ data\ =\ gapdata)}

Multivariable linear regression (additive):

\texttt{myfit\ =\ lm(lifeExp\ \textasciitilde{}\ year\ +\ country,\ data\ =\ gapdata)}

Multivariable linear regression (interaction):

\texttt{myfit\ =\ lm(lifeExp\ \textasciitilde{}\ year\ *\ country,\ data\ =\ gapdata)}

This equivalent to:
\texttt{myfit\ =\ lm(lifeExp\ \textasciitilde{}\ year\ +\ country\ +\ year:country,\ data\ =\ gapdata)}

These examples of multivariable regression include two variables: \texttt{year} and \texttt{country}, but we could include more by adding them with \texttt{+}, it does not just have to be two.

We will now create three different linear regression models to further illustrate the difference between a simple model, additive model, and multiplicative model.

\emph{Model 1: year only}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# UK and Turkey dataset}
\NormalTok{gapdata_UK_T <-}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Turkey"}\NormalTok{, }\StringTok{"United Kingdom"}\NormalTok{))}

\NormalTok{fit_both1 <-}\StringTok{ }\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year_from1952, }\DataTypeTok{data =}\NormalTok{ .)}
\NormalTok{fit_both1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ year_from1952, data = .)
## 
## Coefficients:
##   (Intercept)  year_from1952  
##       57.4154         0.3416
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_lifeExp =} \KeywordTok{predict}\NormalTok{(fit_both1)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ pred_lifeExp))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-15-1.pdf}
\caption{\label{fig:unnamed-chunk-15}Scatter and line plot. Life expectancy in Turkey and the UK - univariable fit.}
\end{figure}

By fitting to year only (\texttt{lifeExp\ \textasciitilde{}\ year\_from1952}), the model ignores country.
This gives us a fitted line which is the average of life expectancy in the UK and Turkey.
This may be desirable, depending on the question.
But here we want to best describe the data.

\textbf{How we made the plot and what does \texttt{predict()} do?}
Previously, we were using \texttt{geom\_smooth(method\ =\ "lm")} to conveniently add linear regression lines on a scatter plot.
When a scatter plot includes categorical value (e.g., the points are coloured by a variable), the regression lines \texttt{geom\_smooth()} draws are multiplicative.
That is great, and almost always exactly what we want.
Here, however, to illustrate the difference between the different models, we will have to use the \texttt{predict()} model and \texttt{geom\_line()} to have full control over the plotted regression lines.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_lifeExp =} \KeywordTok{predict}\NormalTok{(fit_both1)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(country, year, lifeExp, pred_lifeExp) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{group_by}\NormalTok{(country) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{6}\NormalTok{, }\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 6 x 4
## # Groups:   country [2]
##   country         year lifeExp pred_lifeExp
##   <fct>          <int>   <dbl>        <dbl>
## 1 Turkey          1952    43.6         57.4
## 2 Turkey          1977    59.5         66.0
## 3 Turkey          2007    71.8         76.2
## 4 United Kingdom  1952    69.2         57.4
## 5 United Kingdom  1977    72.8         66.0
## 6 United Kingdom  2007    79.4         76.2
\end{verbatim}

Note how the \texttt{slice()} function recognises group\_by() and in this case shows us the 1st, 6th, and 12th observation within each group.

\emph{Model 2: year + country}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_both2 <-}\StringTok{ }\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year_from1952 }\OperatorTok{+}\StringTok{ }\NormalTok{country, }\DataTypeTok{data =}\NormalTok{ .)}
\NormalTok{fit_both2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ year_from1952 + country, data = .)
## 
## Coefficients:
##           (Intercept)          year_from1952  countryUnited Kingdom  
##               50.3023                 0.3416                14.2262
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_lifeExp =} \KeywordTok{predict}\NormalTok{(fit_both2)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ pred_lifeExp, }\DataTypeTok{colour =}\NormalTok{ country))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-17-1.pdf}
\caption{\label{fig:unnamed-chunk-17}Scatter and line plot. Life expectancy in Turkey and the UK - multivariable additive fit.}
\end{figure}

This is better, by including country in the model, we now have fitted lines more closely representing the data.
However, the lines are constrained to be parallel.
This is the additive model that was discussed above.
We need to include an interaction term to allow the effect of year on life expectancy to vary by country in a non-additive manner.

\emph{Model 3: year * country}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit_both3 <-}\StringTok{ }\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(lifeExp }\OperatorTok{~}\StringTok{ }\NormalTok{year_from1952 }\OperatorTok{*}\StringTok{ }\NormalTok{country, }\DataTypeTok{data =}\NormalTok{ .)}
\NormalTok{fit_both3}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## lm(formula = lifeExp ~ year_from1952 * country, data = .)
## 
## Coefficients:
##                         (Intercept)                        year_from1952  
##                             46.0223                               0.4972  
##               countryUnited Kingdom  year_from1952:countryUnited Kingdom  
##                             22.7862                              -0.3113
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata_UK_T }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{pred_lifeExp =} \KeywordTok{predict}\NormalTok{(fit_both3)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ lifeExp, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ pred_lifeExp, }\DataTypeTok{colour =}\NormalTok{ country))}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-18-1.pdf}
\caption{\label{fig:unnamed-chunk-18}Scatter and line plot. Life expectancy in Turkey and the UK - multivariable multiplicative fit.}
\end{figure}

This fits the data much better than the previous two models.
You can check the R-squared using \texttt{summary(fit\_both3)}.

\textbf{Advanced tip:} we can apply a function on multiple objects at once by putting them in a \texttt{list()} and using a \texttt{map\_()} function from the \textbf{purrr} package. \texttt{library(purrr)} gets installed and loaded with \texttt{library(tidyverse)}, but it is outside the scope of this book. Do look it up once you get a little more comfortable with using R, and realise that you are starting to do similar things over and over again. For example, this code:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mod_stats1 <-}\StringTok{ }\KeywordTok{glance}\NormalTok{(fit_both1)}
\NormalTok{mod_stats2 <-}\StringTok{ }\KeywordTok{glance}\NormalTok{(fit_both2)}
\NormalTok{mod_stats3 <-}\StringTok{ }\KeywordTok{glance}\NormalTok{(fit_both3)}

\KeywordTok{bind_rows}\NormalTok{(mod_stats1, mod_stats2, mod_stats3)}
\end{Highlighting}
\end{Shaded}

returns the exact same thing as:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{list}\NormalTok{(fit_both1, fit_both2, fit_both3) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{map_df}\NormalTok{(glance)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 3 x 12
##   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC
##       <dbl>         <dbl> <dbl>     <dbl>    <dbl> <dbl>  <dbl> <dbl> <dbl>
## 1     0.373         0.344 7.98       13.1 1.53e- 3     1  -82.9 172.  175. 
## 2     0.916         0.908 2.99      114.  5.18e-12     2  -58.8 126.  130. 
## 3     0.993         0.992 0.869     980.  7.30e-22     3  -28.5  67.0  72.9
## # ... with 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>
\end{verbatim}

What happens here is that \texttt{map\_df()} applies a function on each object in the list it gets passed, and returns a df (data frame). In this case, the function is \texttt{glance()} (note that once inside \texttt{map\_df()}, \texttt{glance} does not have its own brackets.

\hypertarget{check-assumptions}{%
\subsection{Check assumptions}\label{check-assumptions}}

The assumptions of linear regression can be checked with diagnostic plots, either by passing the fitted object (\texttt{lm()} output) to base R \texttt{plot()}, or by using the more convenient function below.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggfortify)}
\KeywordTok{autoplot}\NormalTok{(fit_both3)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: `arrange_()` is deprecated as of dplyr 0.7.0.
## Please use `arrange()` instead.
## See vignette('programming') for more help
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.
\end{verbatim}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/chap07-diags-example-1.pdf}
\caption{\label{fig:chap07-diags-example}Diagnostic plots. Life expectancy in Turkey and the UK - multivariable multiplicative model.}
\end{figure}

\hypertarget{fitting-more-complex-models}{%
\section{Fitting more complex models}\label{fitting-more-complex-models}}

\hypertarget{the-question-3}{%
\subsection{The Question (3)}\label{the-question-3}}

Finally in this section, we are going to fit a more complex linear regression model.
Here, we will discuss variable selection and introduce the Akaike Information Criterion (AIC).

We will introduce a new dataset: The Western Collaborative Group Study.
This classic dataset includes observations of 3154 healthy young men aged 39-59 from the San Francisco area who were assessed for their personality type.
It aimed to capture the occurrence of coronary heart disease over the following 8.5 years.

We will use it, however, to explore the relationship between systolic blood pressure (\texttt{sbp}) and personality type (\texttt{personality\_2L}), accounting for potential confounders such as weight (\texttt{weight}).
Now this is just for fun - don't write in!

The study was designed to look at cardiovascular events as the outcome, not blood pressure.
But it is convenient to use blood pressure as a continuous outcome from this dataset, even if that was not the intention of the study.

The included personality types are A: aggressive and B: passive.

\hypertarget{model-fitting-principles}{%
\subsection{Model fitting principles}\label{model-fitting-principles}}

\index{linear regression@\textbf{linear regression}!model fitting principles}

We suggest building statistical models on the basis of the following six pragmatic principles:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  As few explanatory variables should be used as possible (parsimony);
\item
  Explanatory variables associated with the outcome variable in previous studies should be accounted for;
\item
  Demographic variables should be included in model exploration;
\item
  Population stratification should be incorporated if available;
\item
  Interactions should be checked and included if influential;
\item
  Final model selection should be performed using a ``criterion-based approach''
\end{enumerate}

\begin{itemize}
\tightlist
\item
  minimise the Akaike information criterion (AIC)
\item
  maximise the adjusted R-squared value.
\end{itemize}

This is not the law, but it probably should be.
These principles are sensible as we will discuss through the rest of this book.
We strongly suggest you do not use automated methods of variable selection.
These are often ``forward selection'' or ``backward elimination'' methods for including or excluding particular variables on the basis of a statistical property.

In certain settings, these approaches may be found to work.
However, they create an artificial distance between you and the problem you are working on.
They give you a false sense of certainty that the model you have created is in some sense valid.
And quite frequently, they will just get it wrong.

Alternatively, you can follow the six principles above.

A variable may have previously been shown to strongly predict an outcome (think smoking and risk of cancer).
This should give you good reason to consider it in your model.
But perhaps you think that previous studies were incorrect, or that the variable is confounded by another.
All this is fair, but it will be expected that this new knowledge is clearly demonstrated by you, so do not omit these variables before you start.

There are some variables that are so commonly associated with particular outcomes in healthcare that they should almost always be included at the start.
Age, sex, social class, and co-morbidity for instance are commonly associated with survival.
These need to be assessed before you start looking at your explanatory variable of interest.

Furthermore, patients are often clustered by a particular grouping variable, such as treating hospital.
There will be commonalities between these patients that may not be fully explained by your observed variables.
To estimate the coefficients of your variables of interest most accurately, clustering should be accounted for in the analysis.

As demonstrated above, the purpose of the model is to provide a best fit approximation of the underlying data.
Effect modification and interactions commonly exist in health datasets, and should be incorporated if present.

Finally, we want to assess how well our models fit the data with `model checking'.
The effect of adding or removing one variable to the coefficients of the other variables in the model is very important, and will be discussed later.
Measures of goodness-of-fit such as the \texttt{AIC}, can also be of great use when deciding which model choice is most valid.

\hypertarget{chap07-aic}{%
\subsection{AIC}\label{chap07-aic}}

\index{linear regression@\textbf{linear regression}!AIC}
\index{AIC}

The Akaike Information Criterion (AIC) is an alternative goodness-of-fit measure.
In that sense, it is similar to the R-squared, but it has a different statistical basis.
It is useful because it can be used to help guide the best fit in generalised linear models such as logistic regression (see Chapter \ref{chap09-h1}).
It is based on the likelihood but is also penalised for the number of variables present in the model.
We aim to have as small an AIC as possible.
The value of the number itself has no inherent meaning, but it is used to compare different models of the same data.

\hypertarget{get-the-data-3}{%
\subsection{Get the data}\label{get-the-data-3}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wcgsdata <-}\StringTok{ }\NormalTok{finalfit}\OperatorTok{::}\NormalTok{wcgs }\CommentTok{#press F1 here for details}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-the-data-1}{%
\subsection{Check the data}\label{check-the-data-1}}

As always, when you receive a new dataset, carefully check that it does not contain errors.

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-23}WCGS data, ff\_glimpse: continuous.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lrrrrr}
\toprule
label & var\_type & n & missing\_n & mean & sd & median\\
\midrule
Subject ID & <int> & 3154 & 0 & 10477.9 & 5877.4 & 11405.5\\
Age (years) & <int> & 3154 & 0 & 46.3 & 5.5 & 45.0\\
Height (inches) & <int> & 3154 & 0 & 69.8 & 2.5 & 70.0\\
\addlinespace
Weight (pounds) & <int> & 3154 & 0 & 170.0 & 21.1 & 170.0\\
Systolic BP (mmHg) & <int> & 3154 & 0 & 128.6 & 15.1 & 126.0\\
Diastolic BP (mmHg) & <int> & 3154 & 0 & 82.0 & 9.7 & 80.0\\
\addlinespace
Cholesterol (mg/100 ml) & <int> & 3142 & 12 & 226.4 & 43.4 & 223.0\\
Cigarettes/day & <int> & 3154 & 0 & 11.6 & 14.5 & 0.0\\
Time to CHD event & <int> & 3154 & 0 & 2683.9 & 666.5 & 2942.0\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h][!h]

\caption{\label{tab:unnamed-chunk-23}WCGS data, ff\_glimpse: categorical.}
\centering
\resizebox{\linewidth}{!}{
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr>{\raggedleft\arraybackslash}p{3cm}>{\raggedleft\arraybackslash}p{3cm}}
\toprule
label & var\_type & n & missing\_n & levels\_n & levels & levels\_count\\
\midrule
Personality type & <fct> & 3154 & 0 & 4 & "A1", "A2", "B3", "B4" & 264, 1325, 1216, 349\\
Personality type & <fct> & 3154 & 0 & 2 & "B", "A" & 1565, 1589\\
Smoking & <fct> & 3154 & 0 & 2 & "Non-smoker", "Smoker" & 1652, 1502\\
\addlinespace
Corneal arcus & <fct> & 3152 & 2 & 2 & "No", "Yes", "(Missing)" & 2211, 941, 2\\
CHD event & <fct> & 3154 & 0 & 2 & "No", "Yes" & 2897, 257\\
Type CHD & <fct> & 3154 & 0 & 4 & "No", "MI\_SD", "Silent\_MI", "Angina" & 2897, 135, 71, 51\\
\bottomrule
\end{tabular}}}
\end{table}

\hypertarget{plot-the-data-4}{%
\subsection{Plot the data}\label{plot-the-data-4}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wcgsdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{y =}\NormalTok{ sbp, }\DataTypeTok{x =}\NormalTok{ weight,}
             \DataTypeTok{colour =}\NormalTok{ personality_2L)) }\OperatorTok{+}\StringTok{   }\CommentTok{# Personality type}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{alpha =} \FloatTok{0.2}\NormalTok{) }\OperatorTok{+}\StringTok{                }\CommentTok{# Add transparency}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/chap07-fig-bp-personality_type-1.pdf}
\caption{(\#fig:chap07-fig-bp-personality\_type)Scatter and line plot. Systolic blood pressure by weight and personality type.}
\end{figure}

From Figure @ref(fig:chap07-fig-bp-personality\_type), we can see that there is a weak relationship between weight and blood pressure.

In addition, there is really no meaningful effect of personality type on blood pressure.
This is really important because, as you will see below, we are about to ``find'' some highly statistically significant effects in a model.

\hypertarget{linear-regression-with-finalfit}{%
\subsection{Linear regression with finalfit}\label{linear-regression-with-finalfit}}

\index{linear regression@\textbf{linear regression}!finalfit}

\textbf{finalfit} is our own package and provides a convenient set of functions for fitting regression models with results presented in final tables.

There are a host of features with example code at the \href{https://finalfit.org}{finalfit website}.

Here we will use the all-in-one \texttt{finalfit()} function, which takes a dependent variable and one or more explanatory variables.
The appropriate regression for the dependent variable is performed, from a choice of linear, logistic, and Cox Proportional Hazards regression models.
Summary statistics, together with a univariable and a multivariable regression analysis are produced in a final results table.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory <-}\StringTok{ "personality_2L"}
\NormalTok{fit_sbp1 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\index{functions@\textbf{functions}!finalfit}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-25}Linear regression: Systolic blood pressure by personality type.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lrrrr}
\toprule
Dependent: Systolic BP (mmHg) &   & unit & value & Coefficient (univariable) & Coefficient (multivariable)\\
\midrule
Personality type & B & Mean (sd) & 127.5 (14.4) & - & -\\
 & A & Mean (sd) & 129.8 (15.7) & 2.32 (1.26 to 3.37, p<0.001) & 2.32 (1.26 to 3.37, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-25}Model metrics: Systolic blood pressure by personality type.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 3154, Number in model = 3154, Missing = 0, Log-likelihood = -13031.39, AIC = 26068.8, R-squared = 0.0059, Adjusted R-squared = 0.0056\\
\bottomrule
\end{tabular}}
\end{table}

Let's look first at our explanatory variable of interest, personality type.
When a factor is entered into a regression model, the default is to compare each level of the factor with a ``reference level''.
What you choose as the reference level can be easily changed (see Section \ref{chap08-h2-fct-relevel}.
Alternative methods are available (sometimes called \emph{contrasts}), but the default method is likely to be what you want almost all the time.
Note this is sometimes referred to as creating a ``dummy variable''.

It can be seen that the mean blood pressure for type A is higher than for type B.
As there is only one variable, the univariable and multivariable analyses are the same (the multivariable column can be removed if desired by including \texttt{select(-5)\ \#5th\ column} in the piped function).

Although the difference is numerically quite small (2.3 mmHg), it is statistically significant partly because of the large number of patients in the study.
The optional \texttt{metrics\ =\ TRUE} output gives us the number of rows (in this case, subjects) included in the model.
This is important as frequently people forget that in standard regression models, missing data from any variable results in the entire row being excluded from the analysis (see Chapter \ref{chap11-h1}).

Note the \texttt{AIC} and \texttt{Adjusted\ R-squared} results.
The adjusted R-squared is very low - the model only explains only 0.6\% of the variation in systolic blood pressure.
This is to be expected, given our scatter plot above.

Let's now include subject weight, which we have hypothesised may influence blood pressure.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"weight"}\NormalTok{, }\StringTok{"personality_2L"}\NormalTok{)}
\NormalTok{fit_sbp2 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:chap07-tab-bp-personality-weight}Multivariable linear regression: Systolic blood pressure by personality type and weight.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lrrrr}
\toprule
Dependent: Systolic BP (mmHg) &   & unit & value & Coefficient (univariable) & Coefficient (multivariable)\\
\midrule
Weight (pounds) & [78.0,320.0] & Mean (sd) & 128.6 (15.1) & 0.18 (0.16 to 0.21, p<0.001) & 0.18 (0.16 to 0.20, p<0.001)\\
Personality type & B & Mean (sd) & 127.5 (14.4) & - & -\\
 & A & Mean (sd) & 129.8 (15.7) & 2.32 (1.26 to 3.37, p<0.001) & 1.99 (0.97 to 3.01, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:chap07-tab-bp-personality-weight}Multivariable linear regression metrics: Systolic blood pressure by personality type and weight.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 3154, Number in model = 3154, Missing = 0, Log-likelihood = -12928.82, AIC = 25865.6, R-squared = 0.068, Adjusted R-squared = 0.068\\
\bottomrule
\end{tabular}}
\end{table}

The output shows us the range for weight (78 to 320 pounds) and the mean (standard deviation) systolic blood pressure for the whole cohort.

The coefficient with 95\% confidence interval is provided by default.
This is interpreted as: for each pound increase in weight, there is on average a corresponding increase of 0.18 mmHg in systolic blood pressure.

Note the difference in the interpretation of continuous and categorical variables in the regression model output (Figure \ref{tab:chap07-tab-bp-personality-weight}).

The adjusted R-squared is now higher - the personality and weight together explain 6.8\% of the variation in blood pressure.

The AIC is also slightly lower meaning this new model better fits the data.

There is little change in the size of the coefficients for each variable in the multivariable analysis, meaning that they are reasonably independent.
As an exercise, check the distribution of weight by personality type using a boxplot.

Let's now add in other variables that may influence systolic blood pressure.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"weight"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                \StringTok{"height"}\NormalTok{, }\StringTok{"chol"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{) }
\NormalTok{fit_sbp3 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-28}Multivariable linear regression: Systolic blood pressure by available explanatory variables.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lrrrr}
\toprule
Dependent: Systolic BP (mmHg) &   & unit & value & Coefficient (univariable) & Coefficient (multivariable)\\
\midrule
Personality type & B & Mean (sd) & 127.5 (14.4) & - & -\\
 & A & Mean (sd) & 129.8 (15.7) & 2.32 (1.26 to 3.37, p<0.001) & 1.44 (0.44 to 2.43, p=0.005)\\
Weight (pounds) & [78.0,320.0] & Mean (sd) & 128.6 (15.1) & 0.18 (0.16 to 0.21, p<0.001) & 0.24 (0.21 to 0.27, p<0.001)\\
\addlinespace
Age (years) & [39.0,59.0] & Mean (sd) & 128.6 (15.1) & 0.45 (0.36 to 0.55, p<0.001) & 0.43 (0.33 to 0.52, p<0.001)\\
Height (inches) & [60.0,78.0] & Mean (sd) & 128.6 (15.1) & 0.11 (-0.10 to 0.32, p=0.302) & -0.84 (-1.08 to -0.61, p<0.001)\\
Cholesterol (mg/100 ml) & [103.0,645.0] & Mean (sd) & 128.6 (15.1) & 0.04 (0.03 to 0.05, p<0.001) & 0.03 (0.02 to 0.04, p<0.001)\\
\addlinespace
Smoking & Non-smoker & Mean (sd) & 128.6 (15.6) & - & -\\
 & Smoker & Mean (sd) & 128.7 (14.6) & 0.08 (-0.98 to 1.14, p=0.883) & 0.95 (-0.05 to 1.96, p=0.063)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-28}Model metrics: Systolic blood pressure by available explanatory variables.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 3154, Number in model = 3142, Missing = 12, Log-likelihood = -12772.04, AIC = 25560.1, R-squared = 0.12, Adjusted R-squared = 0.12\\
\bottomrule
\end{tabular}}
\end{table}

Age, height, serum cholesterol, and smoking status have been added.
Some of the variation explained by personality type has been taken up by these new variables - personality is now associated with an average change of blood pressure of 1.4 mmHg.

The adjusted R-squared now tells us that 12\% of the variation in blood pressure is explained by the model, which is an improvement.

Look out for variables that show large changes in effect size or a change in the direction of effect when going from a univariable to multivariable model.
This means that the other variables in the model are having a large effect on this variable and the cause of this should be explored.
For instance, in this example the effect of height changes size and direction.
This is because of the close association between weight and height.
For instance, it may be more sensible to work with body mass index (\(weight / height^2\)) rather than the two separate variables.

In general, variables that are highly correlated with each other should be treated carefully in regression analysis.
This is called collinearity and can lead to unstable estimates of coefficients.
For more on this, see Section \ref{chap09-h2-multicollinearity}.

Let's create a new variable called \texttt{bmi}, note the conversion from pounds and inches to kg and m:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{wcgsdata <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{bmi =}\NormalTok{ ((weight}\OperatorTok{*}\FloatTok{0.4536}\NormalTok{) }\OperatorTok{/}\StringTok{ }\NormalTok{(height}\OperatorTok{*}\FloatTok{0.0254}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"BMI"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Weight and height can now be replaced in the model with BMI.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"bmi"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                \StringTok{"chol"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{) }

\NormalTok{fit_sbp4 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-31}Multivariable linear regression: Systolic blood pressure using BMI.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lrrrr}
\toprule
Dependent: Systolic BP (mmHg) &   & unit & value & Coefficient (univariable) & Coefficient (multivariable)\\
\midrule
Personality type & B & Mean (sd) & 127.5 (14.4) & - & -\\
 & A & Mean (sd) & 129.8 (15.7) & 2.32 (1.26 to 3.37, p<0.001) & 1.51 (0.51 to 2.50, p=0.003)\\
BMI & [11.2,39.0] & Mean (sd) & 128.6 (15.1) & 1.69 (1.50 to 1.89, p<0.001) & 1.65 (1.46 to 1.85, p<0.001)\\
\addlinespace
Age (years) & [39.0,59.0] & Mean (sd) & 128.6 (15.1) & 0.45 (0.36 to 0.55, p<0.001) & 0.41 (0.32 to 0.50, p<0.001)\\
Cholesterol (mg/100 ml) & [103.0,645.0] & Mean (sd) & 128.6 (15.1) & 0.04 (0.03 to 0.05, p<0.001) & 0.03 (0.02 to 0.04, p<0.001)\\
Smoking & Non-smoker & Mean (sd) & 128.6 (15.6) & - & -\\
\addlinespace
 & Smoker & Mean (sd) & 128.7 (14.6) & 0.08 (-0.98 to 1.14, p=0.883) & 0.98 (-0.03 to 1.98, p=0.057)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-31}Model metrics: Systolic blood pressure using BMI.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 3154, Number in model = 3142, Missing = 12, Log-likelihood = -12775.03, AIC = 25564.1, R-squared = 0.12, Adjusted R-squared = 0.12\\
\bottomrule
\end{tabular}}
\end{table}

On the principle of parsimony, we may want to remove variables which are not contributing much to the model.
For instance, let's compare models with and without the inclusion of smoking.
This can be easily done using the \texttt{finalfit} \texttt{explanatory\_multi} option.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory       <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"bmi"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                      \StringTok{"chol"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{) }
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"bmi"}\NormalTok{, }\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                      \StringTok{"chol"}\NormalTok{) }
\NormalTok{fit_sbp5 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }
\NormalTok{           explanatory_multi, }
           \DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-33}Multivariable linear regression: Systolic blood pressure by available explanatory variables and reduced model.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{4cm}lr>{\raggedleft\arraybackslash}p{4cm}>{\raggedleft\arraybackslash}p{4cm}>{\raggedleft\arraybackslash}p{4cm}r}
\toprule
Dependent: Systolic BP (mmHg) &   & unit & value & Coefficient (univariable) & Coefficient (multivariable) & Coefficient (multivariable reduced)\\
\midrule
Personality type & B & Mean (sd) & 127.5 (14.4) & - & - & -\\
 & A & Mean (sd) & 129.8 (15.7) & 2.32 (1.26 to 3.37, p<0.001) & 1.51 (0.51 to 2.50, p=0.003) & 1.56 (0.57 to 2.56, p=0.002)\\
BMI & [11.2,39.0] & Mean (sd) & 128.6 (15.1) & 1.69 (1.50 to 1.89, p<0.001) & 1.65 (1.46 to 1.85, p<0.001) & 1.62 (1.43 to 1.82, p<0.001)\\
\addlinespace
Age (years) & [39.0,59.0] & Mean (sd) & 128.6 (15.1) & 0.45 (0.36 to 0.55, p<0.001) & 0.41 (0.32 to 0.50, p<0.001) & 0.41 (0.32 to 0.50, p<0.001)\\
Cholesterol (mg/100 ml) & [103.0,645.0] & Mean (sd) & 128.6 (15.1) & 0.04 (0.03 to 0.05, p<0.001) & 0.03 (0.02 to 0.04, p<0.001) & 0.03 (0.02 to 0.04, p<0.001)\\
Smoking & Non-smoker & Mean (sd) & 128.6 (15.6) & - & - & -\\
\addlinespace
 & Smoker & Mean (sd) & 128.7 (14.6) & 0.08 (-0.98 to 1.14, p=0.883) & 0.98 (-0.03 to 1.98, p=0.057) & -\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-33}Model metrics: Systolic blood pressure by available explanatory variables (top) with reduced model (bottom).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 3154, Number in model = 3142, Missing = 12, Log-likelihood = -12775.03, AIC = 25564.1, R-squared = 0.12, Adjusted R-squared = 0.12\\
Number in dataframe = 3154, Number in model = 3142, Missing = 12, Log-likelihood = -12776.83, AIC = 25565.7, R-squared = 0.12, Adjusted R-squared = 0.12\\
\bottomrule
\end{tabular}}
\end{table}

This results in little change in the other coefficients and very little change in the AIC.
We will consider the reduced model the final model.

We can also visualise models using plotting.
This is useful for communicating a model in a restricted space, e.g., in a presentation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory       <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"bmi"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                      \StringTok{"chol"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{) }
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"bmi"}\NormalTok{, }\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                      \StringTok{"chol"}\NormalTok{) }
\NormalTok{fit_sbp5 <-}\StringTok{ }\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ff_plot}\NormalTok{(dependent, explanatory_multi)}
\end{Highlighting}
\end{Shaded}

We can check the assumptions as above.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "sbp"}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"bmi"}\NormalTok{, }\StringTok{"personality_2L"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }
                      \StringTok{"chol"}\NormalTok{) }
\NormalTok{wcgsdata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{lmmulti}\NormalTok{(dependent, explanatory_multi) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{autoplot}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-36-1.pdf}
\caption{\label{fig:unnamed-chunk-36}Diagnostic plots: Linear regression model of systolic blood pressure.}
\end{figure}

An important message in the results relates to the highly significant \emph{p}-values in the table above.
Should we conclude that in a "multivariable regression model controlling for BMI, age, and serum cholesterol, blood pressure was significantly elevated in those with a Type A personality (1.56 (0.57 to 2.56, p=0.002) compared with Type B?
The \emph{p}-value looks impressive, but the actual difference in blood pressure is only 1.6 mmHg.
Even at a population level, that may not be clinically significant, fitting with our first thoughts when we saw the scatter plot.

This serves to emphasise our most important point.
Our focus should be on understanding the underlying data itself, rather than relying on complex multidimensional modelling procedures.
By making liberal use of upfront plotting, together with further visualisation as you understand the data, you will likely be able to draw most of the important conclusions that the data has to offer.
Use modelling to quantify and confirm this, rather than as the primary method of data exploration.

\hypertarget{summary-1}{%
\subsection{Summary}\label{summary-1}}

Time spent truly understanding linear regression is well spent.
Not because you will spend a lot of time making linear regression models in health data science (we rarely do), but because it the essential foundation for understanding more advanced statistical models.

It can even be argued that all \href{https://lindeloev.github.io/tests-as-linear}{common statistical tests are linear models}.
This great post demonstrates beautifully how the statistical tests we are most familiar with (such as t-test, Mann-Whitney U test, ANOVA, chi-squared test) can simply be considered as special cases of linear models, or close approximations.

Regression is fitting lines, preferably straight, through data points.
Make \(\hat{y} = \beta_0 + \beta_1 x_1\) a close friend.

An excellent book for further reading on regression is \citet{harrell2015}.

\hypertarget{exercises-2}{%
\section{Exercises}\label{exercises-2}}

\hypertarget{chap07-ex1}{%
\subsection{Exercise}\label{chap07-ex1}}

Using the \href{https://argoshare.is.ed.ac.uk/multi_regression/}{multivariable regression Shiny app}, hack some p-values to prove to yourself the principle of multiple testing.

From the default position, select ``additive model'' then set ``Error standard deviation'' to 2. Leave all true effects at 0. How many clicks of ``New Sample'' did you need before you got a statistically significant result?

\hypertarget{chap07-ex2}{%
\subsection{Exercise}\label{chap07-ex2}}

Plot the GDP per capita by year for countries in Europe.
Add a best fit straight line to the plot.
In which countries is the relationship not linear?
Advanced: make the line curved by adding a quadratic/squared term, e.g., \(y~x^2+x\). Hint: check geom\_smooth() help page under \texttt{formula}.

\hypertarget{chap07-ex3}{%
\subsection{Exercise}\label{chap07-ex3}}

Compare the relationship between GDP per capita and year for two countries of your choice.
If you can't choose, make it Albania and Austria.

Fit and plot a regression model that simply averages the values across the two countries.

Fit and plot a best fit regression model.

Use your model to determine the difference in GDP per capita for your countries in 1980.

\hypertarget{chap07-ex4}{%
\subsection{Exercise}\label{chap07-ex4}}

Use the Western Collaborative Group Study data to determine if there is a relationship between age and cholesterol level.

Remember to plot the data first.

Make a simple regression model. Add other variables to adjust for potential confounding.

\hypertarget{solutions-2}{%
\section{Solutions}\label{solutions-2}}

Solution to Exercise \ref{chap07-ex2}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(country }\OperatorTok{~}\StringTok{ }\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-37-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Countries not linear: Ireland, Montenegro, Serbia.}

\CommentTok{# Add quadratic term}
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(continent }\OperatorTok{==}\StringTok{ "Europe"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{formula =} \StringTok{"y ~ poly(x, 2)"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(country }\OperatorTok{~}\StringTok{ }\NormalTok{.)}
\end{Highlighting}
\end{Shaded}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-37-2.pdf}

Solution to Exercise \ref{chap07-ex3}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot first}
\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap, }\DataTypeTok{colour=}\NormalTok{ country))}
\end{Highlighting}
\end{Shaded}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-38-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit average line between two countries. }
\NormalTok{fit_both1 =}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(gdpPercap }\OperatorTok{~}\StringTok{ }\NormalTok{year, }\DataTypeTok{data =}\NormalTok{ .)}

\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =} \KeywordTok{predict}\NormalTok{(fit_both1)))}
\end{Highlighting}
\end{Shaded}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-38-2.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit average line between two countries. }
\NormalTok{fit_both3 =}\StringTok{ }\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{lm}\NormalTok{(gdpPercap }\OperatorTok{~}\StringTok{ }\NormalTok{year }\OperatorTok{*}\StringTok{ }\NormalTok{country, }\DataTypeTok{data =}\NormalTok{ .)}

\NormalTok{gapdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{filter}\NormalTok{(country }\OperatorTok{%in%}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =}\NormalTok{ gdpPercap, }\DataTypeTok{colour =}\NormalTok{ country)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_line}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ year, }\DataTypeTok{y =} \KeywordTok{predict}\NormalTok{(fit_both3), }\DataTypeTok{group =}\NormalTok{ country))}
\end{Highlighting}
\end{Shaded}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-38-3.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# You can use the regression equation by hand to work out the difference}
\KeywordTok{summary}\NormalTok{(fit_both3)}

\CommentTok{# Or pass newdata to predict to estimate the two points of interest}
\NormalTok{gdp_}\DecValTok{1980}\NormalTok{ <-}\StringTok{ }\KeywordTok{predict}\NormalTok{(fit_both3, }\DataTypeTok{newdata =} \KeywordTok{data.frame}\NormalTok{(}
  \DataTypeTok{country =} \KeywordTok{c}\NormalTok{(}\StringTok{"Albania"}\NormalTok{, }\StringTok{"Austria"}\NormalTok{),}
  \DataTypeTok{year =} \KeywordTok{c}\NormalTok{(}\DecValTok{1980}\NormalTok{, }\DecValTok{1980}\NormalTok{))}
\NormalTok{)}
\NormalTok{gdp_}\DecValTok{1980}
\NormalTok{gdp_}\DecValTok{1980}\NormalTok{[}\DecValTok{2}\NormalTok{] }\OperatorTok{-}\StringTok{ }\NormalTok{gdp_}\DecValTok{1980}\NormalTok{[}\DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

Solution to Exercise \ref{chap07-ex4}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Plot data first}
\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age, }\DataTypeTok{y =}\NormalTok{ chol))}\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_point}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"lm"}\NormalTok{, }\DataTypeTok{formula =} \StringTok{"y~x"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 12 rows containing non-finite values (stat_smooth).
\end{verbatim}

\begin{verbatim}
## Warning: Removed 12 rows containing missing values (geom_point).
\end{verbatim}

\includegraphics{07_linear_regression_files/figure-latex/unnamed-chunk-39-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Weak positive relationship}

\CommentTok{# Simple linear regression}
\NormalTok{dependent <-}\StringTok{ "chol"}
\NormalTok{explanatory <-}\StringTok{ "age"} 
\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Note: dependent includes missing data. These are dropped.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# For each year of age, cholesterol increases by 0.7 mg/100 ml. }
\CommentTok{# This gradient differs from zero. }

\CommentTok{# Is this effect independent of other available variables?}

\CommentTok{# Make BMI as above}
\NormalTok{dependent <-}\StringTok{ "chol"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{( }\StringTok{"age"}\NormalTok{, }\StringTok{"bmi"}\NormalTok{, }\StringTok{"sbp"}\NormalTok{, }\StringTok{"smoking"}\NormalTok{, }\StringTok{"personality_2L"}\NormalTok{) }
\NormalTok{wcgsdata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{bmi =}\NormalTok{ ((weight}\OperatorTok{*}\FloatTok{0.4536}\NormalTok{) }\OperatorTok{/}\StringTok{ }\NormalTok{(height}\OperatorTok{*}\FloatTok{0.0254}\NormalTok{)}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"BMI"}\NormalTok{)}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Note: dependent includes missing data. These are dropped.
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Effect size is reduced, but still present. }
\CommentTok{# Model poorly describes data, R2=0.033.}
\end{Highlighting}
\end{Shaded}

\hypertarget{chap08-h1}{%
\chapter{Working with categorical outcome variables}\label{chap08-h1}}

\index{categorical data@\textbf{categorical data}}

\begin{quote}
Suddenly Christopher Robin began to tell Pooh about some of the things: People called Kings and Queens and something called Factors \ldots{} and Pooh said ``Oh!'' and thought how wonderful it would be to have a Real Brain which could tell you things.\\
A.A. Milne, \emph{The House at Pooh Corner} (1928)
\end{quote}

\hypertarget{factors}{%
\section{Factors}\label{factors}}

\index{factors}

We said earlier that continuous data can be measured and categorical data can be counted, which is useful to remember.
Categorical data can be a:

\begin{itemize}
\tightlist
\item
  Factor

  \begin{itemize}
  \tightlist
  \item
    a fixed set of names/strings or numbers
  \item
    these may have an inherent order (1st, 2nd 3rd) - ordinal factor
  \item
    or may not (female, male)
  \end{itemize}
\item
  Character

  \begin{itemize}
  \tightlist
  \item
    sequences of letters, numbers, or symbols
  \end{itemize}
\item
  Logical

  \begin{itemize}
  \tightlist
  \item
    containing only TRUE or FALSE
  \end{itemize}
\end{itemize}

Health data is awash with factors.
Whether it is outcomes like death, recurrence, or readmission.
Or predictors like cancer stage, deprivation quintile, or smoking status.
It is essential therefore to be comfortable manipulating factors and dealing with outcomes which are categorical.

\hypertarget{the-question-4}{%
\section{The Question}\label{the-question-4}}

We will use the classic ``Survival from Malignant Melanoma'' dataset which is included in the \textbf{boot} package.
The data consist of measurements made on patients with malignant melanoma, a type of skin cancer.
Each patient had their tumour removed by surgery at the Department of Plastic Surgery, University Hospital of Odense, Denmark, between 1962 and 1977.

For the purposes of this discussion, we are interested in the association between tumour ulceration and death from melanoma.

\hypertarget{get-the-data-4}{%
\section{Get the data}\label{get-the-data-4}}

The Help page (F1 on \texttt{boot::melanoma}) gives us its data dictionary including the definition of each variable and the coding used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{boot}\OperatorTok{::}\NormalTok{melanoma}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-the-data-2}{%
\section{Check the data}\label{check-the-data-2}}

As always, check any new dataset carefully before you start analysis.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}
\KeywordTok{theme_set}\NormalTok{(}\KeywordTok{theme_bw}\NormalTok{())}
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Rows: 205
## Columns: 7
## $ time      <dbl> 10, 30, 35, 99, 185, 204, 210, 232, 232, 279, 295, 355, 3...
## $ status    <dbl> 3, 3, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, ...
## $ sex       <dbl> 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, ...
## $ age       <dbl> 76, 56, 41, 71, 52, 28, 77, 60, 49, 68, 53, 64, 68, 63, 1...
## $ year      <dbl> 1972, 1968, 1977, 1968, 1965, 1971, 1972, 1974, 1968, 197...
## $ thickness <dbl> 6.76, 0.65, 1.34, 2.90, 12.08, 4.84, 5.16, 3.22, 12.88, 7...
## $ ulcer     <dbl> 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ff_glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $Continuous
##               label var_type   n missing_n missing_percent   mean     sd    min
## time           time    <dbl> 205         0             0.0 2152.8 1122.1   10.0
## status       status    <dbl> 205         0             0.0    1.8    0.6    1.0
## sex             sex    <dbl> 205         0             0.0    0.4    0.5    0.0
## age             age    <dbl> 205         0             0.0   52.5   16.7    4.0
## year           year    <dbl> 205         0             0.0 1969.9    2.6 1962.0
## thickness thickness    <dbl> 205         0             0.0    2.9    3.0    0.1
## ulcer         ulcer    <dbl> 205         0             0.0    0.4    0.5    0.0
##           quartile_25 median quartile_75    max
## time           1525.0 2005.0      3042.0 5565.0
## status            1.0    2.0         2.0    3.0
## sex               0.0    0.0         1.0    1.0
## age              42.0   54.0        65.0   95.0
## year           1968.0 1970.0      1972.0 1977.0
## thickness         1.0    1.9         3.6   17.4
## ulcer             0.0    0.0         1.0    1.0
## 
## $Categorical
## data frame with 0 columns and 205 rows
\end{verbatim}

As can be seen, all of the variables are currently coded as continuous/numeric.
The \texttt{\textless{}dbl\textgreater{}} stands for `double', meaning numeric which comes from `double-precision floating point', an awkward computer science term.

\hypertarget{chap08-recode}{%
\section{Recode the data}\label{chap08-recode}}

It is really important that variables are correctly coded for all plotting and analysis functions.
Using the data dictionary, we will convert the categorical variables to factors.

In the section below, we convert the continuous variables to \texttt{factors} (e.g., \texttt{sex\ \%\textgreater{}\%\ factor()\ \%\textgreater{}\%}), then use the \textbf{forcats} package to recode the factor levels.
Modern databases (such as REDCap) can give you an R script to recode your specific dataset.
This means you don't always have to recode your factors from numbers to names manually.
But you will always be recoding variables during the exploration and analysis stages too, so it is important to follow what is happening here.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sex.factor =}             \CommentTok{# Make new variable  }
\NormalTok{           sex }\OperatorTok{%>%}\StringTok{                }\CommentTok{# from existing variable}
\StringTok{           }\KeywordTok{factor}\NormalTok{() }\OperatorTok{%>%}\StringTok{           }\CommentTok{# convert to factor}
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(            }\CommentTok{# forcats function}
             \StringTok{"Female"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{,      }\CommentTok{# new on left, old on right}
             \StringTok{"Male"}\NormalTok{   =}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Sex"}\NormalTok{),       }\CommentTok{# Optional label for finalfit}
         
         \CommentTok{# same thing but more condensed code:}
         \DataTypeTok{ulcer.factor =} \KeywordTok{factor}\NormalTok{(ulcer) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Present"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Absent"}\NormalTok{  =}\StringTok{ "0"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Ulcerated tumour"}\NormalTok{),}
         
         \DataTypeTok{status.factor =} \KeywordTok{factor}\NormalTok{(status) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Died melanoma"}\NormalTok{       =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Alive"}\NormalTok{               =}\StringTok{ "2"}\NormalTok{,}
                      \StringTok{"Died - other causes"}\NormalTok{ =}\StringTok{ "3"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Status"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We have formatted the recode of the \texttt{sex} variables to be on multiple lines - to make it easier for you to see the exact steps included.
We have condensed for the other recodes (e.g., \texttt{ulcer.factor\ =\ factor(ulcer)\ \%\textgreater{}\%}), but it does the exact same thing as the first one.

\index{functions@\textbf{functions}!factor}
\index{functions@\textbf{functions}!fct\_recode}
\index{functions@\textbf{functions}!ff\_label}

\hypertarget{should-i-convert-a-continuous-variable-to-a-categorical-variable}{%
\section{Should I convert a continuous variable to a categorical variable?}\label{should-i-convert-a-continuous-variable-to-a-categorical-variable}}

\index{categorical data@\textbf{categorical data}!convert from continuous}

This is a common question and something which is frequently done.
Take for instance the variable age.
Is it better to leave it as a continuous variable, or to chop it into categories, e.g., 30 to 39 etc.?

The clear disadvantage in doing this is that information is being thrown away.
Which feels like a bad thing to be doing.
This is particularly important if the categories being created are large.

For instance, if age was dichotomised to ``young'' and ``old'' at say 42 years (the current median age in Europe), then it is likely that relevant information to a number of analyses has been discarded.

Secondly, it is unforgivable practice to repeatedly try different cuts of a continuous variable to obtain a statistically significant result.
This is most commonly done in tests of diagnostic accuracy, where a threshold for considering a continuous test result positive is chosen \emph{post hoc} to maximise sensitivity/specificity, but not then validated in an independent cohort.

But there are also advantages to converting a continuous variable to categorical.
Say the relationship between age and an outcome is not linear, but rather u-shaped, then fitting a regression line is more difficult.
If age is cut into 10-year bands and entered into a regression as a factor, then this non-linearity is already accounted for.

Secondly, when communicating the results of an analysis to a lay audience, it may be easier to use a categorical representation.
For instance, an odds of death 1.8 times greater in 70-year-olds compared with 40-year-olds may be easier to grasp than a 1.02 times increase per year.

So what is the answer?
Do not do it unless you have to.
Plot and understand the continuous variable first.
If you do it, try not to throw away too much information.
Repeat your analyses both with the continuous data and categorical data to ensure there is no difference in the conclusion (often called a sensitivity analysis).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Summary of age}
\NormalTok{meldata}\OperatorTok{$}\NormalTok{age }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##    4.00   42.00   54.00   52.46   65.00   95.00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ age)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\includegraphics{08_working_categorical_files/figure-latex/unnamed-chunk-5-1.pdf}

There are different ways in which a continuous variable can be converted to a factor.
You may wish to create a number of intervals of equal length.
The \texttt{cut()} function can be used for this.

Figure \ref{fig:chap08-fig-cut} illustrates different options for this.
We suggest not using the \texttt{label} option of the \texttt{cut()} function to avoid errors, should the underlying data change or when the code is copied and reused.
A better practice is to recode the levels using \texttt{fct\_recode} as above.

The intervals in the output are standard mathematical notation.
A square bracket indicates the value is included in the interval and a round bracket that the value is excluded.

Note the requirement for \texttt{include.lowest\ =\ TRUE} when you specify breaks yourself and the lowest cut-point is also the lowest data value.
This should be clear in Figure \ref{fig:chap08-fig-cut}.

\begin{figure}
\centering
\includegraphics{images/chapter08/1_cut.pdf}
\caption{\label{fig:chap08-fig-cut}\texttt{Cut} a continuous variable into a categorical variable.}
\end{figure}

\hypertarget{equal-intervals-vs-quantiles}{%
\subsection{Equal intervals vs quantiles}\label{equal-intervals-vs-quantiles}}

\index{categorical data@\textbf{categorical data}!quantiles}

Be clear in your head whether you wish to cut the data so the intervals are of equal length.
Or whether you wish to cut the data so there are equal proportions of cases (patients) in each level.

Equal intervals:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{age.factor =} 
\NormalTok{      age }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{cut}\NormalTok{(}\DecValTok{4}\NormalTok{)}
\NormalTok{  )}
\NormalTok{meldata}\OperatorTok{$}\NormalTok{age.factor }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## (3.91,26.8] (26.8,49.5] (49.5,72.2] (72.2,95.1] 
##          16          68         102          19
\end{verbatim}

\index{functions@\textbf{functions}!cut}

Quantiles:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{age.factor =} 
\NormalTok{      age }\OperatorTok{%>%}
\StringTok{      }\NormalTok{Hmisc}\OperatorTok{::}\KeywordTok{cut2}\NormalTok{(}\DataTypeTok{g=}\DecValTok{4}\NormalTok{) }\CommentTok{# Note, cut2 comes from the Hmisc package}
\NormalTok{  )}
\NormalTok{meldata}\OperatorTok{$}\NormalTok{age.factor }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [ 4,43) [43,55) [55,66) [66,95] 
##      55      49      53      48
\end{verbatim}

\index{functions@\textbf{functions}!quantile}

Using the cut function, a continuous variable can be converted to a categorical one:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{age.factor =} 
\NormalTok{      age }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{cut}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{20}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{60}\NormalTok{,}\DecValTok{95}\NormalTok{), }\DataTypeTok{include.lowest =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{fct_recode}\NormalTok{(}
        \StringTok{"≤20"}\NormalTok{      =}\StringTok{  "[4,20]"}\NormalTok{,}
        \StringTok{"21 to 40"}\NormalTok{ =}\StringTok{ "(20,40]"}\NormalTok{,}
        \StringTok{"41 to 60"}\NormalTok{ =}\StringTok{ "(40,60]"}\NormalTok{,}
        \StringTok{">60"}\NormalTok{      =}\StringTok{ "(60,95]"}
\NormalTok{      ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Age (years)"}\NormalTok{)}
\NormalTok{  )}
\KeywordTok{head}\NormalTok{(meldata}\OperatorTok{$}\NormalTok{age.factor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] >60      41 to 60 41 to 60 >60      41 to 60 21 to 40
## Levels: ≤20 21 to 40 41 to 60 >60
\end{verbatim}

\hypertarget{plot-the-data-5}{%
\section{Plot the data}\label{plot-the-data-5}}

We are interested in the association between tumour ulceration and death from melanoma.
To start then, we simply count the number of patients with ulcerated tumours who died.
It is useful to plot this as counts but also as proportions.
It is proportions you are comparing, but you really want to know the absolute numbers as well.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"proportion"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(patchwork)}
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{08_working_categorical_files/figure-latex/unnamed-chunk-9-1.pdf}
\caption{\label{fig:unnamed-chunk-9}Bar chart: Outcome after surgery for patients with ulcerated melanoma.}
\end{figure}

It should be obvious that more died from melanoma in the ulcerated tumour group compared with the non-ulcerated tumour group.
The stacking is orders from top to bottom by default.
This can be easily adjusted by changing the order of the levels within the factor (see re-levelling below).
This default order works well for binary variables - the ``yes'' or ``1'' is lowest and can be easily compared.
This ordering of this particular variable is unusual - it would be more common to have for instance \texttt{alive\ =\ 0}, \texttt{died\ =\ 1}.
One quick option is to just reverse the order of the levels in the plot.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \KeywordTok{position_stack}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \KeywordTok{position_fill}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"proportion"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(patchwork)}
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{08_working_categorical_files/figure-latex/unnamed-chunk-10-1.pdf}
\caption{\label{fig:unnamed-chunk-10}Bar chart: Outcome after surgery for patients with ulcerated melanoma, reversed levels.}
\end{figure}

Just from the plot then, death from melanoma in the ulcerated tumour group is around 40\% and in the non-ulcerated group around 13\%.
The number of patients included in the study is not huge, however, this still looks like a real difference given its effect size.

We may also be interested in exploring potential effect modification, interactions and confounders.
Again, we urge you to first visualise these, rather than going straight to a model.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill=}\NormalTok{status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \KeywordTok{position_stack}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(sex.factor }\OperatorTok{~}\StringTok{ }\NormalTok{age.factor) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill=}\NormalTok{status.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \KeywordTok{position_fill}\NormalTok{(}\DataTypeTok{reverse =} \OtherTok{TRUE}\NormalTok{)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(sex.factor }\OperatorTok{~}\StringTok{ }\NormalTok{age.factor)}\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"bottom"}\NormalTok{)}

\NormalTok{p1 }\OperatorTok{/}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{08_working_categorical_files/figure-latex/unnamed-chunk-11-1.pdf}
\caption{\label{fig:unnamed-chunk-11}Facetted bar plot: Outcome after surgery for patients with ulcerated melanoma aggregated by sex and age.}
\end{figure}

\hypertarget{group-factor-levels-together---fct_collapse}{%
\section{\texorpdfstring{Group factor levels together - \texttt{fct\_collapse()}}{Group factor levels together - fct\_collapse()}}\label{group-factor-levels-together---fct_collapse}}

\index{functions@\textbf{functions}!fct\_collapse}

Our question relates to the association between tumour ulceration and death from melanoma.
The outcome measure has three levels as can be seen.
For our purposes here, we will generate a disease-specific mortality variable (\texttt{status\_dss}), by combining ``Died - other causes'' and ``Alive''.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{status_dss =} \KeywordTok{fct_collapse}\NormalTok{(}
\NormalTok{      status.factor,}
      \StringTok{"Alive"}\NormalTok{ =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"Alive"}\NormalTok{, }\StringTok{"Died - other causes"}\NormalTok{))}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{chap08-h2-fct-relevel}{%
\section{\texorpdfstring{Change the order of values within a factor - \texttt{fct\_relevel()}}{Change the order of values within a factor - fct\_relevel()}}\label{chap08-h2-fct-relevel}}

\index{functions@\textbf{functions}!fct\_relevel}

The default order for levels with \texttt{factor()} is alphabetical.
We often want to reorder the levels in a factor when plotting, or when performing a regression analysis and we want to specify the reference level.

The order can be checked using \texttt{levels()}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# dss - disease specific survival}
\NormalTok{meldata}\OperatorTok{$}\NormalTok{status_dss }\OperatorTok{%>%}\StringTok{ }\KeywordTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "Died melanoma" "Alive"
\end{verbatim}

The reason ``Alive'' is second, rather than alphabetical, is it was recoded from ``2'' and that order was retained.
If, however, we want to make comparisons relative to ``Alive'', we need to move it to the front by using \texttt{fct\_relevel()}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata <-}\StringTok{ }\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{status_dss =}\NormalTok{ status_dss }\OperatorTok{%>%}
\StringTok{           }\KeywordTok{fct_relevel}\NormalTok{(}\StringTok{"Alive"}\NormalTok{)}
\NormalTok{         )}
\end{Highlighting}
\end{Shaded}

Any number of factor levels can be specified in \texttt{fct\_relevel()}.

\hypertarget{summarising-factors-with-finalfit}{%
\section{\texorpdfstring{Summarising factors with \texttt{finalfit}}{Summarising factors with finalfit}}\label{summarising-factors-with-finalfit}}

\index{categorical data@\textbf{categorical data}!finalfit}
\index{categorical data@\textbf{categorical data}!summarising}

Our own \textbf{finalfit} package provides convenient functions to summarise and compare factors, producing final tables for publication.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent   =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} \StringTok{"ulcer.factor"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:chap08-tab-2x2}Two-by-two table with finalfit: Died with melanoma by tumour ulceration status.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrr}
\toprule
label & levels & Alive & Died melanoma\\
\midrule
Ulcerated tumour & Absent & 99 (66.9) & 16 (28.1)\\
 & Present & 49 (33.1) & 41 (71.9)\\
\bottomrule
\end{tabular}}
\end{table}

\texttt{finalfit} is useful for summarising multiple variables.
We often want to summarise more than one factor or continuous variable against our \texttt{dependent} variable of interest.
Think of Table 1 in a journal article.

Any number of continuous or categorical explanatory variables can be added.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} 
                       \KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                         \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-17}Multiple variables by outcome: Outcome after surgery for melanoma by patient and disease factors.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrr}
\toprule
label & levels & Alive & Died melanoma\\
\midrule
Ulcerated tumour & Absent & 99 (66.9) & 16 (28.1)\\
 & Present & 49 (33.1) & 41 (71.9)\\
Age (years) & ≤20 & 6 (4.1) & 3 (5.3)\\
\addlinespace
 & 21 to 40 & 30 (20.3) & 7 (12.3)\\
 & 41 to 60 & 66 (44.6) & 26 (45.6)\\
 & >60 & 46 (31.1) & 21 (36.8)\\
\addlinespace
Sex & Female & 98 (66.2) & 28 (49.1)\\
 & Male & 50 (33.8) & 29 (50.9)\\
thickness & Mean (SD) & 2.4 (2.5) & 4.3 (3.6)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{pearsons-chi-squared-and-fishers-exact-tests}{%
\section{Pearson's chi-squared and Fisher's exact tests}\label{pearsons-chi-squared-and-fishers-exact-tests}}

\index{categorical data@\textbf{categorical data}!chi-squared test}
\index{categorical data@\textbf{categorical data}!Fisher's exact test}
\index{chi-squared test}
\index{Fisher's exact test}

Pearson's chi-squared (\(\chi^2\)) test of independence is used to determine whether two categorical variables are independent in a given population.
Independence here means that the relative frequencies of one variable are the same over all levels of another variable.

A common setting for this is the classic 2x2 table.
This refers to two categorical variables with exactly two levels each, such as is show in Table \ref{tab:chap08-tab-2x2} above.
The null hypothesis of independence for this particular question is no difference in the proportion of patients with ulcerated tumours who die (45.6\%) compared with non-ulcerated tumours (13.9\%).
From the raw frequencies, there seems to be a large difference, as we noted in the plot we made above.

\hypertarget{base-r}{%
\subsection{Base R}\label{base-r}}

Base R has reliable functions for all common statistical tests, but they are sometimes a little inconvenient to extract results from.

A table of counts can be constructed, either using the \texttt{\$} to identify columns, or using the \texttt{with()} function.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{table}\NormalTok{(meldata}\OperatorTok{$}\NormalTok{ulcer.factor, meldata}\OperatorTok{$}\NormalTok{status_dss) }\CommentTok{# both give same result}
\KeywordTok{with}\NormalTok{(meldata, }\KeywordTok{table}\NormalTok{(ulcer.factor, status_dss))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##          
##           Alive Died melanoma
##   Absent     99            16
##   Present    49            41
\end{verbatim}

When working with older R functions, a useful shortcut is the \texttt{exposition\ pipe-operator} (\texttt{\%\$\%}) from the \textbf{magrittr} package, home of the standard forward pipe-operator (\texttt{\%\textgreater{}\%}).
The exposition pipe-operator exposes data frame/tibble columns on the left to the function which follows on the right.
It's easier to see in action by making a table of counts.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(magrittr)}
\NormalTok{meldata }\OperatorTok{%$%}\StringTok{        }\CommentTok{# note $ sign here}
\StringTok{  }\KeywordTok{table}\NormalTok{(ulcer.factor, status_dss)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             status_dss
## ulcer.factor Alive Died melanoma
##      Absent     99            16
##      Present    49            41
\end{verbatim}

The counts table can be passed to \texttt{prop.table()} for proportions.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%$%}
\StringTok{  }\KeywordTok{table}\NormalTok{(ulcer.factor, status_dss) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{prop.table}\NormalTok{(}\DataTypeTok{margin =} \DecValTok{1}\NormalTok{)     }\CommentTok{# 1: row, 2: column etc.}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##             status_dss
## ulcer.factor     Alive Died melanoma
##      Absent  0.8608696     0.1391304
##      Present 0.5444444     0.4555556
\end{verbatim}

Similarly, the counts table can be passed to \texttt{chisq.test()} to perform the chi-squared test.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%$%}\StringTok{        }\CommentTok{# note $ sign here}
\StringTok{  }\KeywordTok{table}\NormalTok{(ulcer.factor, status_dss) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{chisq.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Pearson's Chi-squared test with Yates' continuity correction
## 
## data:  .
## X-squared = 23.631, df = 1, p-value = 1.167e-06
\end{verbatim}

\index{functions@\textbf{functions}!chisq.test}

The result can be extracted into a tibble using the \texttt{tidy()} function from the \textbf{broom} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\NormalTok{meldata }\OperatorTok{%$%}\StringTok{        }\CommentTok{# note $ sign here}
\StringTok{  }\KeywordTok{table}\NormalTok{(ulcer.factor, status_dss) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{chisq.test}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tidy}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 4
##   statistic    p.value parameter method                                         
##       <dbl>      <dbl>     <int> <chr>                                          
## 1      23.6 0.00000117         1 Pearson's Chi-squared test with Yates' continu~
\end{verbatim}

The \texttt{chisq.test()} function applies the Yates' continuity correction by default.
The standard interpretation assumes that the discrete probability of observed counts in the table can be approximated by the continuous chi-squared distribution.
This introduces some error.
The correction involves subtracting 0.5 from the absolute difference between each observed and expected value.
This is particularly helpful when counts are low, but can be removed if desired by \texttt{chisq.test(...,\ correct\ =\ FALSE)}.

\hypertarget{fishers-exact-test}{%
\section{Fisher's exact test}\label{fishers-exact-test}}

A commonly stated assumption of the chi-squared test is the requirement to have an expected count of at least 5 in each cell of the 2x2 table.
For larger tables, all expected counts should be \(>1\) and no more than 20\% of all cells should have expected counts \(<5\).
If this assumption is not fulfilled, an alternative test is Fisher's exact test.
For instance, if we are testing across a 2x4 table created from our \texttt{age.factor} variable and \texttt{status\_dss}, then we receive a warning.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%$%}\StringTok{        }\CommentTok{# note $ sign here}
\StringTok{  }\KeywordTok{table}\NormalTok{(age.factor, status_dss) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{chisq.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in chisq.test(.): Chi-squared approximation may be incorrect
\end{verbatim}

\begin{verbatim}
## 
##  Pearson's Chi-squared test
## 
## data:  .
## X-squared = 2.0198, df = 3, p-value = 0.5683
\end{verbatim}

Switch to Fisher's exact test

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%$%}\StringTok{        }\CommentTok{# note $ sign here}
\StringTok{  }\KeywordTok{table}\NormalTok{(age.factor, status_dss) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{fisher.test}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Fisher's Exact Test for Count Data
## 
## data:  .
## p-value = 0.5437
## alternative hypothesis: two.sided
\end{verbatim}

\index{functions@\textbf{functions}!fisher.test}

\hypertarget{chi-squared-fishers-exact-test-using-finalfit}{%
\section{Chi-squared / Fisher's exact test using finalfit}\label{chi-squared-fishers-exact-test-using-finalfit}}

It is easier using the \texttt{summary\_factorlist()} function from the \textbf{finalfit} package.
Including \texttt{p\ =\ TRUE} in \texttt{summary\_factorlist()} adds a hypothesis test to each included comparison.
This defaults to chi-squared tests with a continuity correction for categorical variables.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent   =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} \StringTok{"ulcer.factor"}\NormalTok{,}
                     \DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\index{functions@\textbf{functions}!summary\_factorlist}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-27}Two-by-two table with chi-squared test using final fit: Outcome after surgery for melanoma by tumour ulceration status.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
label & levels & Alive & Died melanoma & p\\
\midrule
Ulcerated tumour & Absent & 99 (66.9) & 16 (28.1) & <0.001\\
 & Present & 49 (33.1) & 41 (71.9) & \\
\bottomrule
\end{tabular}}
\end{table}

Adding further variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} 
                       \KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                         \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{),}
                     \DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning in chisq.test(age.factor, status_dss): Chi-squared approximation may be
## incorrect
\end{verbatim}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-29}Multiple variables by outcome with hypothesis tests: Outcome after surgery for melanoma by patient and disease factors (chi-squared test).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
label & levels & Alive & Died melanoma & p\\
\midrule
Ulcerated tumour & Absent & 99 (66.9) & 16 (28.1) & <0.001\\
 & Present & 49 (33.1) & 41 (71.9) & \\
Age (years) & ≤20 & 6 (4.1) & 3 (5.3) & 0.568\\
\addlinespace
 & 21 to 40 & 30 (20.3) & 7 (12.3) & \\
 & 41 to 60 & 66 (44.6) & 26 (45.6) & \\
 & >60 & 46 (31.1) & 21 (36.8) & \\
\addlinespace
Sex & Female & 98 (66.2) & 28 (49.1) & 0.036\\
 & Male & 50 (33.8) & 29 (50.9) & \\
thickness & Mean (SD) & 2.4 (2.5) & 4.3 (3.6) & <0.001\\
\bottomrule
\end{tabular}}
\end{table}

Note that for continuous expanatory variables, an F-test (ANOVA) is performed by default.
If variables are considered non-parametric (\texttt{cont\ =\ "mean"}), then a Kruskal-Wallis test is used.

Switch to Fisher's exact test:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} 
                       \KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                         \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{),}
                     \DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{,}
                     \DataTypeTok{p_cat =} \StringTok{"fisher"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-31}Multiple variables by outcome with hypothesis tests: Outcome after surgery for melanoma by patient and disease factors (Fisher's exact test).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
label & levels & Alive & Died melanoma & p\\
\midrule
Ulcerated tumour & Absent & 99 (66.9) & 16 (28.1) & <0.001\\
 & Present & 49 (33.1) & 41 (71.9) & \\
Age (years) & ≤20 & 6 (4.1) & 3 (5.3) & 0.544\\
\addlinespace
 & 21 to 40 & 30 (20.3) & 7 (12.3) & \\
 & 41 to 60 & 66 (44.6) & 26 (45.6) & \\
 & >60 & 46 (31.1) & 21 (36.8) & \\
\addlinespace
Sex & Female & 98 (66.2) & 28 (49.1) & 0.026\\
 & Male & 50 (33.8) & 29 (50.9) & \\
thickness & Mean (SD) & 2.4 (2.5) & 4.3 (3.6) & <0.001\\
\bottomrule
\end{tabular}}
\end{table}

Further options can be included:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\DataTypeTok{dependent =} \StringTok{"status_dss"}\NormalTok{, }
                     \DataTypeTok{explanatory =} 
                       \KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                         \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{),}
                     \DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{,}
                     \DataTypeTok{p_cat =} \StringTok{"fisher"}\NormalTok{,}
                     \DataTypeTok{digits =} 
                       \KeywordTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{2}\NormalTok{), }\CommentTok{#1: mean/median, 2: SD/IQR }
                                      \CommentTok{# 3: p-value, 4: count percentage}
                     \DataTypeTok{na_include =} \OtherTok{TRUE}\NormalTok{, }\CommentTok{# include missing in results/test}
                     \DataTypeTok{add_dependent_label =} \OtherTok{TRUE}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-33}Multiple variables by outcome with hypothesis tests: Options including missing data, rounding, and labels.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Dependent: Status &   & Alive & Died melanoma & p\\
\midrule
Ulcerated tumour & Absent & 99 (66.89) & 16 (28.07) & <0.0001\\
 & Present & 49 (33.11) & 41 (71.93) & \\
Age (years) & ≤20 & 6 (4.05) & 3 (5.26) & 0.5437\\
\addlinespace
 & 21 to 40 & 30 (20.27) & 7 (12.28) & \\
 & 41 to 60 & 66 (44.59) & 26 (45.61) & \\
 & >60 & 46 (31.08) & 21 (36.84) & \\
\addlinespace
Sex & Female & 98 (66.22) & 28 (49.12) & 0.0263\\
 & Male & 50 (33.78) & 29 (50.88) & \\
thickness & Mean (SD) & 2.4 (2.5) & 4.3 (3.6) & <0.0001\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{exercises-3}{%
\section{Exercises}\label{exercises-3}}

\hypertarget{chap08-ex1}{%
\subsection{Exercise}\label{chap08-ex1}}

Using \texttt{finalfit}, create a summary table with ``status.factor'' as the dependent variable and the following as explanatory variables: \texttt{sex.factor,\ ulcer.factor,\ age.factor,\ thickness}.

Change the continuous variable summary statistic to \texttt{median} and \texttt{interquartile\ range} instead of \texttt{mean} and \texttt{sd}.

\hypertarget{chap08-ex2}{%
\subsection{Exercise}\label{chap08-ex2}}

By changing one and only one line in the following block create firstly a new table showing the breakdown of \texttt{status.factor} by age and secondly the breakdown of \texttt{status.factor} by sex:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{meldata }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{count}\NormalTok{(ulcer.factor, status.factor) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{group_by}\NormalTok{(status.factor) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{total =} \KeywordTok{sum}\NormalTok{(n)) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{percentage =} \KeywordTok{round}\NormalTok{(}\DecValTok{100}\OperatorTok{*}\NormalTok{n}\OperatorTok{/}\NormalTok{total, }\DecValTok{1}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{count_perc =} \KeywordTok{paste0}\NormalTok{(n, }\StringTok{" ("}\NormalTok{, percentage, }\StringTok{")"}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{total, }\OperatorTok{-}\NormalTok{n, }\OperatorTok{-}\NormalTok{percentage) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{spread}\NormalTok{(status.factor, count_perc)}
\end{Highlighting}
\end{Shaded}

\hypertarget{chap08-ex3}{%
\subsection{Exercise}\label{chap08-ex3}}

Now produce these tables using the \texttt{summary\_factorlist()} function from the \textbf{finalfit} package.

\hypertarget{chap09-h1}{%
\chapter{Logistic regression}\label{chap09-h1}}

\index{logistic regression@\textbf{logistic regression}}

\begin{quote}
All generalizations are false, including this one.\\
Mark Twain
\end{quote}

\hypertarget{generalised-linear-modelling}{%
\section{Generalised linear modelling}\label{generalised-linear-modelling}}

Do not start here!
The material covered in this chapter is best understood after having read linear regression (Chapter \ref{chap07-h1}) and working with categorical outcome variables (Chapter \ref{chap08-h1}).

Generalised linear modelling is an extension to the linear modelling we are now familiar with.
It allows the principles of linear regression to be applied when outcomes are not continuous numeric variables.

\hypertarget{binary-logistic-regression}{%
\section{Binary logistic regression}\label{binary-logistic-regression}}

\index{logistic regression@\textbf{logistic regression}!binary data}
\index{binary data}

A regression analysis is a statistical approach to estimating the relationships between variables, often by drawing straight lines through data points.
For instance, we may try to predict blood pressure in a group of patients based on their coffee consumption (Figure \ref{fig:chap07-fig-regression} from Chapter\ref{chap07-h1}).
As blood pressure and coffee consumption can be considered on a continuous scale, this is an example of simple linear regression.

Logistic regression is an extension of this, where the variable being predicted is \emph{categorical}.
We will focus on binary logistic regression, where the dependent variable has two levels, e.g., yes or no, 0 or 1, dead or alive.
Other types of logistic regression include `ordinal', when the outcome variable has \textgreater2 ordered levels, and `multinomial', where the outcome variable has \textgreater2 levels with no inherent order.

We will only deal with binary logistic regression.
When we use the term `logistic regression', that is what we are referring to.

We have good reason.
In healthcare we are often interested in an event (like death) occurring or not occurring.
Binary logistic regression can tell us the probability of this outcome occurring in a patient with a particular set of characteristics.

Although in binary logistic regression the outcome must have two levels, remember that the predictors (explanatory variables) can be either continuous or categorical.

\hypertarget{the-question-1-1}{%
\subsection{The Question (1)}\label{the-question-1-1}}

As in previous chapters, we will use concrete examples when discussing the principles of the approach.
We return to our example of coffee drinking.
Yes, we are a little obsessed with coffee.

Our outcome variable was previously blood pressure.
We will now consider our outcome as the occurrence of a cardiovascular (CV) event over a 10-year period.
A cardiovascular event includes the diagnosis of ischemic heart disease, a heart attack (myocardial infarction), or a stroke (cerebrovascular accident).
The diagnosis of a cardiovascular event is clearly a binary condition, it either happens or it does not.
This is ideal for modelling using binary logistic regression.
But remember, the data are completely simulated and not based on anything in the real world.
This bit is just for fun!

\hypertarget{odds-and-probabilities}{%
\subsection{Odds and probabilities}\label{odds-and-probabilities}}

\index{logistic regression@\textbf{logistic regression}!odds and probabilities}

To understand logistic regression we need to remind ourselves about odds and probability.
Odds and probabilities can get confusing so get them straight with Figure \ref{fig:chap09-fig-odds}.

\begin{figure}
\centering
\includegraphics{images/chapter09/0_odds.pdf}
\caption{\label{fig:chap09-fig-odds}Probability vs odds.}
\end{figure}

In many situations, there is no particular reason to prefer one to the other.
However, humans seem to have a preference for expressing chance in terms of probabilities, while odds have particular mathematical properties that make them useful in regression.

When a probability is 0, the odds are 0.
When a probability is between 0 and 0.5, the odds are less than 1.0 (i.e., less than ``1 to 1'').
As probability increases from 0.5 to 1.0, the odds increase from 1.0 to approach infinity.

Thus the range of probability is 0 to 1 and the range of odds is 0 to \(+\infty\).

Odds and probabilities can easily be interconverted.
For example, if the odds of a patient dying from a disease are 1/3 (in horse racing this is stated as `3 to 1 against'), then the probability of death (also known as risk) is 0.25 (or 25\%).
Odds of \texttt{1\ to\ 1} equal 50\%.

\(Odds = \frac{p}{1-p}\), where \(p\) is the probability of the outcome occurring.

\(Probability = \frac{odds}{odds+1}\).

\hypertarget{odds-ratios}{%
\subsection{Odds ratios}\label{odds-ratios}}

\index{logistic regression@\textbf{logistic regression}!odds ratio}
\index{odds ratio}

Another important term to remind ourselves of is the `odds ratio'.
Why?
Because in a logistic regression the slopes of fitted lines (coefficients) can be interpreted as odds ratios.
This is very useful when interpreting the association of a particular predictor with an outcome.

For a given categorical predictor such as smoking, the difference in chance of the outcome occurring for smokers vs non-smokers can be expressed as a ratio of odds or odds ratio Figure \ref{fig:chap09-fig-or}.
For example, if the odds of a smoker have a CV event are 1.5 and the odds of a non smoker are 1.0, then the odds of a smoker having an event are 1.5-times greater than a non-smoker, odds ratio = 1.5.

\begin{figure}
\centering
\includegraphics{images/chapter09/1_or.pdf}
\caption{\label{fig:chap09-fig-or}Odds ratios.}
\end{figure}

An alternative is a ratio of probabilities which is called a risk ratio or relative risk.
We will continue to work with odds ratios given they are an important expression of effect size in logistic regression analysis.

\hypertarget{fitting-a-regression-line}{%
\subsection{Fitting a regression line}\label{fitting-a-regression-line}}

\index{logistic regression@\textbf{logistic regression}!fitted line}

Let's return to the task at hand.
The difficulty in moving from a continuous to a binary outcome variable quickly becomes obvious.
If our \(y\)-axis only has two values, say 0 and 1, then how can we fit a line through our data points?

An assumption of linear regression is that the dependent variable is continuous, unbounded, and measured on an interval or ratio scale.
Unfortunately, binary dependent variables fulfil none of these requirements.

The answer is what makes logistic regression so useful.
Rather than estimating \(y=0\) or \(y=1\) from the \(x\)-axis, we estimate the \emph{probability} of \(y=1\).

There is one more difficulty in this though.
Probabilities can only exist for values of 0 to 1.
The probability scale is therefore not linear - straight lines do not make sense on it.

As we saw above, the odds scale runs from 0 to \(+\infty\).
But here, probabilities from 0 to 0.5 are squashed into odds of 0 to 1, and probabilities from 0.5 to 1 have the expansive comfort of 1 to \(+\infty\).

This is why we fit binary data on a \emph{log-odds scale}.

A log-odds scale sounds incredibly off-putting to non-mathematicians, but it is the perfect solution.

\begin{itemize}
\tightlist
\item
  Log-odds run from \(-\infty\) to \(+\infty\);
\item
  odds of 1 become log-odds of 0;
\item
  a doubling and a halving of odds represent the same distance on the scale.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(}\DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6931472
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{log}\NormalTok{(}\FloatTok{0.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] -0.6931472
\end{verbatim}

I'm sure some are shouting `obviously' at the page.
That is good!

This is wrapped up in a transformation (a bit like the transformations shown in Section \ref{chap06-transform}) using the so-called logit function.
This can be skipped with no loss of understanding, but for those who just-gots-to-see, the logit function is,

\(\log_e (\frac{p}{1-p})\), where \(p\) is the probability of the outcome occurring.

Figure \ref{fig:chap09-fig-logodds} demonstrates the fitted lines from a logistic regression model of cardiovascular event by coffee consumption, stratified by smoking on the log-odds scale (A) and the probability scale (B).
We could conclude, for instance, that on average, non-smokers who drink 2 cups of coffee per day have a 50\% chance of a cardiovascular event.

\begin{figure}
\centering
\includegraphics{images/chapter09/2_prob_logodds.pdf}
\caption{\label{fig:chap09-fig-logodds}A logistic regression model of life-time cardiovascular event occurrence by coffee consumption stratified by smoking (simulated data). Fitted lines plotted on the log-odds scale (A) and probability scale (B). *lines are straight when no polynomials or splines are included in regression.}
\end{figure}

\hypertarget{the-fitted-line-and-the-logistic-regression-equation}{%
\subsection{The fitted line and the logistic regression equation}\label{the-fitted-line-and-the-logistic-regression-equation}}

Figure \ref{fig:chap09-fig-equation} links the logistic regression equation, the appearance of the fitted lines on the probability scale, and the output from a standard base \texttt{R} analysis.
The dots at the top and bottom of the plot represent whether individual patients have had an event or not. The fitted line, therefore, represents the point-to-point probability of a patient with a particular set of characteristics having the event or not.
Compare this to Figure \ref{fig:chap07-fig-equation} to be clear on the difference.
The slope of the line is linear on the log-odds scale and these are presented in the output on the log-odds scale.

Thankfully, it is straightforward to convert these to odds ratios, a measure we can use to communicate effect size and direction effectively.
Said in more technical language, the exponential of the coefficient on the log-odds scale can be interpreted as an odds ratio.

For a continuous variable such as cups of coffee consumed, the odds ratio is the change in odds of a CV event associated with a 1 cup increase in coffee consumption.
We are dealing with linear responses here, so the odds ratio is the same for an increase from 1 to 2 cups, or 3 to 4 cups etc.
Remember that if the odds ratio for 1 unit of change is 1.5, then the odds ratio for 2 units of change is \(exp(log(1.5)*2) = 2.25\).

For a categorical variable such as smoking, the odds ratio is the change in odds of a CV event associated with smoking compared with not smoking (the reference level).

\begin{figure}
\centering
\includegraphics{images/chapter09/4_equation.pdf}
\caption{\label{fig:chap09-fig-equation}Linking the logistic regression fitted line and equation (A) with the R output (B).}
\end{figure}

\hypertarget{effect-modification-and-confounding}{%
\subsection{Effect modification and confounding}\label{effect-modification-and-confounding}}

\index{logistic regression@\textbf{logistic regression}!effect modification}
\index{logistic regression@\textbf{logistic regression}!confounding}
\index{logistic regression@\textbf{logistic regression}!interactions}

As with all multivariable regression models, logistic regression allows the incorporation of multiple variables which all may have direct effects on outcome or may confound the effect of another variable.
This was explored in detail in Section \ref{chap07-confound}; all of the same principles apply.

Adjusting for effect modification and confounding allows us to isolate the direct effect of an explanatory variable of interest upon an outcome.
In our example, we are interested in direct effect of coffee drinking on the occurrence of cardiovascular disease, independent of any association between coffee drinking and smoking.

Figure \ref{fig:chap09-fig-types} demonstrates simple, additive and multiplicative models.
Think back to Figure \ref{fig:chap07-fig-types} and the discussion around it as these terms are easier to think about when looking at the linear regression example, but essentially they work the same way in logistic regression.

Presented on the probability scale, the effect of the interaction is difficult to see.
It is obvious on the log-odds scale that the fitted lines are no longer constrained to be parallel.

\begin{figure}
\centering
\includegraphics{images/chapter09/6_types.pdf}
\caption{\label{fig:chap09-fig-types}Multivariable logistic regression (A) with additive (B) and multiplicative (C) effect modification.}
\end{figure}

The interpretation of the interaction term is important.
The exponential of the interaction coefficient term represents a `ratio-of-odds ratios'.
This is easiest to see through a worked example.
In Figure \ref{fig:chap09-fig-interaction} the effect of coffee on the odds of a cardiovascular event can be compared in smokers and non-smokers.
The effect is now different given the inclusion of a significant interaction term.
Please check back to the linear regression chapter if this is not making sense.

\begin{figure}
\centering
\includegraphics{images/chapter09/7_interactions.pdf}
\caption{\label{fig:chap09-fig-interaction}Multivariable logistic regression with interaction term. The exponential of the interaction term is a ratio-of-odds ratios (ROR).}
\end{figure}

\hypertarget{data-preparation-and-exploratory-analysis}{%
\section{Data preparation and exploratory analysis}\label{data-preparation-and-exploratory-analysis}}

\hypertarget{the-question-2-1}{%
\subsection{The Question (2)}\label{the-question-2-1}}

We will go on to explore the \texttt{boot::melanoma} dataset introduced in Chapter \ref{chap08-h1}.
The data consist of measurements made on patients after surgery to remove the melanoma skin cancer in the University Hospital of Odense, Denmark, between 1962 and 1977.

Malignant melanoma is an aggressive and highly invasive cancer, making it difficult to treat.

To determine how advanced it is, staging is based on the depth of the tumour.
The current TNM classification cut-offs are:

\begin{itemize}
\tightlist
\item
  T1: \(\leq\) 1.0 mm depth
\item
  T2: 1.1 to 2.0 mm depth
\item
  T3: 2.1 to 4.0 mm depth
\item
  T4: \textgreater{} 4.0 mm depth
\end{itemize}

This will be important in our analysis as we will create a new variable based upon this.

Using logistic regression, we will investigate factors associated with death from malignant melanoma with particular interest in tumour ulceration.

\hypertarget{get-the-data-5}{%
\subsection{Get the data}\label{get-the-data-5}}

The Help page (F1 on \texttt{boot::melanoma}) gives us its data dictionary including the definition of each variable and the coding used.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{boot}\OperatorTok{::}\NormalTok{melanoma}
\end{Highlighting}
\end{Shaded}

\hypertarget{check-the-data-3}{%
\subsection{Check the data}\label{check-the-data-3}}

As before, always carefully check and clean new dataset before you start the analysis.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }\KeywordTok{glimpse}\NormalTok{()}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }\KeywordTok{ff_glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\hypertarget{recode-the-data}{%
\subsection{Recode the data}\label{recode-the-data}}

We have seen some of this already (Section \ref{chap08-recode}: Recode data), but for this particular analysis we will recode some further variables.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sex.factor =} \KeywordTok{factor}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{          }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Female"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{,}
                      \StringTok{"Male"}\NormalTok{   =}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Sex"}\NormalTok{),   }
         
         \DataTypeTok{ulcer.factor =} \KeywordTok{factor}\NormalTok{(ulcer) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Present"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Absent"}\NormalTok{  =}\StringTok{ "0"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Ulcerated tumour"}\NormalTok{),}
         
         \DataTypeTok{age  =} \KeywordTok{ff_label}\NormalTok{(age,  }\StringTok{"Age (years)"}\NormalTok{),}
         \DataTypeTok{year =} \KeywordTok{ff_label}\NormalTok{(year, }\StringTok{"Year"}\NormalTok{),}
         
         \DataTypeTok{status.factor =} \KeywordTok{factor}\NormalTok{(status) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Died melanoma"}\NormalTok{  =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Alive"}\NormalTok{ =}\StringTok{ "2"}\NormalTok{,}
                      \StringTok{"Died - other"}\NormalTok{ =}\StringTok{ "3"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_relevel}\NormalTok{(}\StringTok{"Alive"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Status"}\NormalTok{),}
         
         \DataTypeTok{t_stage.factor =} 
\NormalTok{           thickness }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{cut}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{, }
                          \KeywordTok{max}\NormalTok{(thickness, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)),}
               \DataTypeTok{include.lowest =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

Check the \texttt{cut()} function has worked:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma}\OperatorTok{$}\NormalTok{t_stage.factor }\OperatorTok{%>%}\StringTok{ }\KeywordTok{levels}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] "[0,1]"    "(1,2]"    "(2,4]"    "(4,17.4]"
\end{verbatim}

Recode for ease.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{t_stage.factor =} 
      \KeywordTok{fct_recode}\NormalTok{(t_stage.factor,}
                 \StringTok{"T1"}\NormalTok{ =}\StringTok{ "[0,1]"}\NormalTok{,}
                 \StringTok{"T2"}\NormalTok{ =}\StringTok{ "(1,2]"}\NormalTok{,}
                 \StringTok{"T3"}\NormalTok{ =}\StringTok{ "(2,4]"}\NormalTok{,}
                 \StringTok{"T4"}\NormalTok{ =}\StringTok{ "(4,17.4]"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"T-stage"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We will now consider our outcome variable.
With a binary outcome and health data, we often have to make a decision as to \emph{when} to determine if that variable has occurred or not.
In the next chapter we will look at survival analysis where this requirement is not needed.

Our outcome of interest is death from melanoma, but we need to decide when to define this.

A quick histogram of \texttt{time} stratified by \texttt{status.factor} helps.
We can see that most people who died from melanoma did so before 5 years (Figure \ref{fig:chap09-fig-morthist}).
We can also see that the status most of those who did not die is known beyond 5 years.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(ggplot2)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ time}\OperatorTok{/}\DecValTok{365}\NormalTok{)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_histogram}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_grid}\NormalTok{(. }\OperatorTok{~}\StringTok{ }\NormalTok{status.factor)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
\end{verbatim}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-morthist-1.pdf}
\caption{\label{fig:chap09-fig-morthist}Time to outcome/follow-up times for patients in the melanoma dataset.}
\end{figure}

Let's decide then to look at 5-year mortality from melanoma.
The definition of this will be at 5 years after surgery, who had died from melanoma and who had not.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5-year mortality}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{mort_5yr =} 
      \KeywordTok{if_else}\NormalTok{((time}\OperatorTok{/}\DecValTok{365}\NormalTok{) }\OperatorTok{<}\StringTok{ }\DecValTok{5} \OperatorTok{&}\StringTok{ }
\StringTok{                }\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{), }
              \StringTok{"Yes"}\NormalTok{,          }\CommentTok{# then}
              \StringTok{"No"}\NormalTok{) }\OperatorTok{%>%}\StringTok{       }\CommentTok{# else}
\StringTok{      }\KeywordTok{fct_relevel}\NormalTok{(}\StringTok{"No"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"5-year survival"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot-the-data-6}{%
\subsection{Plot the data}\label{plot-the-data-6}}

We are interested in the association between tumour ulceration and outcome (Figure \ref{fig:chap09-fig-ulceration}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p1 <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ mort_5yr)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ ulcer.factor, }\DataTypeTok{fill =}\NormalTok{ mort_5yr)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"proportion"}\NormalTok{)}

\KeywordTok{library}\NormalTok{(patchwork)}
\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-ulceration-1.pdf}
\caption{\label{fig:chap09-fig-ulceration}Exploration ulceration and outcome (5-year mortality).}
\end{figure}

As we might have anticipated from our work in the previous chapter, 5-year mortality is higher in patients with ulcerated tumours compared with those with non-ulcerated tumours.

We are also interested in other variables that may be associated with tumour ulceration.
If they are also associated with our outcome, then they will confound the estimate of the direct effect of tumour ulceration.

We can plot out these relationships, or tabulate them instead.

\hypertarget{tabulate-data}{%
\subsection{Tabulate data}\label{tabulate-data}}

We will use the convenient \texttt{summary\_factorlist()} function from the \texttt{finalfit} package to look for differences across other variables by tumour ulceration.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "ulcer.factor"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"year"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent, explanatory, }\DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{,}
                     \DataTypeTok{add_dependent_label =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-10}Multiple variables by explanatory variable of interest: Malignant melanoma ulceration by patient and disease variables.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrr}
\toprule
Dependent: Ulcerated tumour &   & Absent & Present & p\\
\midrule
Age (years) & Mean (SD) & 50.6 (15.9) & 54.8 (17.4) & 0.072\\
Sex & Female & 79 (68.7) & 47 (52.2) & 0.024\\
 & Male & 36 (31.3) & 43 (47.8) & \\
\addlinespace
Year & Mean (SD) & 1970.0 (2.7) & 1969.8 (2.4) & 0.637\\
T-stage & T1 & 51 (44.3) & 5 (5.6) & <0.001\\
 & T2 & 36 (31.3) & 17 (18.9) & \\
\addlinespace
 & T3 & 21 (18.3) & 30 (33.3) & \\
 & T4 & 7 (6.1) & 38 (42.2) & \\
\bottomrule
\end{tabular}}
\end{table}

It appears that patients with ulcerated tumours were older, more likely to be male, and had thicker/higher stage tumours.
It is important therefore to consider inclusion of these variables in a regression model.

\hypertarget{model-assumptions}{%
\section{Model assumptions}\label{model-assumptions}}

\index{logistic regression@\textbf{logistic regression}!assumptions}

Binary logistic regression is robust to many of the assumptions which cause problems in other statistical analyses.
The main assumptions are:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Binary dependent variable - this is obvious, but as above we need to check (alive, death from disease, death from other causes doesn't work);
\item
  Independence of observations - the observations should not be repeated measurements or matched data;
\item
  Linearity of continuous explanatory variables and the log-odds outcome - take age as an example. If the outcome, say death, gets more frequent or less frequent as age rises, the model will work well. However, say children and the elderly are at high risk of death, but those in middle years are not, then the relationship is not linear. Or more correctly, it is not monotonic, meaning that the response does not only go in one direction;
\item
  No multicollinearity - explanatory variables should not be highly correlated with each other.
\end{enumerate}

\hypertarget{linearity-of-continuous-variables-to-the-response}{%
\subsection{Linearity of continuous variables to the response}\label{linearity-of-continuous-variables-to-the-response}}

\index{logistic regression@\textbf{logistic regression}!loess}

A graphical check of linearity can be performed using a best fit ``loess'' line.
This is on the probability scale, so it is not going to be straight.
But it should be monotonic - it should only ever go up or down.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{mort_5yr.num =} \KeywordTok{as.numeric}\NormalTok{(mort_5yr) }\OperatorTok{-}\StringTok{ }\DecValTok{1}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(mort_5yr.num, age, year) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\KeywordTok{all_of}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"year"}\NormalTok{)), }\DataTypeTok{names_to =} \StringTok{"predictors"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ value, }\DataTypeTok{y =}\NormalTok{ mort_5yr.num)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_point}\NormalTok{(}\DataTypeTok{size =} \FloatTok{0.5}\NormalTok{, }\DataTypeTok{alpha =} \FloatTok{0.5}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{"loess"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{predictors, }\DataTypeTok{scales =} \StringTok{"free_x"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-loess-1.pdf}
\caption{\label{fig:chap09-fig-loess}Linearity of our continuous explanatory variables to the outcome (5-year mortality).}
\end{figure}

Figure \ref{fig:chap09-fig-loess} shows that age is interesting as the relationship is u-shaped.
The chance of death is higher in the young and the old compared with the middle-aged.
This will need to be accounted for in any model including age as a predictor.

\hypertarget{chap09-h2-multicollinearity}{%
\subsection{Multicollinearity}\label{chap09-h2-multicollinearity}}

\index{logistic regression@\textbf{logistic regression}!multicollinearity}
\index{collinearity}
\index{multicollinearity}

The presence of two or more highly correlated variables in a regression analysis can cause problems in the results which are generated.
The slopes of lines (coefficients, ORs) can become unstable, which means big shifts in their size with minimal changes to the model or the underlying data.
The confidence intervals around these coefficients may also be large.
Definitions of the specifics differ between sources, but there are broadly two situations.

The first is when two highly correlated variables have been included in a model, sometimes referred to simply as collinearity.
This can be detected by thinking about which variables may be correlated, and then checking using plotting.

The second situation is more devious.
It is where collinearity exists between three or more variables, even when no pair of variables is particularly highly correlated.
To detect this, we can use a specific metric called the \emph{variance inflation factor}.

As always though, think clearly about your data and whether there may be duplication of information.
Have you included a variable which is calculated from other variables already included in the model?
Including body mass index (BMI), weight and height would be problematic, given the first is calculated from the latter two.

Are you describing a similar piece of information in two different ways?
For instance, all perforated colon cancers are staged T4, so do you include T-stage and the perforation factor?
(Note, not all T4 cancers have perforated.)

The \texttt{ggpairs()} function from \texttt{library(GGally)} is a good way of visualising all two-way associations (Figure \ref{fig:chap09-fig-ggpairs}).

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(GGally)}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"year"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{remove_labels}\NormalTok{() }\OperatorTok{%>%}\StringTok{  }\CommentTok{# ggpairs doesn't work well with labels}
\StringTok{  }\KeywordTok{ggpairs}\NormalTok{(}\DataTypeTok{columns =}\NormalTok{ explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-ggpairs-1.pdf}
\caption{\label{fig:chap09-fig-ggpairs}Exploring two-way associations within our explanatory variables.}
\end{figure}

\index{functions@\textbf{functions}!ggpairs}

If you have many variables you want to check you can split them up.

\textbf{Continuous to continuous}

Here we're using the same \texttt{library(GGally)} code as above, but shortlisting the two categorical variables: age and year (Figure \ref{fig:chap09-fig-contcont}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{select_explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"year"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{remove_labels}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggpairs}\NormalTok{(}\DataTypeTok{columns =}\NormalTok{ select_explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-contcont-1.pdf}
\caption{\label{fig:chap09-fig-contcont}Exploring relationships between continuous variables.}
\end{figure}

\textbf{Continuous to categorical}

Let's use a clever \texttt{pivot\_longer()} and \texttt{facet\_wrap()} combination to efficiently plot multiple variables against each other without using \texttt{ggpairs()}.
We want to compare everything against, for example, age so we need to include \texttt{-age} in the \texttt{pivot\_longer()} call so it doesn't get lumped up with everything else (Figure \ref{fig:chap09-fig-contcat}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{select_explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"ulcer.factor"}\NormalTok{, }
                       \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{all_of}\NormalTok{(select_explanatory)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\OperatorTok{-}\NormalTok{age) }\OperatorTok{%>%}\StringTok{ }\CommentTok{# pivots all but age into two columns: name and value}
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(value, age)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_boxplot}\NormalTok{() }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{name, }\DataTypeTok{scale =} \StringTok{"free"}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{3}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-contcat-1.pdf}
\caption{\label{fig:chap09-fig-contcat}Exploring associations between continuous and categorical explanatory variables.}
\end{figure}

\textbf{Categorical to categorical}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{select_explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{one_of}\NormalTok{(select_explanatory)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pivot_longer}\NormalTok{(}\OperatorTok{-}\NormalTok{sex.factor) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(value, }\DataTypeTok{fill =}\NormalTok{ sex.factor)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"proportion"}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{name, }\DataTypeTok{scale =} \StringTok{"free"}\NormalTok{, }\DataTypeTok{ncol =} \DecValTok{2}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{coord_flip}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\includegraphics{09_logistic_regression_files/figure-latex/unnamed-chunk-11-1.pdf}

None of the explanatory variables are highly correlated with one another.

\textbf{Variance inflation factor}
\index{functions@\textbf{functions}!vif}

Finally, as a final check for the presence of higher-order correlations, the variance inflation factor can be calculated for each of the terms in a final model.
In simple language, this is a measure of how much the variance of a particular regression coefficient is increased due to the presence of multicollinearity in the model.

Here is an example.
\emph{GVIF} stands for generalised variance inflation factor.
A common rule of thumb is that if this is greater than 5-10 for any variable, then multicollinearity may exist.
The model should be further explored and the terms removed or reduced.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"year"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{glmmulti}\NormalTok{(dependent, explanatory) }\OperatorTok{%>%}
\StringTok{  }\NormalTok{car}\OperatorTok{::}\KeywordTok{vif}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##                    GVIF Df GVIF^(1/(2*Df))
## ulcer.factor   1.313355  1        1.146017
## age            1.102313  1        1.049911
## sex.factor     1.124990  1        1.060655
## year           1.102490  1        1.049995
## t_stage.factor 1.475550  3        1.066987
\end{verbatim}

We are not trying to over-egg this, but multicollinearity can be important.
The message as always is the same.
Understand the underlying data using plotting and tables, and you are unlikely to come unstuck.

\hypertarget{fitting-logistic-regression-models-in-base-r}{%
\section{Fitting logistic regression models in base R}\label{fitting-logistic-regression-models-in-base-r}}

\index{logistic regression@\textbf{logistic regression}!model fitting}

The \texttt{glm()} stands for \texttt{generalised\ linear\ model} and is the standard base R approach to logistic regression.

The \texttt{glm()} function has several options and many different types of model can be run.
For instance, `Poisson regression' for count data.

To run binary logistic regression use \texttt{family\ =\ binomial}.
This defaults to \texttt{family\ =\ binomial(link\ =\ \textquotesingle{}logit\textquotesingle{})}.
Other link functions exist, such as the \texttt{probit} function, but this makes little difference to final conclusions.

Let's start with a simple univariable model using the classical R approach.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 <-}\StringTok{ }\KeywordTok{glm}\NormalTok{(mort_5yr }\OperatorTok{~}\StringTok{ }\NormalTok{ulcer.factor, }\DataTypeTok{data =}\NormalTok{ melanoma, }\DataTypeTok{family =}\NormalTok{ binomial)}
\KeywordTok{summary}\NormalTok{(fit1)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = mort_5yr ~ ulcer.factor, family = binomial, data = melanoma)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -0.9925  -0.9925  -0.4265  -0.4265   2.2101  
## 
## Coefficients:
##                     Estimate Std. Error z value Pr(>|z|)    
## (Intercept)          -2.3514     0.3309  -7.105 1.20e-12 ***
## ulcer.factorPresent   1.8994     0.3953   4.805 1.55e-06 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 215.78  on 204  degrees of freedom
## Residual deviance: 188.24  on 203  degrees of freedom
## AIC: 192.24
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\index{functions@\textbf{functions}!glm}

This is the standard R output which you should become familiar with.
It is included in the previous figures.
The estimates of the coefficients (slopes) in this output are on the log-odds scale and always will be.

Easier approaches for doing this in practice are shown below, but for completeness here we will show how to extract the results.
\texttt{str()} shows all the information included in the model object, which is useful for experts but a bit off-putting if you are starting out.

The coefficients and their 95\% confidence intervals can be extracted and exponentiated like this.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{coef}\NormalTok{(fit1) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{exp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##         (Intercept) ulcer.factorPresent 
##           0.0952381           6.6818182
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{confint}\NormalTok{(fit1) }\OperatorTok{%>%}\StringTok{ }\KeywordTok{exp}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Waiting for profiling to be done...
\end{verbatim}

\begin{verbatim}
##                          2.5 %     97.5 %
## (Intercept)         0.04662675  0.1730265
## ulcer.factorPresent 3.18089978 15.1827225
\end{verbatim}

\index{functions@\textbf{functions}!coef}
\index{functions@\textbf{functions}!confint}

Note that the 95\% confidence interval is between the 2.5\% and 97.5\% quantiles of the distribution, hence why the results appear in this way.

A good alternative is the \texttt{tidy()} function from the \textbf{broom} package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(broom)}
\NormalTok{fit1 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{tidy}\NormalTok{(}\DataTypeTok{conf.int =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{exp =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 2 x 7
##   term                estimate std.error statistic  p.value conf.low conf.high
##   <chr>                  <dbl>     <dbl>     <dbl>    <dbl>    <dbl>     <dbl>
## 1 (Intercept)           0.0952     0.331     -7.11 1.20e-12   0.0466     0.173
## 2 ulcer.factorPresent   6.68       0.395      4.80 1.55e- 6   3.18      15.2
\end{verbatim}

We can see from these results that there is a strong association between tumour ulceration and 5-year mortality (OR 6.68, 95\%CI 3.18, 15.18).

Model metrics can be extracted using the \texttt{glance()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fit1 }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{glance}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## # A tibble: 1 x 8
##   null.deviance df.null logLik   AIC   BIC deviance df.residual  nobs
##           <dbl>   <int>  <dbl> <dbl> <dbl>    <dbl>       <int> <int>
## 1          216.     204  -94.1  192.  199.     188.         203   205
\end{verbatim}

\hypertarget{modelling-strategy-for-binary-outcomes}{%
\section{Modelling strategy for binary outcomes}\label{modelling-strategy-for-binary-outcomes}}

\index{logistic regression@\textbf{logistic regression}!model fitting principles}

A statistical model is a tool to understand the world.
The better your model describes your data, the more useful it will be.
Fitting a successful statistical model requires decisions around which variables to include in the model.
Our advice regarding variable selection follows the same lines as in the linear regression chapter.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  As few explanatory variables should be used as possible (parsimony);
\item
  Explanatory variables associated with the outcome variable in previous studies should be accounted for;
\item
  Demographic variables should be included in model exploration;
\item
  Population stratification should be incorporated if available;
\item
  Interactions should be checked and included if influential;
\item
  Final model selection should be performed using a ``criterion-based approach''
\end{enumerate}

\begin{itemize}
\tightlist
\item
  minimise the Akaike information criterion (AIC)
\item
  maximise the c-statistic (area under the receiver operator curve).
\end{itemize}

We will use these principles through the next section.

\hypertarget{fitting-logistic-regression-models-with-finalfit}{%
\section{Fitting logistic regression models with finalfit}\label{fitting-logistic-regression-models-with-finalfit}}

Our preference in model fitting is now to use our own \textbf{finalfit} package.
It gets us to our results quicker and more easily, and produces our final model tables which go directly into manuscripts for publication (we hope).

The approach is the same as in linear regression.
If the outcome variable is correctly specified as a factor, the \texttt{finalfit()} function will run a logistic regression model directly.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ "ulcer.factor"}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-18}Univariable logistic regression: 5-year survival from malignant melanoma by tumour ulceration (fit 1).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 6.68 (3.18-15.18, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-18}Model metrics: 5-year survival from malignant melanoma by tumour ulceration (fit 1).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 192.2, C-statistic = 0.717, H\&L = Chi-sq(8) 0.00 (p=1.000)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{criterion-based-model-fitting}{%
\subsection{Criterion-based model fitting}\label{criterion-based-model-fitting}}

Passing \texttt{metrics\ =\ TRUE} to \texttt{finalfit()} gives us a useful list of model fitting parameters.

We recommend looking at three metrics:

\begin{itemize}
\tightlist
\item
  Akaike information criterion (AIC), which should be minimised,
\item
  C-statistic (area under the receiver operator curve), which should be maximised;
\item
  Hosmer--Lemeshow test, which should be non-significant.
\end{itemize}

\textbf{AIC}
\index{logistic regression@\textbf{logistic regression}!AIC}
\index{AIC}

The AIC has been previously described (Section \ref{chap07-aic}).
It provides a measure of model goodness-of-fit - or how well the model fits the available data.
It is penalised for each additional variable, so should be somewhat robust against over-fitting (when the model starts to describe noise).

\textbf{C-statistic}
\index{logistic regression@\textbf{logistic regression}!C-statistic}
\index{C-statistic}

The c-statistic or area under the receiver operator curve (ROC) provides a measure of model `discrimination'.
It runs from 0.5 to 1.0, with 0.5 being no better than chance, and 1.0 being perfect fit.
What the number actually represents can be thought of like this.
Take our example of death from melanoma.
If you take a random patient who died and a random patient who did not die, then the c-statistic is the probability that the model predicts that patient 1 is more likely to die than patient 2.
In our example above, the model should get that correct 72\% of the time.

\textbf{Hosmer-Lemeshow test}
\index{logistic regression@\textbf{logistic regression}!Hosmer-Lemeshow test}
\index{Hosmer-Lemeshow test}

If you are interested in using your model for prediction, it is important that it is calibrated correctly.
Using our example, calibration means that the model accurately predicts death from melanoma when the risk to the patient is low and also accurately predicts death when the risk is high.
The model should work well across the range of probabilities of death.
The Hosmer-Lemeshow test assesses this.
By default, it assesses the predictive accuracy for death in deciles of risk.
If the model predicts equally well (or badly) at low probabilities compared with high probabilities, the null hypothesis of a difference will be rejected (meaning you get a non-significant p-value).

\hypertarget{chap09-model-fitting}{%
\section{Model fitting}\label{chap09-model-fitting}}

\index{logistic regression@\textbf{logistic regression}!model fitting}
\index{logistic regression@\textbf{logistic regression}!finalfit}

Engage with the data and the results when model fitting.
Do not use automated processes - you have to keep thinking.

Three things are important to keep looking at:

\begin{itemize}
\tightlist
\item
  what is the association between a particular variable and the outcome (OR and 95\%CI);
\item
  how much information is a variable bringing to the model (change in AIC and c-statistic);
\item
  how much influence does adding a variable have on the effect size of another variable, and in particular my variable of interest (a rule of thumb is seeing a greater than 10\% change in the OR of the variable of interest when a new variable is added to the model, suggests the new variable is important).
\end{itemize}

We're going to start by including the variables from above which we think are relevant.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{fit2 =}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-20}Multivariable logistic regression: 5-year survival from malignant melanoma (fit 2).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.21 (1.32-8.28, p=0.012)\\
Age (years) & Mean (SD) & 51.7 (16.0) & 55.3 (18.8) & 1.01 (0.99-1.03, p=0.202) & 1.00 (0.98-1.02, p=0.948)\\
\addlinespace
Sex & Female & 105 (83.3) & 21 (16.7) & - & -\\
 & Male & 55 (69.6) & 24 (30.4) & 2.18 (1.12-4.30, p=0.023) & 1.26 (0.57-2.76, p=0.558)\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & -\\
\addlinespace
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.77 (0.16-3.58, p=0.733)\\
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.98 (0.86-12.10, p=0.098)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 4.98 (1.34-21.64, p=0.021)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-20}Model metrics: 5-year survival from malignant melanoma (fit 2).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 188.1, C-statistic = 0.798, H\&L = Chi-sq(8) 3.92 (p=0.864)\\
\bottomrule
\end{tabular}}
\end{table}

The model metrics have improved with the AIC decreasing from 192 to 188 and the c-statistic increasing from 0.717 to 0.798.

Let's consider \texttt{age}.
We may expect age to be associated with the outcome because it so commonly is.
But there is weak evidence of an association in the univariable analysis.
We have shown above that the relationship of age to the outcome is not linear, therefore we need to act on this.

We can either convert age to a categorical variable or include it with a quadratic term (\(x^2 + x\), remember parabolas from school?).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{age.factor =} \KeywordTok{cut}\NormalTok{(age,}
                     \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{75}\NormalTok{, }\DecValTok{100}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Age (years)"}\NormalTok{))}

\CommentTok{# Add this to relevel:}
\CommentTok{# fct_relevel("(50,75]")}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{), }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-22}Multivariable logistic regression: using `cut` to convert a continuous variable as a factor (fit 3).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 6.28 (2.97-14.35, p<0.001)\\
Age (years) & (0,25] & 10 (71.4) & 4 (28.6) & - & -\\
\addlinespace
 & (25,50] & 62 (84.9) & 11 (15.1) & 0.44 (0.12-1.84, p=0.229) & 0.54 (0.13-2.44, p=0.400)\\
 & (50,75] & 79 (76.0) & 25 (24.0) & 0.79 (0.24-3.08, p=0.712) & 0.81 (0.22-3.39, p=0.753)\\
 & (75,100] & 9 (64.3) & 5 (35.7) & 1.39 (0.28-7.23, p=0.686) & 1.12 (0.20-6.53, p=0.894)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-22}Model metrics: using `cut` to convert a continuous variable as a factor (fit 3).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 196.6, C-statistic = 0.742, H\&L = Chi-sq(8) 0.20 (p=1.000)\\
\bottomrule
\end{tabular}}
\end{table}

There is no strong relationship between the categorical representation of age and the outcome.
Let's try a quadratic term.

In base R, a quadratic term is added like this.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glm}\NormalTok{(mort_5yr }\OperatorTok{~}\StringTok{ }\NormalTok{ulcer.factor  }\OperatorTok{+}\KeywordTok{I}\NormalTok{(age}\OperatorTok{^}\DecValTok{2}\NormalTok{) }\OperatorTok{+}\StringTok{ }\NormalTok{age, }
    \DataTypeTok{data =}\NormalTok{ melanoma, }\DataTypeTok{family =}\NormalTok{ binomial) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Call:
## glm(formula = mort_5yr ~ ulcer.factor + I(age^2) + age, family = binomial, 
##     data = melanoma)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -1.3253  -0.8973  -0.4082  -0.3889   2.2872  
## 
## Coefficients:
##                       Estimate Std. Error z value Pr(>|z|)    
## (Intercept)         -1.2636638  1.2058471  -1.048    0.295    
## ulcer.factorPresent  1.8423431  0.3991559   4.616 3.92e-06 ***
## I(age^2)             0.0006277  0.0004613   1.361    0.174    
## age                 -0.0567465  0.0476011  -1.192    0.233    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 215.78  on 204  degrees of freedom
## Residual deviance: 185.98  on 201  degrees of freedom
## AIC: 193.98
## 
## Number of Fisher Scoring iterations: 5
\end{verbatim}

\index{functions@\textbf{functions}!glm}

It can be done in \texttt{Finalfit} in a similar manner.
Note with default univariable model settings, the quadratic and linear terms are considered in separate models, which doesn't make much sense.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"I(age^2)"}\NormalTok{, }\StringTok{"age"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-25}Multivariable logistic regression: including a quadratic term (fit 4).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 6.31 (2.98-14.44, p<0.001)\\
Age (years) & Mean (SD) & 51.7 (16.0) & 55.3 (18.8) & 1.01 (0.99-1.03, p=0.202) & 0.94 (0.86-1.04, p=0.233)\\
\addlinespace
I(age\textasciicircum{}2) &  &  &  & 1.00 (1.00-1.00, p=0.101) & 1.00 (1.00-1.00, p=0.174)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-25}Model metrics: including a quadratic term (fit 4).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 194, C-statistic = 0.748, H\&L = Chi-sq(8) 5.24 (p=0.732)\\
\bottomrule
\end{tabular}}
\end{table}

The AIC is worse when adding age either as a factor or with a quadratic term to the base model.

One final method to visualise the contribution of a particular variable is to remove it from the full model.
This is convenient in \texttt{Finalfit}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, explanatory_multi, }
           \DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-27}Multivariable logistic regression model: comparing a reduced model in one table (fit 5).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable) & OR (multivariable reduced)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.06 (1.25-7.93, p=0.017) & 3.21 (1.32-8.28, p=0.012)\\
Age (years) & (0,25] & 10 (71.4) & 4 (28.6) & - & - & -\\
\addlinespace
 & (25,50] & 62 (84.9) & 11 (15.1) & 0.44 (0.12-1.84, p=0.229) & 0.37 (0.08-1.80, p=0.197) & -\\
 & (50,75] & 79 (76.0) & 25 (24.0) & 0.79 (0.24-3.08, p=0.712) & 0.60 (0.15-2.65, p=0.469) & -\\
 & (75,100] & 9 (64.3) & 5 (35.7) & 1.39 (0.28-7.23, p=0.686) & 0.61 (0.09-4.04, p=0.599) & -\\
\addlinespace
Sex & Female & 105 (83.3) & 21 (16.7) & - & - & -\\
 & Male & 55 (69.6) & 24 (30.4) & 2.18 (1.12-4.30, p=0.023) & 1.21 (0.54-2.68, p=0.633) & 1.26 (0.57-2.76, p=0.559)\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & - & -\\
\addlinespace
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.74 (0.15-3.50, p=0.697) & 0.77 (0.16-3.58, p=0.733)\\
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.91 (0.84-11.82, p=0.106) & 2.99 (0.86-12.11, p=0.097)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 5.38 (1.43-23.52, p=0.016) & 5.01 (1.37-21.52, p=0.020)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-27}Model metrics: comparing a reduced model in one table (fit 5).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 190, C-statistic = 0.802, H\&L = Chi-sq(8) 13.87 (p=0.085)\\
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 186.1, C-statistic = 0.794, H\&L = Chi-sq(8) 1.07 (p=0.998)\\
\bottomrule
\end{tabular}}
\end{table}

The AIC improves when age is removed (186 from 190) at only a small loss in discrimination (0.794 from 0.802).
Looking at the model table and comparing the full multivariable with the reduced multivariable, there has been a small change in the OR for ulceration, with some of the variation accounted for by age now being taken up by ulceration.
This is to be expected, given the association (albeit weak) that we saw earlier between age and ulceration.
Given all this, we will decide not to include age in the model.

Now what about the variable sex.
It has a significant association with the outcome in the univariable analysis, but much of this is explained by other variables in multivariable analysis.
Is it contributing much to the model?

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, explanatory_multi, }
           \DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-29}Multivariable logistic regression: further reducing the model (fit 6).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable) & OR (multivariable reduced)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.21 (1.32-8.28, p=0.012) & 3.26 (1.35-8.39, p=0.011)\\
Sex & Female & 105 (83.3) & 21 (16.7) & - & - & -\\
\addlinespace
 & Male & 55 (69.6) & 24 (30.4) & 2.18 (1.12-4.30, p=0.023) & 1.26 (0.57-2.76, p=0.559) & -\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & - & -\\
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.77 (0.16-3.58, p=0.733) & 0.75 (0.16-3.45, p=0.700)\\
\addlinespace
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.99 (0.86-12.11, p=0.097) & 2.96 (0.86-11.96, p=0.098)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 5.01 (1.37-21.52, p=0.020) & 5.33 (1.48-22.56, p=0.014)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-29}Model metrics: further reducing the model (fit 6).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 186.1, C-statistic = 0.794, H\&L = Chi-sq(8) 1.07 (p=0.998)\\
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 184.4, C-statistic = 0.791, H\&L = Chi-sq(8) 0.43 (p=1.000)\\
\bottomrule
\end{tabular}}
\end{table}

By removing sex we have improved the AIC a little (184.4 from 186.1) with a small change in the c-statistic (0.791 from 0.794).

Looking at the model table, the variation has been taken up mostly by stage 4 disease and a little by ulceration.
But there has been little change overall.
We will exclude sex from our final model as well.

As a final we can check for a first-order interaction between ulceration and T-stage.
Just to remind us what this means, a significant interaction would mean the effect of, say, ulceration on 5-year mortality would differ by T-stage.
For instance, perhaps the presence of ulceration confers a much greater risk of death in advanced deep tumours compared with earlier superficial tumours.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor*t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, explanatory_multi, }
           \DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-31}Multivariable logistic regression: including an interaction term (fit 7).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrrr}
\toprule
label & levels & No & Yes & OR (univariable) & OR (multivariable) & OR (multivariable reduced)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.26 (1.35-8.39, p=0.011) & 4.00 (0.18-41.34, p=0.274)\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & - & -\\
\addlinespace
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.75 (0.16-3.45, p=0.700) & 0.94 (0.12-5.97, p=0.949)\\
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.96 (0.86-11.96, p=0.098) & 3.76 (0.76-20.80, p=0.104)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 5.33 (1.48-22.56, p=0.014) & 2.67 (0.12-25.11, p=0.426)\\
\addlinespace
UlcerPresent:T2 & Interaction & - & - & - & - & 0.57 (0.02-21.55, p=0.730)\\
UlcerPresent:T3 & Interaction & - & - & - & - & 0.62 (0.04-17.39, p=0.735)\\
UlcerPresent:T4 & Interaction & - & - & - & - & 1.85 (0.09-94.20, p=0.716)\\
\bottomrule
\end{tabular}}
\end{table}

There are no significant interaction terms.

Our final model table is therefore:

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, explanatory_multi, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-33}Multivariable logistic regression: final model (fit 8).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.26 (1.35-8.39, p=0.011)\\
Age (years) & (0,25] & 10 (71.4) & 4 (28.6) & - & -\\
\addlinespace
 & (25,50] & 62 (84.9) & 11 (15.1) & 0.44 (0.12-1.84, p=0.229) & -\\
 & (50,75] & 79 (76.0) & 25 (24.0) & 0.79 (0.24-3.08, p=0.712) & -\\
 & (75,100] & 9 (64.3) & 5 (35.7) & 1.39 (0.28-7.23, p=0.686) & -\\
\addlinespace
Sex & Female & 105 (83.3) & 21 (16.7) & - & -\\
 & Male & 55 (69.6) & 24 (30.4) & 2.18 (1.12-4.30, p=0.023) & -\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & -\\
\addlinespace
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.75 (0.16-3.45, p=0.700)\\
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.96 (0.86-11.96, p=0.098)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 5.33 (1.48-22.56, p=0.014)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-33}Model metrics: final model (fit 8).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 184.4, C-statistic = 0.791, H\&L = Chi-sq(8) 0.43 (p=1.000)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{odds-ratio-plot}{%
\subsection{Odds ratio plot}\label{odds-ratio-plot}}

\index{logistic regression@\textbf{logistic regression}!odds ratio plot}
\index{plotting@\textbf{plotting}!odds ratio}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{or_plot}\NormalTok{(dependent, explanatory_multi,}
          \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{25}\NormalTok{),}
          \DataTypeTok{table_text_size =} \FloatTok{3.5}\NormalTok{,}
          \DataTypeTok{title_text_size =} \DecValTok{16}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Removed 2 rows containing missing values (geom_errorbarh).
\end{verbatim}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/unnamed-chunk-34-1.pdf}
\caption{\label{fig:unnamed-chunk-34}Odds ratio plot.}
\end{figure}

\index{functions@\textbf{functions}!or\_plot}
\index{plotting@\textbf{plotting}!or\_plot}

We can conclude that there is evidence of an association between tumour ulceration and 5-year survival which is independent of the tumour depth as captured by T-stage.

\hypertarget{correlated-groups-of-observations}{%
\section{Correlated groups of observations}\label{correlated-groups-of-observations}}

\index{logistic regression@\textbf{logistic regression}!correlated groups}
\index{logistic regression@\textbf{logistic regression}!mixed effects}
\index{logistic regression@\textbf{logistic regression}!random effects}
\index{logistic regression@\textbf{logistic regression}!multilevel}
\index{logistic regression@\textbf{logistic regression}!hierarchical}

In our modelling strategy above, we mentioned the incorporation of population stratification if available.
What does this mean?

Our regression is seeking to capture the characteristics of particular patients.
These characteristics are made manifest through the slopes of fitted lines - the estimated coefficients (ORs) of particular variables.
A goal is to estimate these characteristics as precisely as possible.
Bias can be introduced when correlations between patients are not accounted for.
Correlations may be as simple as being treated within the same hospital.
By virtue of this fact, these patients may have commonalities that have not been captured by the observed variables.

Population characteristics can be incorporated into our models.
We may not be interested in capturing and measuring the effects themselves, but want to ensure they are accounted for in the analysis.

One approach is to include grouping variables as \texttt{random\ effects}.
These may be nested with each other, for example patients within hospitals within countries.
These are added in addition to the \texttt{fixed\ effects} we have been dealing with up until now.

These models go under different names including mixed effects model, multilevel model, or hierarchical model.

Other approaches, such as generalized estimating equations are not dealt with here.

\hypertarget{simulate-data}{%
\subsection{Simulate data}\label{simulate-data}}

Our melanoma dataset doesn't include any higher level structure, so we will simulate this for demonstration purposes.
We have just randomly allocated 1 of 4 identifiers to each patient below.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Simulate random hospital identifier}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{hospital_id =} \KeywordTok{sample}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{4}\NormalTok{, }\DecValTok{205}\NormalTok{, }\DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{))}

\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{hospital_id =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{3}\NormalTok{, }\DecValTok{50}\NormalTok{), }\KeywordTok{rep}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{55}\NormalTok{)))}
\end{Highlighting}
\end{Shaded}

\hypertarget{plot-the-data-7}{%
\subsection{Plot the data}\label{plot-the-data-7}}

We will speak in terms of `hospitals' now, but the grouping variable(s) could clearly be anything.

The simplest random effects approach is a `random intercept model'.
This allows the intercept of fitted lines to vary by hospital.
The random intercept model constrains lines to be parallel, in a similar way to the additive models discussed above and in Chapter 7.

It is harder to demonstrate with binomial data, but we can stratify the 5-year mortality by T-stage (considered as a continuous variable for this purpose).
Note there were no deaths in `hospital 4' (Figure \ref{fig:chap09-fig-randeffects}).
We can model this accounting for inter-hospital variation below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{mort_5yr.num =} \KeywordTok{as.numeric}\NormalTok{(mort_5yr) }\OperatorTok{-}\StringTok{ }\DecValTok{1} \CommentTok{# Convert factor to 0 and 1}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =} \KeywordTok{as.numeric}\NormalTok{(t_stage.factor), }\DataTypeTok{y =}\NormalTok{ mort_5yr.num)) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_jitter}\NormalTok{(}\DataTypeTok{width =} \FloatTok{0.1}\NormalTok{, }\DataTypeTok{height =} \FloatTok{0.1}\NormalTok{) }\OperatorTok{+}
\StringTok{  }\KeywordTok{geom_smooth}\NormalTok{(}\DataTypeTok{method =} \StringTok{'loess'}\NormalTok{, }\DataTypeTok{se =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{facet_wrap}\NormalTok{(}\OperatorTok{~}\NormalTok{hospital_id) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{labs}\NormalTok{(}\DataTypeTok{x=} \StringTok{"T-stage"}\NormalTok{, }\DataTypeTok{y =} \StringTok{"Mortality (5 y)"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## `geom_smooth()` using formula 'y ~ x'
\end{verbatim}

\begin{figure}
\centering
\includegraphics{09_logistic_regression_files/figure-latex/chap09-fig-randeffects-1.pdf}
\caption{\label{fig:chap09-fig-randeffects}Investigating random effects by looking at the relationship between the outcome variable (5-year mortality) and T-stage at each hospital.}
\end{figure}

\hypertarget{mixed-effects-models-in-base-r}{%
\subsection{Mixed effects models in base R}\label{mixed-effects-models-in-base-r}}

There are a number of different packages offering mixed effects modelling in R, our preferred is \texttt{lme4}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lme4)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: Matrix
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'Matrix'
\end{verbatim}

\begin{verbatim}
## The following objects are masked from 'package:tidyr':
## 
##     expand, pack, unpack
\end{verbatim}

\begin{verbatim}
## Registered S3 methods overwritten by 'lme4':
##   method                          from
##   cooks.distance.influence.merMod car 
##   influence.merMod                car 
##   dfbeta.influence.merMod         car 
##   dfbetas.influence.merMod        car
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{glmer}\NormalTok{(mort_5yr }\OperatorTok{~}\StringTok{ }\NormalTok{t_stage.factor }\OperatorTok{+}\StringTok{ }\NormalTok{(}\DecValTok{1} \OperatorTok{|}\StringTok{ }\NormalTok{hospital_id), }
        \DataTypeTok{data =}\NormalTok{ ., }\DataTypeTok{family =} \StringTok{"binomial"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: mort_5yr ~ t_stage.factor + (1 | hospital_id)
##    Data: .
## 
##      AIC      BIC   logLik deviance df.resid 
##    174.6    191.2    -82.3    164.6      200 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -1.4507 -0.3930 -0.2891 -0.0640  3.4591 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  hospital_id (Intercept) 2.619    1.618   
## Number of obs: 205, groups:  hospital_id, 4
## 
## Fixed effects:
##                  Estimate Std. Error z value Pr(>|z|)    
## (Intercept)      -3.13132    1.01451  -3.087  0.00203 ** 
## t_stage.factorT2  0.02256    0.74792   0.030  0.97593    
## t_stage.factorT3  1.82349    0.62920   2.898  0.00375 ** 
## t_stage.factorT4  2.61190    0.62806   4.159  3.2e-05 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Correlation of Fixed Effects:
##             (Intr) t_s.T2 t_s.T3
## t_stg.fctT2 -0.365              
## t_stg.fctT3 -0.454  0.591       
## t_stg.fctT4 -0.459  0.590  0.718
\end{verbatim}

\index{functions@\textbf{functions}!glmer}

The base R output is similar to \texttt{glm()}.
It includes the standard deviation on the random effects intercept as well.
Meaning the variation between hospitals being captured by the model.

The output can be examined using \texttt{tidy()} and \texttt{glance()} functions as above.

We find it more straightforward to use finalfit.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ "t_stage.factor"}
\NormalTok{random_effect <-}\StringTok{ "hospital_id"} \CommentTok{# Is the same as:}
\NormalTok{random_effect <-}\StringTok{ "(1 | hospital_id)"}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }
           \DataTypeTok{random_effect =}\NormalTok{ random_effect,}
           \DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can incorporate our (made-up) hospital identifier into our final model from above.
Using \texttt{keep\_models\ =\ TRUE}, we can compare univariable, multivariable and mixed effects models.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"age.factor"}\NormalTok{, }
                \StringTok{"sex.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer.factor"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{)}
\NormalTok{random_effect <-}\StringTok{ "hospital_id"}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, explanatory_multi, random_effect, }
           \DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{,}
           \DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-39}Multilevel (mixed effects) logistic regression.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrrrr}
\toprule
Dependent: 5-year survival &   & No & Yes & OR (univariable) & OR (multivariable) & OR (multivariable reduced) & OR (multilevel)\\
\midrule
Ulcerated tumour & Absent & 105 (91.3) & 10 (8.7) & - & - & - & -\\
 & Present & 55 (61.1) & 35 (38.9) & 6.68 (3.18-15.18, p<0.001) & 3.06 (1.25-7.93, p=0.017) & 3.26 (1.35-8.39, p=0.011) & 2.49 (0.94-6.59, p=0.065)\\
Age (years) & (0,25] & 10 (71.4) & 4 (28.6) & - & - & - & -\\
\addlinespace
 & (25,50] & 62 (84.9) & 11 (15.1) & 0.44 (0.12-1.84, p=0.229) & 0.37 (0.08-1.80, p=0.197) & - & -\\
 & (50,75] & 79 (76.0) & 25 (24.0) & 0.79 (0.24-3.08, p=0.712) & 0.60 (0.15-2.65, p=0.469) & - & -\\
 & (75,100] & 9 (64.3) & 5 (35.7) & 1.39 (0.28-7.23, p=0.686) & 0.61 (0.09-4.04, p=0.599) & - & -\\
\addlinespace
Sex & Female & 105 (83.3) & 21 (16.7) & - & - & - & -\\
 & Male & 55 (69.6) & 24 (30.4) & 2.18 (1.12-4.30, p=0.023) & 1.21 (0.54-2.68, p=0.633) & - & -\\
T-stage & T1 & 52 (92.9) & 4 (7.1) & - & - & - & -\\
\addlinespace
 & T2 & 49 (92.5) & 4 (7.5) & 1.06 (0.24-4.71, p=0.936) & 0.74 (0.15-3.50, p=0.697) & 0.75 (0.16-3.45, p=0.700) & 0.83 (0.18-3.73, p=0.807)\\
 & T3 & 36 (70.6) & 15 (29.4) & 5.42 (1.80-20.22, p=0.005) & 2.91 (0.84-11.82, p=0.106) & 2.96 (0.86-11.96, p=0.098) & 3.83 (1.00-14.70, p=0.051)\\
 & T4 & 23 (51.1) & 22 (48.9) & 12.43 (4.21-46.26, p<0.001) & 5.38 (1.43-23.52, p=0.016) & 5.33 (1.48-22.56, p=0.014) & 7.03 (1.71-28.86, p=0.007)\\
\bottomrule
\end{tabular}}
\end{table}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-39}Model metrics: multilevel (mixed effects) logistic regression.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{18cm}}
\toprule
\\
\midrule
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 190, C-statistic = 0.802, H\&L = Chi-sq(8) 13.87 (p=0.085)\\
Number in dataframe = 205, Number in model = 205, Missing = 0, AIC = 184.4, C-statistic = 0.791, H\&L = Chi-sq(8) 0.43 (p=1.000)\\
Number in model = 205, Number of groups = 4, AIC = 173.2, C-statistic = 0.866\\
\bottomrule
\end{tabular}}
\end{table}

As can be seen, incorporating the (made-up) hospital identifier has altered our coefficients.
It has also improved the model discrimination with a c-statistic of 0.830 from 0.802.
Note that the AIC should not be used to compare mixed effects models estimated in this way with \texttt{glm()} models (the former uses a restricted maximum likelihood {[}REML{]} approach by default, while \texttt{glm()} uses maximum likelihood).

Random slope models are an extension of the random intercept model.
Here the gradient of the response to a particular variable is allowed to vary by hospital.
For example, this can be included using \texttt{random\_effect\ =\ "(thickness\ \textbar{}\ hospital\_id)"} where the gradient of the continuous variable tumour thickness was allow to vary by hospital.

As models get more complex, care has to be taken to ensure the underlying data is understood and assumptions are checked.

Mixed effects modelling is a book in itself and the purpose here is to introduce the concept and provide some approaches for its incorporation.
Clearly much is written elsewhere for those who are enthusiastic to learn more.

\hypertarget{exercises-4}{%
\section{Exercises}\label{exercises-4}}

\hypertarget{chap09-ex1}{%
\subsection{Exercise}\label{chap09-ex1}}

Investigate the association between sex and 5-year mortality for patients who have undergone surgery for melanoma.

First recode the variables as shown in the text, then plot the counts and proportions for 5-year disease-specific mortality in women and men. Is there an association between sex and mortality?

\hypertarget{chap09-ex2}{%
\subsection{Exercise}\label{chap09-ex2}}

Make a table showing the relationship between sex and the variables age, T-stage and ulceration. Hint: \texttt{summary\_factorlist()}.
Express age in terms of median and interquartile range. Include a statistical comparison.

What associations do you see?

\hypertarget{chap09-ex3}{%
\subsection{Exercise}\label{chap09-ex3}}

Run a logistic regression model for 5-year disease-specific mortality including sex, age, T-stage and ulceration.

What is the c-statistic for this model?

Is there a relationship between sex and mortality, after adjustment for the other explanatory variables?

\hypertarget{chap09-ex4}{%
\subsection{Exercise}\label{chap09-ex4}}

Make an odds ratio plot for this model.

\hypertarget{solutions-3}{%
\section{Solutions}\label{solutions-3}}

Solution to Exercise \ref{chap09-ex1}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Recode}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{sex.factor =} \KeywordTok{factor}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{          }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Female"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{,}
                      \StringTok{"Male"}\NormalTok{   =}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Sex"}\NormalTok{),   }
         
         \DataTypeTok{ulcer.factor =} \KeywordTok{factor}\NormalTok{(ulcer) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Present"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Absent"}\NormalTok{  =}\StringTok{ "0"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Ulcerated tumour"}\NormalTok{),}
         
         \DataTypeTok{age  =} \KeywordTok{ff_label}\NormalTok{(age,  }\StringTok{"Age (years)"}\NormalTok{),}
         \DataTypeTok{year =} \KeywordTok{ff_label}\NormalTok{(year, }\StringTok{"Year"}\NormalTok{),}
         
         \DataTypeTok{status.factor =} \KeywordTok{factor}\NormalTok{(status) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Died melanoma"}\NormalTok{  =}\StringTok{ "1"}\NormalTok{,}
                      \StringTok{"Alive"}\NormalTok{ =}\StringTok{ "2"}\NormalTok{,}
                      \StringTok{"Died - other"}\NormalTok{ =}\StringTok{ "3"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{fct_relevel}\NormalTok{(}\StringTok{"Alive"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Status"}\NormalTok{),}
         
         \DataTypeTok{t_stage.factor =} 
\NormalTok{           thickness }\OperatorTok{%>%}\StringTok{ }
\StringTok{           }\KeywordTok{cut}\NormalTok{(}\DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FloatTok{1.0}\NormalTok{, }\FloatTok{2.0}\NormalTok{, }\FloatTok{4.0}\NormalTok{, }
                          \KeywordTok{max}\NormalTok{(thickness, }\DataTypeTok{na.rm=}\OtherTok{TRUE}\NormalTok{)),}
               \DataTypeTok{include.lowest =} \OtherTok{TRUE}\NormalTok{)}
\NormalTok{  )}

\CommentTok{# Plot}
\NormalTok{p1 <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sex.factor, }\DataTypeTok{fill =}\NormalTok{ mort_5yr)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{() }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{theme}\NormalTok{(}\DataTypeTok{legend.position =} \StringTok{"none"}\NormalTok{)}

\NormalTok{p2 <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ggplot}\NormalTok{(}\KeywordTok{aes}\NormalTok{(}\DataTypeTok{x =}\NormalTok{ sex.factor, }\DataTypeTok{fill =}\NormalTok{ mort_5yr)) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{geom_bar}\NormalTok{(}\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{) }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{ylab}\NormalTok{(}\StringTok{"proportion"}\NormalTok{)}

\NormalTok{p1 }\OperatorTok{+}\StringTok{ }\NormalTok{p2}
\end{Highlighting}
\end{Shaded}

Solution to Exercise \ref{chap09-ex2}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{## Recode T-stage first}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{t_stage.factor =} 
      \KeywordTok{fct_recode}\NormalTok{(t_stage.factor,}
                 \DataTypeTok{T1 =} \StringTok{"[0,1]"}\NormalTok{,}
                 \DataTypeTok{T2 =} \StringTok{"(1,2]"}\NormalTok{,}
                 \DataTypeTok{T3 =} \StringTok{"(2,4]"}\NormalTok{,}
                 \DataTypeTok{T4 =} \StringTok{"(4,17.4]"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"T-stage"}\NormalTok{)}
\NormalTok{  )}

\NormalTok{dependent =}\StringTok{ "sex.factor"}
\NormalTok{explanatory =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{, }\StringTok{"ulcer.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent, explanatory, }\DataTypeTok{p =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na_include =} \OtherTok{TRUE}\NormalTok{,}
                     \DataTypeTok{cont =} \StringTok{"median"}\NormalTok{)}

\CommentTok{# Men have more T4 tumours and they are more likely to be ulcerated. }
\end{Highlighting}
\end{Shaded}

Solution to Exercise \ref{chap09-ex3}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent =}\StringTok{ "mort_5yr"}
\NormalTok{explanatory =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{, }\StringTok{"ulcer.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{metrics =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# c-statistic = 0.798}
\CommentTok{# In multivariable model, male vs female OR 1.26 (0.57-2.76, p=0.558).}
\CommentTok{# No relationship after accounting for T-stage and tumour ulceration. }
\CommentTok{# Sex is confounded by these two variables. }
\end{Highlighting}
\end{Shaded}

Solution to Exercise \ref{chap09-ex4}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent =}\StringTok{ "mort_5yr"}
\NormalTok{explanatory =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"sex.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"t_stage.factor"}\NormalTok{, }\StringTok{"ulcer.factor"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{or_plot}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\hypertarget{chap10-h1}{%
\chapter{Time-to-event data and survival}\label{chap10-h1}}

\index{time-to-event / survival@\textbf{time-to-event / survival}}

\begin{quote}
The reports of my death have been greatly exaggerated.\\
Mark Twain
\end{quote}

In healthcare, we deal with a lot of binary outcomes.
Death yes/no or disease recurrence yes/no for instance.
These outcomes are often easily analysed using binary logistic regression as described in the previous chapter.

When the time taken for the outcome to occur is important, we need a different approach.
For instance, in patients with cancer, the time taken until recurrence of the cancer is often just as important as the fact it has recurred.

\hypertarget{the-question-5}{%
\section{The Question}\label{the-question-5}}

We will again use the classic ``Survival from Malignant Melanoma'' dataset included in the \textbf{boot} package which we have used previously.
The data consist of measurements made on patients with malignant melanoma.
Each patient had their tumour removed by surgery at the Department of Plastic Surgery, University Hospital of Odense, Denmark, during the period 1962 to 1977.

We are interested in the association between tumour ulceration and survival after surgery.

\hypertarget{get-and-check-the-data}{%
\section{Get and check the data}\label{get-and-check-the-data}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{boot}\OperatorTok{::}\NormalTok{melanoma }\CommentTok{#F1 here for help page with data dictionary}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{glimpse}\NormalTok{(melanoma)}
\KeywordTok{missing_glimpse}\NormalTok{(melanoma)}
\KeywordTok{ff_glimpse}\NormalTok{(melanoma)}
\end{Highlighting}
\end{Shaded}

As was seen before, all variables are coded as numeric and some need recoding to factors.
This is done below for those we are interested in.

\hypertarget{death-status}{%
\section{Death status}\label{death-status}}

\texttt{status} is the patient's status at the end of the study.

\begin{itemize}
\tightlist
\item
  1 indicates that they had died from melanoma;
\item
  2 indicates that they were still alive and;
\item
  3 indicates that they had died from causes unrelated to their melanoma.
\end{itemize}

There are three options for coding this.

\begin{itemize}
\tightlist
\item
  Overall survival: considering all-cause mortality, comparing 2 (alive) with 1 (died melanoma)/3 (died other);
\item
  Cause-specific survival: considering disease-specific mortality comparing 2 (alive)/3 (died other) with 1 (died melanoma);
\item
  Competing risks: comparing 2 (alive) with 1 (died melanoma) accounting for 3 (died other); see more below.
\end{itemize}

\hypertarget{time-and-censoring}{%
\section{Time and censoring}\label{time-and-censoring}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!censoring}
\texttt{time} is the number of days from surgery until either the occurrence of the event (death) or the last time the patient was known to be alive.
For instance, if a patient had surgery and was seen to be well in a clinic 30 days later, but there had been no contact since, then the patient's status would be considered alive at 30 days.
This patient is censored from the analysis at day 30, an important feature of time-to-event analyses.

\hypertarget{recode-the-data-1}{%
\section{Recode the data}\label{recode-the-data-1}}

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(forcats)}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \CommentTok{# Overall survival}
    \DataTypeTok{status_os =} \KeywordTok{if_else}\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\CommentTok{# "still alive"}
                       \DecValTok{1}\NormalTok{), }\CommentTok{# "died of melanoma" or "died of other causes"}
    
    \CommentTok{# Diease-specific survival}
    \DataTypeTok{status_dss =} \KeywordTok{if_else}\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\CommentTok{# "still alive"}
                        \KeywordTok{if_else}\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\CommentTok{# "died of melanoma"}
                               \DecValTok{0}\NormalTok{)), }\CommentTok{# "died of other causes is censored"}
    
    \CommentTok{# Competing risks regression}
    \DataTypeTok{status_crr =} \KeywordTok{if_else}\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\CommentTok{# "still alive"}
                        \KeywordTok{if_else}\NormalTok{(status }\OperatorTok{==}\StringTok{ }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\CommentTok{# "died of melanoma"}
                               \DecValTok{2}\NormalTok{)), }\CommentTok{# "died of other causes"}
    
    \CommentTok{# Label and recode other variables}
    \DataTypeTok{age =} \KeywordTok{ff_label}\NormalTok{(age, }\StringTok{"Age (years)"}\NormalTok{), }\CommentTok{# ff_label table friendly  labels}
    \DataTypeTok{thickness =} \KeywordTok{ff_label}\NormalTok{(thickness, }\StringTok{"Tumour thickness (mm)"}\NormalTok{),}
    \DataTypeTok{sex =} \KeywordTok{factor}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Male"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{, }
                 \StringTok{"Female"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Sex"}\NormalTok{),}
    \DataTypeTok{ulcer =} \KeywordTok{factor}\NormalTok{(ulcer) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"No"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{,}
                 \StringTok{"Yes"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Ulcerated tumour"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

\hypertarget{kaplan-meier-survival-estimator}{%
\section{Kaplan Meier survival estimator}\label{kaplan-meier-survival-estimator}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!Kaplan Meier estimator}
\index{Kaplan Meier estimator}
\index{time-to-event / survival@\textbf{time-to-event / survival}!log-rank test}
\index{log-rank test}

We will use the excellent \textbf{survival} package to produce the Kaplan Meier (KM) survival estimator (\citet{therneau2000}, \citet{therneau2020}).
This is a non-parametric statistic used to estimate the survival function from time-to-event data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(survival)}

\NormalTok{survival_object <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%$%}\StringTok{ }
\StringTok{    }\KeywordTok{Surv}\NormalTok{(time, status_os)}

\CommentTok{# Explore:}
\KeywordTok{head}\NormalTok{(survival_object) }\CommentTok{# + marks censoring, in this case "Alive"}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1]  10   30   35+  99  185  204
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Expressing time in years}
\NormalTok{survival_object <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%$%}\StringTok{ }
\StringTok{    }\KeywordTok{Surv}\NormalTok{(time}\OperatorTok{/}\DecValTok{365}\NormalTok{, status_os)}
\end{Highlighting}
\end{Shaded}

\index{functions@\textbf{functions}!Surv}

\hypertarget{km-analysis-for-whole-cohort}{%
\subsection{KM analysis for whole cohort}\label{km-analysis-for-whole-cohort}}

\hypertarget{model}{%
\subsection{Model}\label{model}}

The survival object is the first step to performing univariable and multivariable survival analyses.

If you want to plot survival stratified by a single grouping variable, you can substitute ``survival\_object \textasciitilde{} 1'' by ``survival\_object \textasciitilde{} factor''

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Overall survival in whole cohort}
\NormalTok{my_survfit <-}\StringTok{ }\KeywordTok{survfit}\NormalTok{(survival_object }\OperatorTok{~}\StringTok{ }\DecValTok{1}\NormalTok{, }\DataTypeTok{data =}\NormalTok{ melanoma)}
\NormalTok{my_survfit }\CommentTok{# 205 patients, 71 events}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: survfit(formula = survival_object ~ 1, data = melanoma)
## 
##       n  events  median 0.95LCL 0.95UCL 
##  205.00   71.00      NA    9.15      NA
\end{verbatim}

\index{functions@\textbf{functions}!survfit}

\hypertarget{life-table}{%
\subsection{Life table}\label{life-table}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!life table}

A life table is the tabular form of a KM plot, which you may be familiar with.
It shows survival as a proportion, together with confidence limits.
The whole table is shown with, \texttt{summary(my\_survfit)}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{summary}\NormalTok{(my_survfit, }\DataTypeTok{times =} \KeywordTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call: survfit(formula = survival_object ~ 1, data = melanoma)
## 
##  time n.risk n.event survival std.err lower 95% CI upper 95% CI
##     0    205       0    1.000  0.0000        1.000        1.000
##     1    193      11    0.946  0.0158        0.916        0.978
##     2    183      10    0.897  0.0213        0.856        0.940
##     3    167      16    0.819  0.0270        0.767        0.873
##     4    160       7    0.784  0.0288        0.730        0.843
##     5    122      10    0.732  0.0313        0.673        0.796
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# 5 year overall survival is 73%}
\end{Highlighting}
\end{Shaded}

\hypertarget{kaplan-meier-plot}{%
\section{Kaplan Meier plot}\label{kaplan-meier-plot}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!Kaplan Meier plot}

We can plot survival curves using the \textbf{finalfit} wrapper for the package \textbf{survminer}.
There are numerous options available on the help page.
You should always include a number-at-risk table under these plots as it is essential for interpretation.

As can be seen, the probability of dying is much greater if the tumour was ulcerated, compared to those that were not ulcerated.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent_os <-}\StringTok{ "Surv(time/365, status_os)"}
\NormalTok{explanatory  <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"ulcer"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{surv_plot}\NormalTok{(dependent_os, explanatory, }\DataTypeTok{pval =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Warning: Vectorized input to `element_text()` is not officially supported.
## Results may be unexpected or may change in future versions of ggplot2.
\end{verbatim}

\includegraphics{10_survival_files/figure-latex/unnamed-chunk-8-1.pdf}

\index{functions@\textbf{functions}!surv\_plot}
\index{plotting@\textbf{plotting}!surv\_plot}

\hypertarget{cox-proportional-hazards-regression}{%
\section{Cox proportional hazards regression}\label{cox-proportional-hazards-regression}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!Cox proportional hazards regression}
\index{Cox proportional hazards regression}

The Cox proportional hazards model is a regression model similar to those we have already dealt with.
It is commonly used to investigate the association between the time to an event (such as death) and a set of explanatory variables.

Cox proportional hazards regression can be performed using \texttt{survival::coxph()} or the all-in-one \texttt{finalfit()} function.
The latter produces a table containing counts (proportions) for factors, mean (SD) for continuous variables and a univariable and multivariable CPH regression.

\hypertarget{coxph}{%
\subsection{\texorpdfstring{\texttt{coxph()}}{coxph()}}\label{coxph}}

CPH using the \texttt{coxph()} function produces a similar output to \texttt{lm()} and \texttt{glm()}, so it should be familiar to you now.
It can be passed to \texttt{summary()} as below, and also to \texttt{broom::tidy()} if you want to get the results into a tibble.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(survival)}
\KeywordTok{coxph}\NormalTok{(}\KeywordTok{Surv}\NormalTok{(time, status_os) }\OperatorTok{~}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{sex }\OperatorTok{+}\StringTok{ }\NormalTok{thickness }\OperatorTok{+}\StringTok{ }\NormalTok{ulcer, }\DataTypeTok{data =}\NormalTok{ melanoma) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## coxph(formula = Surv(time, status_os) ~ age + sex + thickness + 
##     ulcer, data = melanoma)
## 
##   n= 205, number of events= 71 
## 
##               coef exp(coef) se(coef)     z Pr(>|z|)    
## age       0.021831  1.022071 0.007752 2.816 0.004857 ** 
## sexMale   0.413460  1.512040 0.240132 1.722 0.085105 .  
## thickness 0.099467  1.104582 0.034455 2.887 0.003891 ** 
## ulcerYes  0.952083  2.591100 0.267966 3.553 0.000381 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
##           exp(coef) exp(-coef) lower .95 upper .95
## age           1.022     0.9784    1.0067     1.038
## sexMale       1.512     0.6614    0.9444     2.421
## thickness     1.105     0.9053    1.0325     1.182
## ulcerYes      2.591     0.3859    1.5325     4.381
## 
## Concordance= 0.739  (se = 0.03 )
## Likelihood ratio test= 47.89  on 4 df,   p=1e-09
## Wald test            = 46.72  on 4 df,   p=2e-09
## Score (logrank) test = 52.77  on 4 df,   p=1e-10
\end{verbatim}

The output shows the number of patients and the number of events.
The coefficient can be exponentiated and interpreted as a \textbf{hazard ratio}, \texttt{exp(coef)}.
Helpfully, 95\% confidence intervals are also provided.

A hazard is the term given to the rate at which events happen.
The probability that an event will happen over a period of time is the hazard multiplied by the time interval.
An assumption of CPH is that hazards are constant over time (see below).

For a given predictor then, the hazard in one group (say males) would be expected to be a constant proportion of the hazard in another group (say females).
The ratio of these hazards is, unsurprisingly, the hazard ratio.

The hazard ratio differs from the relative risk and odds ratio.
The hazard ratio represents the difference in the risk of an event at any given time, whereas the relative risk or odds ratio usually represents the cumulative risk over a period of time.

\hypertarget{finalfit}{%
\subsection{\texorpdfstring{\texttt{finalfit()}}{finalfit()}}\label{finalfit}}

Alternatively, a CPH regression can be run with \textbf{finalfit} functions.
This is convenient for model fitting, exploration and the export of results.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent_os  <-}\StringTok{ "Surv(time, status_os)"}
\NormalTok{dependent_dss <-}\StringTok{ "Surv(time, status_dss)"}
\NormalTok{dependent_crr <-}\StringTok{ "Surv(time, status_crr)"}
\NormalTok{explanatory   <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{)}

\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory)}
\end{Highlighting}
\end{Shaded}

The labelling of the final table can be adjusted as desired.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory, }\DataTypeTok{add_dependent_label =} \OtherTok{FALSE}\NormalTok{) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\StringTok{"Overall survival"}\NormalTok{ =}\StringTok{ }\NormalTok{label) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\StringTok{" "}\NormalTok{ =}\StringTok{ }\NormalTok{levels) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{rename}\NormalTok{(}\StringTok{"  "}\NormalTok{ =}\StringTok{ }\NormalTok{all)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-13}Univariable and multivariable Cox Proportional Hazards: Overall survival following surgery for melanoma by patient and tumour variables (tidied).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Overall survival &   &    & HR (univariable) & HR (multivariable)\\
\midrule
Age (years) & Mean (SD) & 52.5 (16.7) & 1.03 (1.01-1.05, p<0.001) & 1.02 (1.01-1.04, p=0.005)\\
Sex & Female & 126 (100.0) & - & -\\
 & Male & 79 (100.0) & 1.93 (1.21-3.07, p=0.006) & 1.51 (0.94-2.42, p=0.085)\\
\addlinespace
Tumour thickness (mm) & Mean (SD) & 2.9 (3.0) & 1.16 (1.10-1.23, p<0.001) & 1.10 (1.03-1.18, p=0.004)\\
Ulcerated tumour & No & 115 (100.0) & - & -\\
 & Yes & 90 (100.0) & 3.52 (2.14-5.80, p<0.001) & 2.59 (1.53-4.38, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{reduced-model}{%
\subsection{Reduced model}\label{reduced-model}}

If you are using a backwards selection approach or similar, a reduced model can be directly specified and compared.
The full model can be kept or dropped.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory_multi <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory, }
\NormalTok{             explanatory_multi, }\DataTypeTok{keep_models =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-15}Cox Proportional Hazards: Overall survival following surgery for melanoma with reduced model.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Dependent: Surv(time, status\_os) &   & all & HR (univariable) & HR (multivariable) & HR (multivariable reduced)\\
\midrule
Age (years) & Mean (SD) & 52.5 (16.7) & 1.03 (1.01-1.05, p<0.001) & 1.02 (1.01-1.04, p=0.005) & 1.02 (1.01-1.04, p=0.003)\\
Sex & Female & 126 (100.0) & - & - & -\\
 & Male & 79 (100.0) & 1.93 (1.21-3.07, p=0.006) & 1.51 (0.94-2.42, p=0.085) & -\\
\addlinespace
Tumour thickness (mm) & Mean (SD) & 2.9 (3.0) & 1.16 (1.10-1.23, p<0.001) & 1.10 (1.03-1.18, p=0.004) & 1.10 (1.03-1.18, p=0.003)\\
Ulcerated tumour & No & 115 (100.0) & - & - & -\\
 & Yes & 90 (100.0) & 3.52 (2.14-5.80, p<0.001) & 2.59 (1.53-4.38, p<0.001) & 2.72 (1.61-4.57, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{testing-for-proportional-hazards}{%
\subsection{Testing for proportional hazards}\label{testing-for-proportional-hazards}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!assumptions}
\index{time-to-event / survival@\textbf{time-to-event / survival}!testing for proportional hazards}

An assumption of CPH regression is that the hazard (think risk) associated with a particular variable does not change over time.
For example, is the magnitude of the increase in risk of death associated with tumour ulceration the same in the early post-operative period as it is in later years?

The \texttt{cox.zph()} function from the \textbf{survival} package allows us to test this assumption for each variable.
The plot of scaled Schoenfeld residuals should be a horizontal line.
The included hypothesis test identifies whether the gradient differs from zero for each variable.
No variable significantly differs from zero at the 5\% significance level.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{, }\StringTok{"year"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{coxphmulti}\NormalTok{(dependent_os, explanatory) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{cox.zph}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\NormalTok{\{zph_result <<-}\StringTok{ }\NormalTok{.\} }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{plot}\NormalTok{(}\DataTypeTok{var=}\DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{10_survival_files/figure-latex/unnamed-chunk-16-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{zph_result}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           chisq df     p
## age       2.067  1 0.151
## sex       0.505  1 0.477
## thickness 2.837  1 0.092
## ulcer     4.325  1 0.038
## year      0.451  1 0.502
## GLOBAL    7.891  5 0.162
\end{verbatim}

\index{functions@\textbf{functions}!cox.zph}

\hypertarget{stratified-models}{%
\subsection{Stratified models}\label{stratified-models}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!stratified models}

One approach to dealing with a violation of the proportional hazards assumption is to stratify by that variable.
Including a \texttt{strata()} term will result in a separate baseline hazard function being fit for each level in the stratification variable. It will be no longer possible to make direct inference on the effect associated with that variable.

This can be incorporated directly into the explanatory variable list.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }
               \StringTok{"strata(year)"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-18}Cox Proportional Hazards: Overall survival following surgery for melanoma stratified by year of surgery.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Dependent: Surv(time, status\_os) &   & all & HR (univariable) & HR (multivariable)\\
\midrule
Age (years) & Mean (SD) & 52.5 (16.7) & 1.03 (1.01-1.05, p<0.001) & 1.03 (1.01-1.05, p=0.002)\\
Sex & Female & 126 (100.0) & - & -\\
 & Male & 79 (100.0) & 1.93 (1.21-3.07, p=0.006) & 1.75 (1.06-2.87, p=0.027)\\
\addlinespace
Ulcerated tumour & No & 115 (100.0) & - & -\\
 & Yes & 90 (100.0) & 3.52 (2.14-5.80, p<0.001) & 2.61 (1.47-4.63, p=0.001)\\
Tumour thickness (mm) & Mean (SD) & 2.9 (3.0) & 1.16 (1.10-1.23, p<0.001) & 1.08 (1.01-1.16, p=0.027)\\
\addlinespace
strata(year) &  &  & - & -\\
\bottomrule
\end{tabular}}
\end{table}

\index{functions@\textbf{functions}!strata}

\hypertarget{correlated-groups-of-observations-1}{%
\subsection{Correlated groups of observations}\label{correlated-groups-of-observations-1}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!correlated groups}
\index{time-to-event / survival@\textbf{time-to-event / survival}!mixed effects}
\index{time-to-event / survival@\textbf{time-to-event / survival}!random effects}
\index{time-to-event / survival@\textbf{time-to-event / survival}!multilevel}
\index{time-to-event / survival@\textbf{time-to-event / survival}!cluster}
\index{time-to-event / survival@\textbf{time-to-event / survival}!frailty}

As a general rule, you should always try to account for any higher structure in your data within the model.
For instance, patients may be clustered within particular hospitals.

There are two broad approaches to dealing with correlated groups of observations.

Adding a \texttt{cluster()} term is similar to a generalised estimating equations (GEE) approach (something we're not covering in this book).
Here, a standard CPH model is fitted but the standard errors of the estimated hazard ratios are adjusted to account for correlations.

A \texttt{frailty()} term implies a mixed effects model, where specific random effects term(s) are directly incorporated into the model.

Both approaches achieve the same goal in different ways.
Volumes have been written on GEE vs mixed effects models and we won't rehearse them in this introductory book.
We favour the latter approach because of its flexibility and our preference for mixed effects modelling in generalised linear modelling.
Note \texttt{cluster()} and \texttt{frailty()} terms cannot be combined in the same model.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Simulate random hospital identifier}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{hospital_id =} \KeywordTok{c}\NormalTok{(}\KeywordTok{rep}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{), }\KeywordTok{rep}\NormalTok{(}\DecValTok{11}\NormalTok{, }\DecValTok{5}\NormalTok{)))}

\CommentTok{# Cluster model}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{, }
                \StringTok{"cluster(hospital_id)"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory) }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{mykable}\NormalTok{(}\DataTypeTok{caption =} \StringTok{"Cox Proportional Hazards: Overall survival following surgery for melanoma with robust standard errors (cluster model)."}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  Dependent: Surv(time, status_os)                   all
##                       Age (years) Mean (SD) 52.5 (16.7)
##                               Sex    Female 126 (100.0)
##                                        Male  79 (100.0)
##             Tumour thickness (mm) Mean (SD)   2.9 (3.0)
##                  Ulcerated tumour        No 115 (100.0)
##                                         Yes  90 (100.0)
##              cluster(hospital_id)                      
##           HR (univariable)        HR (multivariable)
##  1.03 (1.01-1.05, p<0.001) 1.02 (1.00-1.04, p=0.016)
##                          -                         -
##  1.93 (1.21-3.07, p=0.006) 1.51 (1.10-2.08, p=0.011)
##  1.16 (1.10-1.23, p<0.001) 1.10 (1.04-1.17, p<0.001)
##                          -                         -
##  3.52 (2.14-5.80, p<0.001) 2.59 (1.61-4.16, p<0.001)
##                          -                         -
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Frailty model}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{, }
                \StringTok{"frailty(hospital_id)"}\NormalTok{)}
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{finalfit}\NormalTok{(dependent_os, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-22}Cox Proportional Hazards: Overall survival following surgery for melanoma (frailty model).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Dependent: Surv(time, status\_os) &   & all & HR (univariable) & HR (multivariable)\\
\midrule
Age (years) & Mean (SD) & 52.5 (16.7) & 1.03 (1.01-1.05, p<0.001) & 1.02 (1.01-1.04, p=0.005)\\
Sex & Female & 126 (100.0) & - & -\\
 & Male & 79 (100.0) & 1.93 (1.21-3.07, p=0.006) & 1.51 (0.94-2.42, p=0.085)\\
\addlinespace
Tumour thickness (mm) & Mean (SD) & 2.9 (3.0) & 1.16 (1.10-1.23, p<0.001) & 1.10 (1.03-1.18, p=0.004)\\
Ulcerated tumour & No & 115 (100.0) & - & -\\
 & Yes & 90 (100.0) & 3.52 (2.14-5.80, p<0.001) & 2.59 (1.53-4.38, p<0.001)\\
\addlinespace
frailty(hospital\_id) &  &  & - & -\\
\bottomrule
\end{tabular}}
\end{table}

The \texttt{frailty()} method here is being superseded by the \textbf{coxme} package, and we look forward to incorporating this in the future.

\hypertarget{hazard-ratio-plot}{%
\subsection{Hazard ratio plot}\label{hazard-ratio-plot}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!hazard ratio plot}
\index{plots@\textbf{plots}!hazard ratio plot}

A plot of any of the above models can be produced using the \texttt{hr\_plot()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{    }\KeywordTok{hr_plot}\NormalTok{(dependent_os, explanatory)}
\end{Highlighting}
\end{Shaded}

\hypertarget{competing-risks-regression}{%
\section{Competing risks regression}\label{competing-risks-regression}}

\index{time-to-event / survival@\textbf{time-to-event / survival}!competing risks regression}

Competing-risks regression is an alternative to CPH regression.
It can be useful if the outcome of interest may not be able to occur simply because something else (like death) has happened first.
For instance, in our example it is obviously not possible for a patient to die from melanoma if they have died from another disease first.
By simply looking at cause-specific mortality (deaths from melanoma) and considering other deaths as censored, bias may result in estimates of the influence of predictors.

The approach by Fine and Gray is one option for dealing with this.
It is implemented in the package \textbf{cmprsk}.
The \texttt{crr()} syntax differs from \texttt{survival::coxph()} but \texttt{finalfit} brings these together.

It uses the \texttt{finalfit::ff\_merge()} function, which can join any number of models together.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory   <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex"}\NormalTok{, }\StringTok{"thickness"}\NormalTok{, }\StringTok{"ulcer"}\NormalTok{)}
\NormalTok{dependent_dss <-}\StringTok{ "Surv(time, status_dss)"}
\NormalTok{dependent_crr <-}\StringTok{ "Surv(time, status_crr)"}

\NormalTok{melanoma }\OperatorTok{%>%}
\StringTok{    }\CommentTok{# Summary table}
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent_dss, explanatory, }
                     \DataTypeTok{column =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{fit_id =} \OtherTok{TRUE}\NormalTok{) }\OperatorTok{%>%}
\StringTok{    }\CommentTok{# CPH univariable}
\StringTok{      }\KeywordTok{ff_merge}\NormalTok{(}
\NormalTok{    melanoma }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{coxphmulti}\NormalTok{(dependent_dss, explanatory) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{fit2df}\NormalTok{(}\DataTypeTok{estimate_suffix =} \StringTok{" (DSS CPH univariable)"}\NormalTok{)}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\CommentTok{# CPH multivariable}
\StringTok{  }\KeywordTok{ff_merge}\NormalTok{(}
\NormalTok{    melanoma }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{coxphmulti}\NormalTok{(dependent_dss, explanatory) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{fit2df}\NormalTok{(}\DataTypeTok{estimate_suffix =} \StringTok{" (DSS CPH multivariable)"}\NormalTok{)}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{    }\CommentTok{# Fine and Gray competing risks regression}
\StringTok{  }\KeywordTok{ff_merge}\NormalTok{(}
\NormalTok{    melanoma }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{crrmulti}\NormalTok{(dependent_crr, explanatory) }\OperatorTok{%>%}
\StringTok{      }\KeywordTok{fit2df}\NormalTok{(}\DataTypeTok{estimate_suffix =} \StringTok{" (competing risks multivariable)"}\NormalTok{)}
\NormalTok{    ) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\NormalTok{fit_id, }\OperatorTok{-}\NormalTok{index) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{dependent_label}\NormalTok{(melanoma, }\StringTok{"Survival"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Dependent variable is a survival object
\end{verbatim}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-26}Cox Proportional Hazards and competing risks regression combined.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Dependent: Survival &   & all & HR (DSS CPH univariable) & HR (DSS CPH multivariable) & HR (competing risks multivariable)\\
\midrule
Age (years) & Mean (SD) & 52.5 (16.7) & 1.01 (1.00-1.03, p=0.141) & 1.01 (1.00-1.03, p=0.141) & 1.01 (0.99-1.02, p=0.520)\\
Sex & Female & 126 (61.5) & - & - & -\\
 & Male & 79 (38.5) & 1.54 (0.91-2.60, p=0.106) & 1.54 (0.91-2.60, p=0.106) & 1.50 (0.87-2.57, p=0.140)\\
\addlinespace
Tumour thickness (mm) & Mean (SD) & 2.9 (3.0) & 1.12 (1.04-1.20, p=0.004) & 1.12 (1.04-1.20, p=0.004) & 1.09 (1.01-1.18, p=0.019)\\
Ulcerated tumour & No & 115 (56.1) & - & - & -\\
 & Yes & 90 (43.9) & 3.20 (1.75-5.88, p<0.001) & 3.20 (1.75-5.88, p<0.001) & 3.09 (1.71-5.60, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{summary-2}{%
\section{Summary}\label{summary-2}}

So here we have presented the various aspects of time-to-event analysis which are commonly used when looking at survival.
There are many other applications, some of which may not be obvious: for instance we use CPH for modelling length of stay in hospital.

Stratification can be used to deal with non-proportional hazards in a particular variable.

Hierarchical structure in your data can be accommodated with cluster or frailty (random effects) terms.

Competing risks regression may be useful if your outcome is in competition with another, such as all-cause death, but is currently limited in its ability to accommodate hierarchical structures.

\hypertarget{dates-in-r}{%
\section{Dates in R}\label{dates-in-r}}

\hypertarget{converting-dates-to-survival-time}{%
\subsection{Converting dates to survival time}\label{converting-dates-to-survival-time}}

In the melanoma example dataset, we already had the time in a convenient format for survival analysis - survival time in days since the operation.
This section shows how to convert dates into ``days from event''.
First we will generate a dummy operation date and censoring date based on the melanoma data.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(lubridate)}
\NormalTok{first_date <-}\StringTok{ }\KeywordTok{ymd}\NormalTok{(}\StringTok{"1966-01-01"}\NormalTok{)           }\CommentTok{# create made-up dates for operations}
\NormalTok{last_date  <-}\StringTok{ }\NormalTok{first_date }\OperatorTok{+}\StringTok{ }
\StringTok{  }\KeywordTok{days}\NormalTok{(}\KeywordTok{nrow}\NormalTok{(melanoma)}\OperatorTok{-}\DecValTok{1}\NormalTok{)                  }\CommentTok{# every day from 1-Jan 1966}
\NormalTok{operation_date <-}\StringTok{ }
\StringTok{  }\KeywordTok{seq}\NormalTok{(}\DataTypeTok{from =}\NormalTok{ first_date, }
      \DataTypeTok{to =}\NormalTok{ last_date, }\DataTypeTok{by =} \StringTok{"1 day"}\NormalTok{)       }\CommentTok{# create dates}

\NormalTok{melanoma}\OperatorTok{$}\NormalTok{operation_date <-}\StringTok{ }\NormalTok{operation_date }\CommentTok{# add sequence to melanoma dataset}
\end{Highlighting}
\end{Shaded}

Now we will create a `censoring' date by adding \texttt{time} from the melanoma dataset to our made up operation date.

Remember the censoring date is either when an event occurred (e.g., death) or the last known alive status of the patient.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{censoring_date =}\NormalTok{ operation_date }\OperatorTok{+}\StringTok{ }\KeywordTok{days}\NormalTok{(time))}

\CommentTok{# (Same as doing:):}
\NormalTok{melanoma}\OperatorTok{$}\NormalTok{censoring_date <-}\StringTok{ }\NormalTok{melanoma}\OperatorTok{$}\NormalTok{operation_date }\OperatorTok{+}\StringTok{ }\KeywordTok{days}\NormalTok{(melanoma}\OperatorTok{$}\NormalTok{time)}
\end{Highlighting}
\end{Shaded}

Now consider if we only had the \texttt{operation\ date} and \texttt{censoring\ date}.
We want to create the \texttt{time} variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{time_days =}\NormalTok{ censoring_date }\OperatorTok{-}\StringTok{ }\NormalTok{operation_date)}
\end{Highlighting}
\end{Shaded}

The \texttt{Surv()} function expects a number (\texttt{numeric} variable), rather than a \texttt{date} object, so we'll convert it:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# This doesn't work }
\CommentTok{# Surv(melanoma$time_days, melanoma$status==1)}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}\DataTypeTok{time_days_numeric =} \KeywordTok{as.numeric}\NormalTok{(time_days))}

\CommentTok{# This works as exepcted. }
\KeywordTok{Surv}\NormalTok{(melanoma}\OperatorTok{$}\NormalTok{time_days_numeric, melanoma}\OperatorTok{$}\NormalTok{status.factor }\OperatorTok{==}\StringTok{ "Died"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{exercises-5}{%
\section{Exercises}\label{exercises-5}}

\hypertarget{chap10-ex1}{%
\subsection{Exercise}\label{chap10-ex1}}

Using the above scripts, perform a univariable Kaplan Meier analysis to determine if \texttt{ulcer} influences overall survival. Hint: \texttt{survival\_object\ \textasciitilde{}\ ulcer}.

Try modifying the plot produced (see Help for ggsurvplot). For example:

\begin{itemize}
\tightlist
\item
  Add in a median survival line: \texttt{surv.median.line="hv"}
\item
  Alter the plot legend: \texttt{legend.title\ =\ "Ulcer\ Present",\ legend.labs\ =\ c("No",\ "Yes")}
\item
  Change the y-axis to a percentage: \texttt{ylab\ =\ "Probability\ of\ survival\ (\%)",\ surv.scale\ =\ "percent"}
\item
  Display follow-up up to 10 years, and change the scale to 1 year: \texttt{xlim\ =\ c(0,10),\ break.time.by\ =\ 1)}
\end{itemize}

\hypertarget{chap10-ex2}{%
\subsection{Exercise}\label{chap10-ex2}}

Create a new CPH model, but now include the variable \texttt{thickness} as a variable.

\begin{itemize}
\tightlist
\item
  How would you interpret the output?
\item
  Is it an independent predictor of overall survival in this model?
\item
  Are CPH assumptions maintained?
\end{itemize}

\hypertarget{solutions-4}{%
\section{Solutions}\label{solutions-4}}

Solution to Exercise \ref{chap10-ex1}:

\begin{verbatim}
## Call: survfit(formula = survival_object ~ ulcer, data = melanoma)
## 
##                 ulcer=No 
##  time n.risk n.event survival std.err lower 95% CI upper 95% CI
##     0    115       0    1.000  0.0000        1.000        1.000
##     1    112       2    0.983  0.0122        0.959        1.000
##     2    112       0    0.983  0.0122        0.959        1.000
##     3    107       5    0.939  0.0225        0.896        0.984
##     4    105       2    0.921  0.0252        0.873        0.972
##     5     78       4    0.883  0.0306        0.825        0.945
## 
##                 ulcer=Yes 
##  time n.risk n.event survival std.err lower 95% CI upper 95% CI
##     0     90       0    1.000  0.0000        1.000        1.000
##     1     81       9    0.900  0.0316        0.840        0.964
##     2     71      10    0.789  0.0430        0.709        0.878
##     3     60      11    0.667  0.0497        0.576        0.772
##     4     55       5    0.611  0.0514        0.518        0.721
##     5     44       6    0.543  0.0526        0.449        0.657
\end{verbatim}

\begin{verbatim}
## Warning: Vectorized input to `element_text()` is not officially supported.
## Results may be unexpected or may change in future versions of ggplot2.
\end{verbatim}

\includegraphics{10_survival_files/figure-latex/unnamed-chunk-31-1.pdf}

Solution to Exercise \ref{chap10-ex2}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Fit model}
\NormalTok{my_hazard =}\StringTok{ }\KeywordTok{coxph}\NormalTok{(survival_object }\OperatorTok{~}\StringTok{ }\NormalTok{sex }\OperatorTok{+}\StringTok{ }\NormalTok{ulcer }\OperatorTok{+}\StringTok{ }\NormalTok{age }\OperatorTok{+}\StringTok{ }\NormalTok{thickness, }\DataTypeTok{data=}\NormalTok{melanoma)}
\KeywordTok{summary}\NormalTok{(my_hazard)}

\CommentTok{# Melanoma thickness has a HR 1.11 (1.03 to 1.18). }
\CommentTok{# This is interpretted as a 11% increase in the}
\CommentTok{# risk of death at any time for each 1 mm increase in thickness. }

\CommentTok{# Check assumptions}
\NormalTok{ph =}\StringTok{ }\KeywordTok{cox.zph}\NormalTok{(my_hazard)}
\NormalTok{ph}
\CommentTok{# GLOBAL shows no overall violation of assumptions.}
\CommentTok{# Plot Schoenfield residuals to evaluate PH}
\KeywordTok{plot}\NormalTok{(ph, }\DataTypeTok{var=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{part-workflow}{%
\part{Workflow}\label{part-workflow}}

Throughout this book we have tried to provide the most efficient approaches to data analysis using R.
In this section, we will provide workflows, or ways-of-working, which maximise efficiency, incorporate reporting of results within analyses, make exporting of tables and plots easy, and keep data safe, secured and backed up.

We also include a section on dealing with missing data in R. Something that we both feel strongly about and which is often poorly described and dealt with in academic publishing.

\hypertarget{chap11-h1}{%
\chapter{The problem of missing data}\label{chap11-h1}}

\index{missing data@\textbf{missing data}}

\begin{quote}
In heaven, all the interesting people are missing.\\
Friedrich Nietzsche
\end{quote}

\hypertarget{identification-of-missing-data}{%
\section{Identification of missing data}\label{identification-of-missing-data}}

As journal editors, we often receive studies in which the investigators fail to describe, analyse, or even acknowledge missing data.
This is frustrating, as it is often of the utmost importance.
Conclusions may (and do) change when missing data are accounted for.
Some folk seem to not even appreciate that in a conventional regression, only rows with complete data are included.
By reading this, you will not be one of them!

These are the five steps to ensuring missing data are correctly identified and appropriately dealt with:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ensure your data are coded correctly.
\item
  Identify missing values within each variable.
\item
  Look for patterns of missingness.
\item
  Check for associations between missing and observed data.
\item
  Decide how to handle missing data.
\end{enumerate}

We will work through a number of functions that will help with each of these.
But first, here are some terms that are easy to mix up.
These are important as they describe the mechanism of missingness and this determines how you can handle the missing data.

For each of the following examples we will imagine that we are collecting data on the relationship between gender, smoking and the outcome of cancer treatment.
The ground truth in this imagined scenario is that both gender and smoking influence the outcome from cancer treatment.

\hypertarget{missing-completely-at-random-mcar}{%
\subsection{Missing completely at random (MCAR)}\label{missing-completely-at-random-mcar}}

\index{missing data@\textbf{missing data}!missing completely at random}
As it says, values are randomly missing from your dataset.
Missing data values do not relate to any other data in the dataset and there is no pattern to the actual values of the missing data themselves.

In our example, smoking status is missing from a random subset of male and female patients.

This may have the effect of making our population smaller, but the complete case population has the same characteristics as the missing data population.
This is easy to handle, but unfortunately, data are almost never missing completely at random.

\hypertarget{missing-at-random-mar}{%
\subsection{Missing at random (MAR)}\label{missing-at-random-mar}}

\index{missing data@\textbf{missing data}!missing at random}
This is confusing and would be better named \emph{missing conditionally at random}.
Here, missingness in particular variable has an association with one or more other variables in the dataset.
However, the \emph{actual values of the missing data are random}.

In our example, smoking status is missing for some female patients but not for male patients.

But data is missing from the same number of female smokers as female non-smokers.
So the complete case female patients have the same characteristics as the missing data female patients.

\hypertarget{missing-not-at-random-mnar}{%
\subsection{Missing not at random (MNAR)}\label{missing-not-at-random-mnar}}

\index{missing data@\textbf{missing data}!missing not at random}
The pattern of missingness is related to other variables in the dataset, but in addition, the \emph{actual values of the missing data are not random}.

In our example, smoking status is missing in female patients who are more likely to smoke, but not for male patients.

Thus, the complete case female patients have different characteristics to the missing data female patients.
For instance, the missing data female patients may be more likely to die after cancer treatment.
Looking at our available population, we therefore under estimate the likelihood of a female dying from cancer treatment.

Missing not at random data are important, can alter your conclusions, and are the most difficult to diagnose and handle.
They can only be detected by collecting and examining some of the missing data.
This is often difficult or impossible to do.

How you deal with missing data is dependent on the type of missingness.
Once you know the type, you can start addressing it.
More on this below.

\hypertarget{ensure-your-data-are-coded-correctly-ff_glimpse}{%
\section{\texorpdfstring{Ensure your data are coded correctly: \texttt{ff\_glimpse()}}{Ensure your data are coded correctly: ff\_glimpse()}}\label{ensure-your-data-are-coded-correctly-ff_glimpse}}

\index{variable types@\textbf{variable types}}

While it sounds obvious, this step is often ignored in the rush to get results.
The first step in any analysis is robust data cleaning and coding.
Lots of packages have a glimpse-type function and our own \textbf{finalfit} is no different.
This function has three specific goals:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Ensure all variables are of the type you expect them to be. That is the commonest reason to get an error with a \textbf{finalfit} function. Numbers should be numeric, categorical variables should be characters or factors, and dates should be dates (for a reminder on these, see Section \ref{chap02-vartypes}.
\item
  Ensure you know which variables have missing data. This presumes missing values are correctly assigned \texttt{NA}.
\item
  Ensure factor levels and variable labels are assigned correctly.
\end{enumerate}

\hypertarget{the-question-6}{%
\subsection{The Question}\label{the-question-6}}

Using the \texttt{colon\_s} colon cancer dataset, we are interested in exploring the association between a cancer obstructing the bowel and 5-year survival, accounting for other patient and disease characteristics.

For demonstration purposes, we will make up MCAR and MAR smoking variables (\texttt{smoking\_mcar} and \texttt{smoking\_mar}).
Do not worry about understanding the long cascading mutate and \texttt{sample()} functions below, this is merely for creating the example variables.
You would not be `creating' your data, we hope.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Create some extra missing data}
\KeywordTok{library}\NormalTok{(finalfit)}
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{colon_s <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \CommentTok{## Smoking missing completely at random}
    \DataTypeTok{smoking_mcar =} \KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Smoker"}\NormalTok{, }\StringTok{"Non-smoker"}\NormalTok{, }\OtherTok{NA}\NormalTok{), }
                          \KeywordTok{n}\NormalTok{(), }\DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{, }
                          \DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.2}\NormalTok{, }\FloatTok{0.7}\NormalTok{, }\FloatTok{0.1}\NormalTok{)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{factor}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Smoking (MCAR)"}\NormalTok{),}
    
    \CommentTok{## Smoking missing conditional on patient sex}
    \DataTypeTok{smoking_mar =} \KeywordTok{ifelse}\NormalTok{(sex.factor }\OperatorTok{==}\StringTok{ "Female"}\NormalTok{,}
                         \KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Smoker"}\NormalTok{, }\StringTok{"Non-smoker"}\NormalTok{, }\OtherTok{NA}\NormalTok{), }
                                \KeywordTok{sum}\NormalTok{(sex.factor }\OperatorTok{==}\StringTok{ "Female"}\NormalTok{), }
                                \DataTypeTok{replace =} \OtherTok{TRUE}\NormalTok{,}
                                \DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\FloatTok{0.5}\NormalTok{, }\FloatTok{0.4}\NormalTok{)),}
                         
                         \KeywordTok{sample}\NormalTok{(}\KeywordTok{c}\NormalTok{(}\StringTok{"Smoker"}\NormalTok{, }\StringTok{"Non-smoker"}\NormalTok{, }\OtherTok{NA}\NormalTok{), }
                                \KeywordTok{sum}\NormalTok{(sex.factor }\OperatorTok{==}\StringTok{ "Male"}\NormalTok{), }
                                \DataTypeTok{replace=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{prob =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.15}\NormalTok{, }\FloatTok{0.75}\NormalTok{, }\FloatTok{0.1}\NormalTok{))}
\NormalTok{    ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{factor}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{ff_label}\NormalTok{(}\StringTok{"Smoking (MAR)"}\NormalTok{)}
\NormalTok{  )}
\end{Highlighting}
\end{Shaded}

We will then examine our variables of interest using \texttt{ff\_glimpse()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{,  }
                 \StringTok{"smoking_mcar"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}

\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ff_glimpse}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $Continuous
##             label var_type   n missing_n missing_percent mean   sd  min
## age   Age (years)    <dbl> 929         0             0.0 59.8 11.9 18.0
## nodes       nodes    <dbl> 911        18             1.9  3.7  3.6  0.0
##       quartile_25 median quartile_75  max
## age          53.0   61.0        69.0 85.0
## nodes         1.0    2.0         5.0 33.0
## 
## $Categorical
##                            label var_type   n missing_n missing_percent
## mort_5yr        Mortality 5 year    <fct> 915        14             1.5
## sex.factor                   Sex    <fct> 929         0             0.0
## obstruct.factor      Obstruction    <fct> 908        21             2.3
## smoking_mcar      Smoking (MCAR)    <fct> 828       101            10.9
## smoking_mar        Smoking (MAR)    <fct> 726       203            21.9
##                 levels_n                              levels  levels_count
## mort_5yr               2        "Alive", "Died", "(Missing)"  511, 404, 14
## sex.factor             2                    "Female", "Male"      445, 484
## obstruct.factor        2            "No", "Yes", "(Missing)"  732, 176, 21
## smoking_mcar           2 "Non-smoker", "Smoker", "(Missing)" 645, 183, 101
## smoking_mar            2 "Non-smoker", "Smoker", "(Missing)" 585, 141, 203
##                   levels_percent
## mort_5yr        55.0, 43.5,  1.5
## sex.factor                48, 52
## obstruct.factor 78.8, 18.9,  2.3
## smoking_mcar          69, 20, 11
## smoking_mar           63, 15, 22
\end{verbatim}

You don't need to specify the variables, and if you don't, \texttt{ff\_glimpse()} will summarise all variables:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{ff_glimpse}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

Use this to check that the variables are all assigned and behaving as expected.
The proportion of missing data can be seen, e.g., \texttt{smoking\_mar} has 22\% missing data.

\hypertarget{identify-missing-values-in-each-variable-missing_plot}{%
\section{\texorpdfstring{Identify missing values in each variable: \texttt{missing\_plot()}}{Identify missing values in each variable: missing\_plot()}}\label{identify-missing-values-in-each-variable-missing_plot}}

\index{missing data@\textbf{missing data}!missingness plot}

Visualising data is essential to help understand it, and missing data is no exception.
\texttt{missing\_plot()} function also from \textbf{finalfit} is useful for grasping the amount of missing data in each variable.
Row number is on the x-axis and all included variables are on the y-axis.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{missing_plot}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11_missing_data_files/figure-latex/unnamed-chunk-5-1.pdf}

Further visualisations of missingness can be done using the \href{http://naniar.njtierney.com}{naniar} package.

\hypertarget{look-for-patterns-of-missingness-missing_pattern}{%
\section{\texorpdfstring{Look for patterns of missingness: \texttt{missing\_pattern()}}{Look for patterns of missingness: missing\_pattern()}}\label{look-for-patterns-of-missingness-missing_pattern}}

\index{missing data@\textbf{missing data}!missingness pattern}

Using \textbf{finalfit}, \texttt{missing\_pattern()} wraps a function from the \textbf{mice} package, \texttt{md.pattern()}.
This produces a table and a plot showing the pattern of missingness between variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"obstruct.factor"}\NormalTok{,  }
                 \StringTok{"smoking_mcar"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}

\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_pattern}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11_missing_data_files/figure-latex/unnamed-chunk-6-1.pdf}

\begin{verbatim}
##     age sex.factor mort_5yr obstruct.factor smoking_mcar smoking_mar    
## 631   1          1        1               1            1           1   0
## 167   1          1        1               1            1           0   1
## 69    1          1        1               1            0           1   1
## 27    1          1        1               1            0           0   2
## 14    1          1        1               0            1           1   1
## 4     1          1        1               0            1           0   2
## 3     1          1        1               0            0           1   2
## 8     1          1        0               1            1           1   1
## 4     1          1        0               1            1           0   2
## 1     1          1        0               1            0           1   2
## 1     1          1        0               1            0           0   3
##       0          0       14              21          101         203 339
\end{verbatim}

This allows us to look for patterns of missingness between variables.
There are 11 patterns in these data.
The number and pattern of missingness help us to determine the likelihood of it being random rather than systematic.

\hypertarget{including-missing-data-in-demographics-tables}{%
\section{Including missing data in demographics tables}\label{including-missing-data-in-demographics-tables}}

\index{missing data@\textbf{missing data}!demographics table}

``Table 1'' in a healthcare study is often a demographics table of an ``explanatory variable of interest'' against other explanatory variables/confounders.
Do not silently drop missing values in this table.
It is easy to do this correctly with \texttt{summary\_factorlist()}.
This function provides a useful summary of a dependent variable against explanatory variables.
Despite its name, continuous variables are handled nicely.

\texttt{na\_include=TRUE} ensures missing data from the explanatory variables (but not dependent) are included.
To include missing values from the dependent, add \texttt{na\_include\_dependent\ =\ TRUE}.
Including a total column (\texttt{total\_col\ =\ TRUE}) is also useful, as well as column totals (\texttt{add\_col\_totals\ =\ TRUE}).

If you are using a lot of continuous explanatory variables with missing values, then these can be seen easily using \texttt{add\_row\_totals\ =\ TRUE}.

Note that missing data is not included when \emph{p}-values are generated.
If you wish missing data to be passed to statistical tests, then include \texttt{na\_to\_p\ =\ TRUE}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Explanatory or confounding variables}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{,  }
                 \StringTok{"smoking_mcar"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}

\CommentTok{# Explanatory variable of interest}
\NormalTok{dependent <-}\StringTok{ "obstruct.factor"} \CommentTok{# Bowel obstruction}

\NormalTok{table1 <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(dependent, explanatory, }
                     \DataTypeTok{na_include=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na_include_dependent =} \OtherTok{TRUE}\NormalTok{, }
                     \DataTypeTok{total_col =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{add_col_totals =} \OtherTok{TRUE}\NormalTok{, }\DataTypeTok{p=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-8}Simulated missing completely at random (MCAR) and missing at random (MAR) dataset.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrrr}
\toprule
label & levels & No & Yes & (Missing) & Total & p\\
\midrule
Total N (\%) &  & 732 (78.8) & 176 (18.9) & 21 (2.3) & 929 & \\
Age (years) & Mean (SD) & 60.2 (11.5) & 57.3 (13.3) & 63.9 (11.9) & 59.8 (11.9) & 0.004\\
Sex & Female & 346 (47.3) & 91 (51.7) & 8 (38.1) & 445 (47.9) & 0.330\\
\addlinespace
 & Male & 386 (52.7) & 85 (48.3) & 13 (61.9) & 484 (52.1) & \\
nodes & Mean (SD) & 3.7 (3.7) & 3.5 (3.2) & 3.3 (3.1) & 3.7 (3.6) & 0.435\\
Smoking (MCAR) & Non-smoker & 500 (68.3) & 130 (73.9) & 15 (71.4) & 645 (69.4) & 0.080\\
\addlinespace
 & Smoker & 154 (21.0) & 26 (14.8) & 3 (14.3) & 183 (19.7) & \\
 & (Missing) & 78 (10.7) & 20 (11.4) & 3 (14.3) & 101 (10.9) & \\
Smoking (MAR) & Non-smoker & 456 (62.3) & 115 (65.3) & 14 (66.7) & 585 (63.0) & 0.822\\
\addlinespace
 & Smoker & 112 (15.3) & 26 (14.8) & 3 (14.3) & 141 (15.2) & \\
 & (Missing) & 164 (22.4) & 35 (19.9) & 4 (19.0) & 203 (21.9) & \\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{check-for-associations-between-missing-and-observed-data}{%
\section{Check for associations between missing and observed data`}\label{check-for-associations-between-missing-and-observed-data}}

\index{missing data@\textbf{missing data}!associations}

In deciding whether data is MCAR or MAR, one approach is to explore patterns of missingness between levels of included variables.
This is particularly important (we would say absolutely required) for a primary outcome measure / dependent variable.

Take for example ``death''.
When that outcome is missing it is often for a particular reason.
For example, perhaps patients undergoing emergency surgery were less likely to have complete records compared with those undergoing planned surgery.
And of course, death is more likely after emergency surgery.

\texttt{missing\_pairs()} uses functions from the \textbf{GGally} package.
It produces pairs plots to show relationships between missing values and observed values in all variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{,  }
                 \StringTok{"smoking_mcar"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_pairs}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{11_missing_data_files/figure-latex/unnamed-chunk-9-1.pdf}
\caption{\label{fig:unnamed-chunk-9}Missing data matrix with \texttt{missing\_pairs()}.}
\end{figure}

For continuous variables (age and nodes), the distributions of observed and missing data can immediately be visually compared.
For example, look at Row 1 Column 2.
The age of patients who's mortality data is known is the blue box plot, and the age of patients with missing mortality data is the grey box plot.

For categorical data, the comparisons are presented as counts (remember \texttt{geom\_bar()} from Chapter \ref{chap04-h1}).
To be able to compare proportions, we can add the \texttt{position\ =\ "fill"} argument:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_pairs}\NormalTok{(dependent, explanatory, }\DataTypeTok{position =} \StringTok{"fill"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{11_missing_data_files/figure-latex/unnamed-chunk-10-1.pdf}
\caption{\label{fig:unnamed-chunk-10}Missing data matrix with \texttt{missing\_pairs(position\ =\ \textquotesingle{}fill\textquotesingle{})} .}
\end{figure}

Find the two sets of bar plots that show the proportion of missing smoking data for sex (bottom of Column 3).
Missingness in Smoking (MCAR) does not relate to sex - females and males have the same proportion of missing data.
Missingness in Smoking (MAR), however, does differ by sex as females have more missing data than men here.
This is how we designed the example at the top of this chapter, so it all makes sense.

We can also confirm this by using \texttt{missing\_compare()}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "smoking_mcar"}

\NormalTok{missing_mcar <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_compare}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-12}Missing data comparison: Smoking (MCAR).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Missing data analysis: Smoking (MCAR) &   & Not missing & Missing & p\\
\midrule
Age (years) & Mean (SD) & 59.7 (11.9) & 59.9 (12.6) & 0.882\\
Sex & Female & 399 (89.7) & 46 (10.3) & 0.692\\
 & Male & 429 (88.6) & 55 (11.4) & \\
\addlinespace
nodes & Mean (SD) & 3.6 (3.4) & 4.0 (4.5) & 0.302\\
Obstruction & No & 654 (89.3) & 78 (10.7) & 0.891\\
 & Yes & 156 (88.6) & 20 (11.4) & \\
\bottomrule
\end{tabular}}
\end{table}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{dependent <-}\StringTok{ "smoking_mar"}

\NormalTok{missing_mar <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_compare}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-14}Missing data comparison: Smoking (MAR).}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrr}
\toprule
Missing data analysis: Smoking (MAR) &   & Not missing & Missing & p\\
\midrule
Age (years) & Mean (SD) & 59.9 (11.8) & 59.4 (12.6) & 0.632\\
Sex & Female & 288 (64.7) & 157 (35.3) & <0.001\\
 & Male & 438 (90.5) & 46 (9.5) & \\
\addlinespace
nodes & Mean (SD) & 3.6 (3.5) & 3.9 (3.9) & 0.321\\
Obstruction & No & 568 (77.6) & 164 (22.4) & 0.533\\
 & Yes & 141 (80.1) & 35 (19.9) & \\
\bottomrule
\end{tabular}}
\end{table}

It takes dependent and explanatory variables, and in this context ``dependent'' refers to the variable being tested for missingness against the explanatory variables.
\footnote{By default, \texttt{missing\_compare()} uses an F-test test for continuous variables and chi-squared for categorical variables; you can change these the same way you change tests in \texttt{summary\_factorlist()}.
  Check the Help tab or online documentation for a reminder.}
As expected, a relationship is seen between sex and smoking (MAR) but not smoking (MCAR).

\hypertarget{for-those-who-like-an-omnibus-test}{%
\subsection{For those who like an omnibus test}\label{for-those-who-like-an-omnibus-test}}

If you work predominately with continuous rather than categorical data, you may find these tests from the \texttt{MissMech} package useful.
It provides two tests which can be used to determine whether data are MCAR; the package and its output are well documented.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(MissMech)}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"nodes"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"} 

\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\KeywordTok{all_of}\NormalTok{(explanatory)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{MissMech}\OperatorTok{::}\KeywordTok{TestMCARNormality}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Call:
## MissMech::TestMCARNormality(data = .)
## 
## Number of Patterns:  2 
## 
## Total number of cases used in the analysis:  929 
## 
##  Pattern(s) used:
##           age   nodes   Number of cases
## group.1     1       1               911
## group.2     1      NA                18
## 
## 
##     Test of normality and Homoscedasticity:
##   -------------------------------------------
## 
## Hawkins Test:
## 
##     P-value for the Hawkins test of normality and homoscedasticity:  7.607252e-14 
## 
##     Either the test of multivariate normality or homoscedasticity (or both) is rejected.
##     Provided that normality can be assumed, the hypothesis of MCAR is 
##     rejected at 0.05 significance level. 
## 
## Non-Parametric Test:
## 
##     P-value for the non-parametric test of homoscedasticity:  0.6171955 
## 
##     Reject Normality at 0.05 significance level.
##     There is not sufficient evidence to reject MCAR at 0.05 significance level.
\end{verbatim}

\hypertarget{handling-missing-data-mcar}{%
\section{Handling missing data: MCAR}\label{handling-missing-data-mcar}}

\index{missing data@\textbf{missing data}!handling}

Prior to a standard regression analysis, we can either:

\begin{itemize}
\tightlist
\item
  Delete the variable with the missing data
\item
  Delete the cases with the missing data
\item
  Impute (fill in) the missing data
\item
  Model the missing data
\end{itemize}

Using the examples, we identify that smoking (MCAR) is missing completely at random.

We know nothing about the missing values themselves, but we know of no plausible reason that the values of the missing data, for say, people who died should be different to the values of the missing data for those who survived.
The pattern of missingness is therefore not felt to be MNAR.

\hypertarget{common-solution-row-wise-deletion}{%
\subsection{Common solution: row-wise deletion}\label{common-solution-row-wise-deletion}}

Depending on the number of data points that are missing, we may have sufficient power with complete cases to examine the relationships of interest.

We therefore elect to omit the patients in whom smoking is missing.
This is known as list-wise deletion and will be performed by default and usually silently by any standard regression function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{,  }
                 \StringTok{"smoking_mcar"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{fit =}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-17}Regression analysis with missing data: List-wise deletion.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Dependent: Mortality 5 year &   & Alive & Died & OR (univariable) & OR (multivariable)\\
\midrule
Age (years) & Mean (SD) & 59.8 (11.4) & 59.9 (12.5) & 1.00 (0.99-1.01, p=0.986) & 1.01 (1.00-1.02, p=0.200)\\
Sex & Female & 243 (55.6) & 194 (44.4) & - & -\\
 & Male & 268 (56.1) & 210 (43.9) & 0.98 (0.76-1.27, p=0.889) & 1.02 (0.76-1.38, p=0.872)\\
\addlinespace
nodes & Mean (SD) & 2.7 (2.4) & 4.9 (4.4) & 1.24 (1.18-1.30, p<0.001) & 1.25 (1.18-1.33, p<0.001)\\
Obstruction & No & 408 (56.7) & 312 (43.3) & - & -\\
 & Yes & 89 (51.1) & 85 (48.9) & 1.25 (0.90-1.74, p=0.189) & 1.53 (1.05-2.22, p=0.027)\\
\addlinespace
Smoking (MCAR) & Non-smoker & 358 (56.4) & 277 (43.6) & - & -\\
 & Smoker & 90 (49.7) & 91 (50.3) & 1.31 (0.94-1.82, p=0.113) & 1.37 (0.96-1.96, p=0.083)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{other-considerations}{%
\subsection{Other considerations}\label{other-considerations}}

\begin{itemize}
\tightlist
\item
  Sensitivity analysis
\item
  Omit the variable
\item
  Imputation
\item
  Model the missing data
\end{itemize}

If the variable in question is thought to be particularly important, you may wish to perform a sensitivity analysis.
A sensitivity analysis in this context aims to capture the effect of uncertainty on the conclusions drawn from the model.
Thus, you may choose to re-label all missing smoking values as ``smoker'', and see if that changes the conclusions of your analysis. The same procedure can be performed labelling with ``non-smoker''.

If smoking is not associated with the explanatory variable of interest or the outcome, it may be considered not to be a confounder and so could be omitted.
That deals with the missing data issue, but of course may not always be appropriate.

Imputation and modelling are considered below.

\hypertarget{handling-missing-data-mar}{%
\section{Handling missing data: MAR}\label{handling-missing-data-mar}}

But life is rarely that simple.

Considering that the smoking variable is more likely to be missing if the patient is female (missing\_compare shows a relationship).
But, say, that the missing values are not different from the observed values.
Missingness is then MAR.

If we simply drop all the patients for whom smoking is missing (list-wise deletion), then we drop relatively more females than men.
This may have consequences for our conclusions if sex is associated with our explanatory variable of interest or outcome.

\hypertarget{common-solution-multivariate-imputation-by-chained-equations-mice}{%
\subsection{Common solution: Multivariate Imputation by Chained Equations (mice)}\label{common-solution-multivariate-imputation-by-chained-equations-mice}}

\index{missing data@\textbf{missing data}!imputation}
\index{missing data@\textbf{missing data}!multiple imputation}
\index{imputation}
\index{multiple imputation}

\textbf{mice} is our go to package for multiple imputation.
That's the process of filling in missing data using a best-estimate from all the other data that exists.
When first encountered, this may not sound like a good idea.

However, taking our simple example, if missingness in smoking is predicted strongly by sex (and other observed variables), and the values of the missing data are random, then we can impute (best-guess) the missing smoking values using sex and other variables in the dataset.

Imputation is not usually appropriate for the explanatory variable of interest or the outcome variable, although these can be used to impute other variables.
In both cases, the hypothesis is that there is a meaningful association with other variables in the dataset, therefore it doesn't make sense to use these variables to impute them.

The process of multiple imputation involves:

\begin{itemize}
\tightlist
\item
  \textbf{Impute} missing data \emph{m} times, which results in \emph{m} complete datasets
\item
  \textbf{Diagnose} the quality of the imputed values
\item
  \textbf{Analyse} each completed dataset
\item
  \textbf{Pool} the results of the repeated analyses
\end{itemize}

We will present a \texttt{mice()} example here.
The package is well documented, and there are a number of checks and considerations that should be made to inform the imputation process.
Read the documentation carefully prior to doing this yourself.

Note also \texttt{missing\_predictorMatrix()} from \textbf{finalfit}.
This provides a straightforward way to include or exclude variables to be imputed or to be used for imputation.

\textbf{Impute}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Multivariate Imputation by Chained Equations (mice)}
\KeywordTok{library}\NormalTok{(finalfit)}
\KeywordTok{library}\NormalTok{(dplyr)}
\KeywordTok{library}\NormalTok{(mice)}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\end{Highlighting}
\end{Shaded}

Choose which variable to input missing values for and which variables to use for the imputation process.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(dependent, explanatory) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{missing_predictorMatrix}\NormalTok{(}
    \DataTypeTok{drop_from_imputed =} \KeywordTok{c}\NormalTok{(}\StringTok{"obstruct.factor"}\NormalTok{, }\StringTok{"mort_5yr"}\NormalTok{)}
\NormalTok{  ) ->}\StringTok{ }\NormalTok{predM}
\end{Highlighting}
\end{Shaded}

Make 10 imputed datasets and run our logistic regression analysis on each set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fits <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(dependent, explanatory) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }
\StringTok{  }\CommentTok{# Usually run imputation with 10 imputed sets, 4 here for demonstration}
\StringTok{  }\KeywordTok{mice}\NormalTok{(}\DataTypeTok{m =} \DecValTok{4}\NormalTok{, }\DataTypeTok{predictorMatrix =}\NormalTok{ predM) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }
\StringTok{  }\CommentTok{# Run logistic regression on each imputed set}
\StringTok{  }\KeywordTok{with}\NormalTok{(}\KeywordTok{glm}\NormalTok{(}\KeywordTok{formula}\NormalTok{(}\KeywordTok{ff_formula}\NormalTok{(dependent, explanatory)), }
           \DataTypeTok{family=}\StringTok{"binomial"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  iter imp variable
##   1   1  mort_5yr  nodes  obstruct.factor  smoking_mar
##   1   2  mort_5yr  nodes  obstruct.factor  smoking_mar
##   1   3  mort_5yr  nodes  obstruct.factor  smoking_mar
##   1   4  mort_5yr  nodes  obstruct.factor  smoking_mar
##   2   1  mort_5yr  nodes  obstruct.factor  smoking_mar
##   2   2  mort_5yr  nodes  obstruct.factor  smoking_mar
##   2   3  mort_5yr  nodes  obstruct.factor  smoking_mar
##   2   4  mort_5yr  nodes  obstruct.factor  smoking_mar
##   3   1  mort_5yr  nodes  obstruct.factor  smoking_mar
##   3   2  mort_5yr  nodes  obstruct.factor  smoking_mar
##   3   3  mort_5yr  nodes  obstruct.factor  smoking_mar
##   3   4  mort_5yr  nodes  obstruct.factor  smoking_mar
##   4   1  mort_5yr  nodes  obstruct.factor  smoking_mar
##   4   2  mort_5yr  nodes  obstruct.factor  smoking_mar
##   4   3  mort_5yr  nodes  obstruct.factor  smoking_mar
##   4   4  mort_5yr  nodes  obstruct.factor  smoking_mar
##   5   1  mort_5yr  nodes  obstruct.factor  smoking_mar
##   5   2  mort_5yr  nodes  obstruct.factor  smoking_mar
##   5   3  mort_5yr  nodes  obstruct.factor  smoking_mar
##   5   4  mort_5yr  nodes  obstruct.factor  smoking_mar
\end{verbatim}

\textbf{Extract metrics from each model}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Examples of extracting metrics from fits and taking the mean}
\CommentTok{## AICs}
\NormalTok{fits }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{getfit}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map}\NormalTok{(AIC) }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{unlist}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1193.679
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# C-statistic}
\NormalTok{fits }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{getfit}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\NormalTok{purrr}\OperatorTok{::}\KeywordTok{map}\NormalTok{(}\OperatorTok{~}\StringTok{ }\NormalTok{pROC}\OperatorTok{::}\KeywordTok{roc}\NormalTok{(.x}\OperatorTok{$}\NormalTok{y, .x}\OperatorTok{$}\NormalTok{fitted)}\OperatorTok{$}\NormalTok{auc) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{unlist}\NormalTok{() }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mean}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.6789003
\end{verbatim}

\textbf{Pool models together}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Pool  results}
\NormalTok{fits_pool <-}\StringTok{ }\NormalTok{fits }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{pool}\NormalTok{()}

\CommentTok{## Can be passed to or_plot}
\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{or_plot}\NormalTok{(dependent, explanatory, }\DataTypeTok{glmfit =}\NormalTok{ fits_pool, }\DataTypeTok{table_text_size=}\DecValTok{4}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\includegraphics{11_missing_data_files/figure-latex/unnamed-chunk-22-1.pdf}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Summarise and put in table}
\NormalTok{fit_imputed <-}\StringTok{ }\NormalTok{fits_pool }\OperatorTok{%>%}\StringTok{                                  }
\StringTok{  }\KeywordTok{fit2df}\NormalTok{(}\DataTypeTok{estimate_name =} \StringTok{"OR (multiple imputation)"}\NormalTok{, }\DataTypeTok{exp =} \OtherTok{TRUE}\NormalTok{)}

\CommentTok{# Use finalfit merge methods to create and compare results}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                 \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}

\NormalTok{table_uni_multi <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }\DataTypeTok{keep_fit_id =} \OtherTok{TRUE}\NormalTok{) }

\NormalTok{explanatory =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{)}

\NormalTok{fit_multi_no_smoking <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{glmmulti}\NormalTok{(dependent, explanatory) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{fit2df}\NormalTok{(}\DataTypeTok{estimate_suffix =} \StringTok{" (multivariable without smoking)"}\NormalTok{) }

\CommentTok{# Combine to final table}
\NormalTok{table_imputed <-}\StringTok{ }
\StringTok{  }\NormalTok{table_uni_multi }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ff_merge}\NormalTok{(fit_multi_no_smoking) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{ff_merge}\NormalTok{(fit_imputed, }\DataTypeTok{last_merge =} \OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-23}Regression analysis with missing data: Multiple imputation using `mice()`.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrrrr}
\toprule
Dependent: Mortality 5 year &   & Alive & Died & OR (univariable) & OR (multivariable) & OR (multivariable without smoking) & OR (multiple imputation)\\
\midrule
Age (years) & Mean (SD) & 59.8 (11.4) & 59.9 (12.5) & 1.00 (0.99-1.01, p=0.986) & 1.02 (1.01-1.04, p=0.004) & 1.01 (1.00-1.02, p=0.122) & 1.01 (1.00-1.02, p=0.213)\\
Sex & Female & 243 (55.6) & 194 (44.4) & - & - & - & -\\
 & Male & 268 (56.1) & 210 (43.9) & 0.98 (0.76-1.27, p=0.889) & 0.97 (0.69-1.34, p=0.836) & 0.98 (0.74-1.30, p=0.890) & 1.01 (0.77-1.34, p=0.924)\\
\addlinespace
nodes & Mean (SD) & 2.7 (2.4) & 4.9 (4.4) & 1.24 (1.18-1.30, p<0.001) & 1.28 (1.21-1.37, p<0.001) & 1.25 (1.19-1.32, p<0.001) & 1.23 (1.17-1.29, p<0.001)\\
Obstruction & No & 408 (56.7) & 312 (43.3) & - & - & - & -\\
 & Yes & 89 (51.1) & 85 (48.9) & 1.25 (0.90-1.74, p=0.189) & 1.49 (1.00-2.22, p=0.052) & 1.36 (0.95-1.93, p=0.089) & 1.34 (0.95-1.90, p=0.098)\\
\addlinespace
Smoking (MAR) & Non-smoker & 312 (54.0) & 266 (46.0) & - & - & - & -\\
 & Smoker & 87 (62.6) & 52 (37.4) & 0.70 (0.48-1.02, p=0.067) & 0.77 (0.51-1.16, p=0.221) & - & 0.75 (0.50-1.14, p=0.178)\\
\bottomrule
\end{tabular}}
\end{table}

By examining the coefficients, the effect of the imputation compared with the complete case analysis can be seen.

\textbf{Other considerations}

\begin{itemize}
\tightlist
\item
  Omit the variable
\item
  Model the missing data
\end{itemize}

As above, if the variable does not appear to be important, it may be omitted from the analysis.
A sensitivity analysis in this context is another form of imputation.
But rather than using all other available information to best-guess the missing data, we simply assign the value as above.
Imputation is therefore likely to be more appropriate.

There is an alternative method to model the missing data for the categorical in this setting -- just consider the missing data as a factor level.
This has the advantage of simplicity, with the disadvantage of increasing the number of terms in the model.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{explanatory =}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"nodes"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{, }\StringTok{"smoking_mar"}\NormalTok{)}
\NormalTok{fit_explicit_na =}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{smoking_mar =}\NormalTok{ forcats}\OperatorTok{::}\KeywordTok{fct_explicit_na}\NormalTok{(smoking_mar)}
\NormalTok{  ) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-25}Regression analysis with missing data: Explicitly modelling missing data.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Dependent: Mortality 5 year &   & Alive & Died & OR (univariable) & OR (multivariable)\\
\midrule
Age (years) & Mean (SD) & 59.8 (11.4) & 59.9 (12.5) & 1.00 (0.99-1.01, p=0.986) & 1.01 (1.00-1.02, p=0.114)\\
Sex & Female & 243 (55.6) & 194 (44.4) & - & -\\
 & Male & 268 (56.1) & 210 (43.9) & 0.98 (0.76-1.27, p=0.889) & 0.95 (0.71-1.28, p=0.743)\\
\addlinespace
nodes & Mean (SD) & 2.7 (2.4) & 4.9 (4.4) & 1.24 (1.18-1.30, p<0.001) & 1.25 (1.19-1.32, p<0.001)\\
Obstruction & No & 408 (56.7) & 312 (43.3) & - & -\\
 & Yes & 89 (51.1) & 85 (48.9) & 1.25 (0.90-1.74, p=0.189) & 1.35 (0.95-1.92, p=0.099)\\
\addlinespace
Smoking (MAR) & Non-smoker & 312 (54.0) & 266 (46.0) & - & -\\
 & Smoker & 87 (62.6) & 52 (37.4) & 0.70 (0.48-1.02, p=0.067) & 0.78 (0.52-1.17, p=0.233)\\
 & (Missing) & 112 (56.6) & 86 (43.4) & 0.90 (0.65-1.25, p=0.528) & 0.85 (0.59-1.23, p=0.390)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{handling-missing-data-mnar}{%
\section{Handling missing data: MNAR}\label{handling-missing-data-mnar}}

Missing not at random data is tough in healthcare.
To determine if data are MNAR for definite, we need to know their value in a subset of observations (patients).

Imagine that smoking status is poorly recorded in patients admitted to hospital as an emergency with an obstructing bowel cancer.
Obstructing bowel cancers may be larger or their position may make the prognosis worse.
Smoking may relate to the aggressiveness of the cancer and may be an independent predictor of prognosis.
The missing values for smoking may therefore not be random.
Smoking may be more common in the emergency patients and may be more common in those that die.

There is no easy way to handle this.
If at all possible, try to get the missing data.
Otherwise, be careful when drawing conclusions from analyses where data are thought to be missing not at random.

\hypertarget{summary-3}{%
\section{Summary}\label{summary-3}}

The more data analysis you do, the more you realise just how important missing data is.
It is imperative that you understand where missing values exist in your own data.
By following the simple steps in this chapter, you will be able to determine whether the cases (commonly patients) with missing values are a different population to those with complete data.
This is the basis for understanding the impact of missing data on your analyses.

Whether you remove cases, remove variables, impute data, or model missing values, always check how each approach alters the conclusions of your analysis.
Be transparent when you report your results and include the alternative approaches in appendices of published work.

\hypertarget{chap12-h1}{%
\chapter{Notebooks and Markdown}\label{chap12-h1}}

\index{notebooks@\textbf{notebooks}}
\index{markdown@\textbf{markdown}}

\begin{quote}
You ask me if I keep a notebook to record my great ideas. I've only ever had one.\\
Albert Einstein
\end{quote}

\hypertarget{what-is-a-notebook}{%
\section{What is a Notebook?}\label{what-is-a-notebook}}

R is all-powerful for the manipulation, visualisation and analysis of data.
What is often under-appreciated is the flexibility with which analyses can be exported or reported.

For instance, a full scientific paper, industry report, or monthly update can be easily written to accommodate a varying underlying dataset, and all tables and plots will be updated automatically.

This idea can be extended to a workflow in which all analyses are performed primarily within a document which doubles as the final report.

Enter ``Data Notebooks''!
Notebooks are documents which combine code and rich text elements, such as headings, paragraphs and links, in one document.
They combine analysis and reporting in one human-readable document to provide an intuitive interface between the researcher and their analysis (Figure \ref{fig:chap12-fig-literate}).
This is sometimes called ``literate programming'', given the resulting logical structure of information can be easily read in the manner a human would read a book.

\begin{figure}
\centering
\includegraphics{images/chapter12/1_literate_programming.pdf}
\caption{\label{fig:chap12-fig-literate}Traditional versus literate programming using Notebooks.}
\end{figure}

In our own work, we have now moved to doing most of our analyses in a Notebook file, rather than using a ``script'' file. You may not have guessed, but this whole book is written in this way.

Some of the advantages of the Notebook interface are:

\begin{itemize}
\tightlist
\item
  code and output are adjacent to each other, so you are not constantly switching between ``panes'';
\item
  easier to work on smaller screen, e.g., laptop;
\item
  documentation and reporting can be done beside the code, text elements can be fully formatted;
\item
  the code itself can be outputted or hidden;
\item
  the code is not limited to R - you can use Python, SQL etc.;
\item
  facilitate collaboration by easily sharing human-readable analysis documents;
\item
  can be outputted in a number of formats including HTML (web page), PDF, and Microsoft Word;
\item
  output can be extended to other formats such as presentations;
\item
  training/learning may be easier as course materials, examples, and student notes are all in the same document.
\end{itemize}

\hypertarget{what-is-markdown}{%
\section{What is Markdown?}\label{what-is-markdown}}

Markdown is a lightweight language that can be used to write fully-formatted documents.
It is plain-text and uses a simple set of rules to produce rather sophisticated output - we love it!

It is easy to format headings, bold text, italics, etc.
Within RStudio there is a Quick Reference guide (Figure \ref{fig:chap12-fig-help}) and links to the \href{https://www.rstudio.com/resources/cheatsheets}{RStudio cheatsheets} can be found in the Help drop-down menu.

\begin{figure}
\centering
\includegraphics{images/chapter12/3_help.pdf}
\caption{\label{fig:chap12-fig-help}RStudio Markdown quick reference guide.}
\end{figure}

Markdown exists independent of R and is used by a range of techies and alike.
A combination of Markdown (which is text with special characters to indicate desired formatting) and R code within it (usually to produce tables and plots) is called R Markdown.
R scripts have the file extension \texttt{.R}, Markdown documents have a file extension \texttt{.md}, therefore, R Markdown documents are \texttt{.Rmd}.

\hypertarget{what-is-the-difference-between-a-notebook-and-an-r-markdown-file}{%
\section{What is the difference between a Notebook and an R Markdown file?}\label{what-is-the-difference-between-a-notebook-and-an-r-markdown-file}}

Most people use the terms R Notebook and R Markdown interchangeably and that is fine.
Technically, R Markdown is a file, whereas R Notebook is a way to work with R Markdown files.
R Notebooks do not have their own file format, they all use \texttt{.Rmd}.
All R Notebooks can be `knitted' to R Markdown outputs, and all R Markdown documents can be interfaced as a Notebook.

An important difference is in the execution of code.
In R Markdown, when the file is \texttt{Knit}, all the elements (chunks) are also run.
Knit is to R Markdown what Source is to an R script (Source was introduced in Chapter 1, essentially it means `Run all lines').

In a Notebook, when the file is rendered with the \texttt{Preview} button, no code is re-run, only that which has already been run and is present in the document is included in the output.
Also, in the Notebook behind-the-scenes file (\texttt{.nb}), all the code is always included.
Something to watch out for if your code contains sensitive information, such as a password (which it never should!).

\hypertarget{notebook-vs-html-vs-pdf-vs-word}{%
\section{Notebook vs HTML vs PDF vs Word}\label{notebook-vs-html-vs-pdf-vs-word}}

\index{Microsoft Word}
\index{PDF}
\index{HTML}

In RStudio, a Notebook can be created by going to:\\
File -\textgreater{} New File -\textgreater{} R Notebook

Alternatively, you can create a Markdown file using:\\
File -\textgreater{} New File -\textgreater{} R Markdown\ldots{}

Don't worry which you choose.
As mentioned above, they are essentially the same thing but just come with different options.
It is easy to switch from a Notebook to a Markdown file if you wish to create a PDF or Word document for instance.

If you are primarily doing analysis in the Notebook environment, choose Notebook.
If you are primarily creating a PDF or Word document, choose R Markdown file.

\hypertarget{the-anatomy-of-a-notebook-r-markdown-file}{%
\section{The anatomy of a Notebook / R Markdown file}\label{the-anatomy-of-a-notebook-r-markdown-file}}

When you create a file, a helpful template is provided to get you started.
Figure \ref{fig:chap12-fig-anatomy} shows the essential elements of a Notebook file and how these translate to the \texttt{HTML} preview.

\hypertarget{yaml-header}{%
\subsection{YAML header}\label{yaml-header}}

\index{YAML header}

Every Notebook and Markdown file requires a ``YAML header''.
Where do they get these terms you ask?
Originally YAML was said to mean Yet Another Markup Language, referencing its purpose as a markup language.
It was later repurposed as YAML Ain't Markup Language, a recursive acronym, to distinguish its purpose as data-oriented rather than document markup (thank you Wikipedia).

This is simply where many of the settings/options for file creation are placed.
In RStudio, these often update automatically as different settings are invoked in the Options menu.

\begin{figure}
\centering
\includegraphics{images/chapter12/2_anatomy_rotated.pdf}
\caption{\label{fig:chap12-fig-anatomy}The Anatomy of a Notebook/Markdown file. Input (left) and output (right).}
\end{figure}

\hypertarget{r-code-chunks}{%
\subsection{R code chunks}\label{r-code-chunks}}

\index{chunks}

R code within a Notebook or Markdown file can be included in two ways:

\begin{itemize}
\tightlist
\item
  in-line: e.g., the total number of oranges was \texttt{\textasciigrave{}r} \texttt{sum(fruit\$oranges)\textasciigrave{}};
\item
  as a ``chunk''.
\end{itemize}

R chunks are flexible, come with lots of options, and you will soon get into the way of using them.

Figure \ref{fig:chap12-fig-anatomy} shows how a chunk fits into the document.

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{```\{r\}}
\BaseNTok{# This is basic chunk. }
\BaseNTok{# It always starts with ```\{r\}}
\BaseNTok{# And ends with ```}
\FunctionTok{# Code goes here}
\NormalTok{sum(fruit$oranges)}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

This may look off-putting, but just go with it for now.
You can type the four back-ticks in manually, or use the \texttt{Insert} button and choose \texttt{R}.
You will also notice that chunks are not limited to R code.
It is particularly helpful that Python can also be run in this way.

When doing an analysis in a Notebook you will almost always want to see the code and the output.
When you are creating a final document you may wish to hide code.
Chunk behaviour can be controlled via the \texttt{Chunk\ Cog} on the right of the chunk (Figure \ref{fig:chap12-fig-anatomy}).

Table \ref{tab:chap12-tab-chunk-output} shows the various permutations of code and output options that are available.
The code is placed in the chunk header but the options fly-out now does this automatically, e.g.,

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{```\{r, echo=FALSE\}}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

\begin{table}

\caption{\label{tab:chap12-tab-chunk-output}Chunk output options when knitting an R Markdown file. When using the Chunk Cog, RStudio will add these options appropriately; there is no need to memorise them.}
\centering
\begin{tabular}[t]{ll}
\toprule
Option & Code\\
\midrule
Show output only & echo=FALSE\\
Show code and output & echo=TRUE\\
Show code (don't run code) & eval=FALSE\\
Show nothing (run code) & include=FALSE\\
Show nothing (don't run code) & include=FALSE, eval=FALSE\\
\addlinespace
 & \\
Hide warnings & warnings=FALSE\\
Hide messages & messages=FALSE\\
\bottomrule
\end{tabular}
\end{table}

\hypertarget{setting-default-chunk-options}{%
\subsection{Setting default chunk options}\label{setting-default-chunk-options}}

We can set default options for all our chunks at the top of our document by adding and editing \texttt{knitr::opts\_chunk\$set(echo\ =\ TRUE)} at the top of the document.

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{```\{r\}}
\BaseNTok{knitr::opts_chunk$set(echo = TRUE,}
\BaseNTok{                      warning = FALSE)}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

\hypertarget{setting-default-figure-options}{%
\subsection{Setting default figure options}\label{setting-default-figure-options}}

It is possible to set different default sizes for different output types by including these in the YAML header (or using the document cog):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{---}
\NormalTok{title: "R Notebook"}
\NormalTok{output: }
\NormalTok{  pdf_document: }
\BaseNTok{    fig_height: 3}
\BaseNTok{    fig_width: 4}
\NormalTok{  html_document: }
\BaseNTok{    fig_height: 6}
\BaseNTok{    fig_width: 9}
\NormalTok{---}
\end{Highlighting}
\end{Shaded}

The YAML header is very sensitive to the spaces/tabs, so make sure these are correct.

\hypertarget{markdown-elements}{%
\subsection{Markdown elements}\label{markdown-elements}}

Markdown text can be included as you wish around your chunks.
Figure \ref{fig:chap12-fig-anatomy} shows an example of how this can be done.
This is a great way of getting into the habit of explicitly documenting your analysis.
When you come back to a file in 6 months' time, all of your thinking is there in front of you, rather than having to work out what on Earth you were on about from a collection of random code!

\hypertarget{interface-and-outputting}{%
\section{Interface and outputting}\label{interface-and-outputting}}

\hypertarget{running-code-and-chunks-knitting}{%
\subsection{Running code and chunks, knitting}\label{running-code-and-chunks-knitting}}

\index{knitr}

Figure \ref{fig:chap12-fig-options} shows the various controls for running chunks and producing an output document.
Code can be run line-by-line using \texttt{Ctrl+Enter} as you are used to.
There are options for running all the chunks above the current chunk you are working on.
This is useful as a chunk you are working on will often rely on objects created in preceding chunks.

\begin{figure}
\centering
\includegraphics{images/chapter12/4_notebook_options_rotated.pdf}
\caption{\label{fig:chap12-fig-options}Chunk and document options in Notebook/Markdown files.}
\end{figure}

It is good practice to use the \texttt{Restart\ R\ and\ Run\ All\ Chunks} option in the \texttt{Run} menu every so often.
This ensures that all the code in your document is self-contained and is not relying on an object in the environment which you have created elsewhere.
If this was the case, it will fail when rendering a Markdown document.

Probably the most important engine behind the RStudio Notebooks functionality is the \textbf{knitr} package by Yihui Xie.

Not knitting like your granny does, but rendering a Markdown document into an output file, such as HTML, PDF or Word.
There are many options which can be applied in order to achieve the desired output.
Some of these have been specifically coded into RStudio (Figure \ref{fig:chap12-fig-options}).

PDF document creation requires a \texttt{LaTeX} distribution to be installed on your computer.
Depending on what system you are using, this may be setup already.
An easy way to do this is using the \textbf{tinytex} package.

\begin{Shaded}
\begin{Highlighting}[]
\BaseNTok{```\{r\}}
\BaseNTok{install.packages("tinytex")}
\BaseNTok{# Restart R, then run}
\BaseNTok{tinytex::install_tinytex()}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

In the next chapter we will focus on the details of producing a polished final document.

\hypertarget{file-structure-and-workflow}{%
\section{File structure and workflow}\label{file-structure-and-workflow}}

\index{file structure@\textbf{file structure}}
\index{workflow@\textbf{workflow}}

As projects get bigger, it is important that they are well organised.
This will avoid errors and make collaboration easier.

What is absolutely compulsory is that your analysis must reside within an RStudio Project and have a meaningful name (not MyProject! or Analysis1).
Creating a New Project on RStudio will automatically create a new folder for itself (unless you choose ``Existing Folder'').
Never work within a generic Home or Documents directory.
Furthermore, do not change the working directory using \texttt{setwd()} - there is no reason to do this, and it usually makes your analysis less reproducible.
Once you're starting to get the hang of R, you should initiate all Projects with a Git repository for version control (see Chapter \ref{chap13-h1}).

For smaller projects with 1-2 data files, a couple of scripts and an R Markdown document, it is fine to keep them all in the Project folder (but we repeat, each Project must have its own folder).
Once the number of files grows beyond that, you should add separate folders for different types of files.

Here is our suggested approach.
Based on the nature of your analyses, the number of folders may be smaller or greater than this, and they may be called something different.

\begin{verbatim}
proj/
- scripts/
- data_raw/
- data_processed/
- figures/
- 00_analysis.Rmd
\end{verbatim}

\texttt{scripts/} contains all the \texttt{.R} script files used for data cleaning/preparation. If you only have a few scripts, it's fine to not have this one and just keep the \texttt{.R} files in the project folder (where \texttt{00\_analysis.Rmd} is in the above example).
\texttt{data\_raw/} contains all raw data, such as \texttt{.csv} files, \texttt{data\_processed/} contains data you've taken from raw, cleaned, modified, joined or otherwise changed using R scripts.
\texttt{figures/} may contain plots (e.g., \texttt{.png}, \texttt{.jpg}, \texttt{.pdf})
\texttt{00\_analysis.Rmd} or \texttt{00\_analysis.R} is the actual main working file, and we keep this in the main project directory.

Your R scripts should be numbered using double digits, and they should have meaningful names, for example:

\begin{verbatim}
scripts/00_source_all.R
scripts/01_read_data.R
scripts/02_make_factors.R
scripts/03_duplicate_records.R
\end{verbatim}

For instance, \texttt{01\_read\_data.R} may look like this.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Melanoma project}
\CommentTok{## Data pull}

\CommentTok{# Get data}
\KeywordTok{library}\NormalTok{(readr)}
\NormalTok{melanoma <-}\StringTok{ }\KeywordTok{read_csv}\NormalTok{(}
\NormalTok{  here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data_raw"}\NormalTok{, }\StringTok{"melanoma.csv"}\NormalTok{)}
\NormalTok{)}

\CommentTok{# Other basic reccoding or renaming functions here}

\CommentTok{# Save}
\KeywordTok{save}\NormalTok{(melanoma, }\DataTypeTok{file =} 
\NormalTok{  here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data_processed"}\NormalTok{, }\StringTok{"melanoma_working.rda"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note the use of \texttt{here::here()}.
RStudio projects manage working directories in a better way than \texttt{setwd()}.
\texttt{here::here()} is useful when sharing projects between Linux, Mac and Windows machines, which have different conventions for file paths.

For instance, on a Mac you would otherwise do \texttt{read\_csv("data/melanoma.csv")} and on Windows you would have to do \texttt{read\_csv("data\textbackslash{}melanoma.csv")}.
Having to include either \texttt{/} (GNU/Linux, macOS) or \texttt{\textbackslash{}} (Windows) in your script means it will have to be changed by hand when running on a different system.
What \texttt{here::here("data\_raw",\ "melanoma.csv")}, however, works on any system, as it will use an appropriate one `behind the scenes' without you having to change anything.

\texttt{02\_make\_factors.R} is our example second file, but it could be anything you want.
It could look something like this.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Melanoma project}
\CommentTok{## Create factors}
\KeywordTok{library}\NormalTok{(tidyverse)}

\KeywordTok{load}\NormalTok{(}
\NormalTok{  here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data_processed"}\NormalTok{, }\StringTok{"melanoma_working.rda"}\NormalTok{)}
\NormalTok{)}

\CommentTok{## Recode variables}
\NormalTok{melanoma <-}\StringTok{ }\NormalTok{melanoma }\OperatorTok{%>%}
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{sex =} \KeywordTok{factor}\NormalTok{(sex) }\OperatorTok{%>%}\StringTok{ }
\StringTok{      }\KeywordTok{fct_recode}\NormalTok{(}\StringTok{"Male"}\NormalTok{ =}\StringTok{ "1"}\NormalTok{, }
                 \StringTok{"Female"}\NormalTok{ =}\StringTok{ "0"}\NormalTok{)}
\NormalTok{  )}

\CommentTok{# Save}
\KeywordTok{save}\NormalTok{(melanoma, }\DataTypeTok{file =} 
\NormalTok{  here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"melanoma_working.rda"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

All these files can then be brought together in a single file to \texttt{source()}.
This function is used to run code from a file.

\texttt{00\_source\_all.R} might look like this:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Melanoma project}
\CommentTok{## Source all}

\KeywordTok{source}\NormalTok{( here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"scripts"}\NormalTok{, }\StringTok{"01_data_upload.R"}\NormalTok{) )}
\KeywordTok{source}\NormalTok{( here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"scripts"}\NormalTok{, }\StringTok{"02_make_factors.R"}\NormalTok{) ) }
\KeywordTok{source}\NormalTok{( here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"scripts"}\NormalTok{, }\StringTok{"03_duplicate_records.R"}\NormalTok{) ) }

\CommentTok{# Save}
\KeywordTok{save}\NormalTok{(melanoma, }\DataTypeTok{file =} 
\NormalTok{  here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data_processed"}\NormalTok{, }\StringTok{"melanoma_final.rda"}\NormalTok{)}
\NormalTok{)}
\end{Highlighting}
\end{Shaded}

You can now bring your robustly prepared data into your analysis file, which can be \texttt{.R} or \texttt{.Rmd} if you are working in a Notebook.
We call this \texttt{00\_analysis.Rmd} and it always sits in the project root director.
You have two options in bringing in the data.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \texttt{source("00\_source\_all.R")} to re-load and process the data again

  \begin{itemize}
  \tightlist
  \item
    this is useful if the data is changing
  \item
    may take a long time if it is a large dataset with lots of manipulations
  \end{itemize}
\item
  \texttt{load("melanoma\_final.rda")} from the \texttt{data\_processed/} folder

  \begin{itemize}
  \tightlist
  \item
    usually quicker, but loads the dataset which was created the last time you ran \texttt{00\_source\_all.R}
  \end{itemize}
\end{enumerate}

\begin{quote}
Remember: For \texttt{.R} files use \texttt{source()}, for \texttt{.rda} files use \texttt{load()}.
\end{quote}

The two options look like this:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{---}
\NormalTok{title: "Melanoma analysis"}
\NormalTok{output: html_notebook}
\NormalTok{---}

\BaseNTok{```\{r get-data-option-1, echo=FALSE\}}
\BaseNTok{load(}
\BaseNTok{  here:here("data", "melanoma_all.rda")}
\BaseNTok{)}
\BaseNTok{```}

\BaseNTok{```\{r get-data-option-2, echo=FALSE\}}
\BaseNTok{source(}
\BaseNTok{  here:here("R", "00_source_all.R")}
\BaseNTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{why-go-to-all-this-bother}{%
\subsection{Why go to all this bother?}\label{why-go-to-all-this-bother}}

It comes from many years of finding errors due to badly organised projects.
It is not needed for a small quick project, but is essential for any major work.

At the very start of an analysis (as in the first day), we will start working in a single file.
We will quickly move chunks of data cleaning / preparation code into separate files as we go.

Compartmentalising the data cleaning helps with finding and dealing with errors (`debugging').
Sourced files can be `commented out' (adding a \# to a line in the \texttt{00\_source\_all.R} file) if you wish to exclude the manipulations in that particular file.

Most important, it helps with collaboration.
When multiple people are working on a project, it is essential that communication is good and everybody is working to the same overall plan.

\hypertarget{chap13-h1}{%
\chapter{Exporting and reporting}\label{chap13-h1}}

\index{exporting@\textbf{exporting}}

\begin{quote}
Without data, you are just another person with an opinion.\\
W. Edwards Deming
\end{quote}

The results of any data analysis are meaningless if they are not effectively communicated.

This may be as a journal article or presentation, or perhaps a regular report or webpage. In Chapter \ref{chap13-h1} we emphasise another of the major strengths of R - the ease with which HTML (a web page), PDF, or Word documents can be generated.

The purpose of this chapter is to focus on the details of how to get your exported tables, plots and documents looking exactly the way you want them. There are many customisations that can be used, and we will only touch on a few of these.

We will generate a report using data already familiar to you from this book.
It will contain two tables - a demographics table and a regression table - and a plot.
We will use the \texttt{colon\_s} data from the \texttt{finalfit} package.
What follows is for demonstration purposes and is not meant to illustrate model building.
For the purposes of the demonstration, we will ask, does a particular characteristic of a colon cancer (e.g., cancer differentiation) predict 5-year survival?

\hypertarget{which-format-should-i-use}{%
\section{Which format should I use?}\label{which-format-should-i-use}}

The three common formats for exporting reports have different pros and cons:

\begin{itemize}
\tightlist
\item
  HTML is the least fussy to work with and can resize itself and its content automatically. For rapid exploration and prototyping, we recommend knitting to HTML. HTML documents can be attached to emails and viewed using any browser, even with no internet access (as long as it is a self-contained HTML document, which R Markdown exports usually are).
\item
  PDF looks most professional when printed. This is because R Markdown uses LaTeX to typeset PDF documents. LaTeX PDFs are our preferred method of producing printable reports or dissertations, but they come with their own bag of issues. Mainly that LaTeX figures and tables \emph{float} and may therefore appear much later down the document than the original text describing it was.
\item
  Word is useful when working with non-R people who need to edit your output.
\end{itemize}

\hypertarget{working-in-a-.r-file}{%
\section{\texorpdfstring{Working in a \texttt{.R} file}{Working in a .R file}}\label{working-in-a-.r-file}}

We will demonstrate how you might put together a report in two ways.

First, we will show what you might do if you were working in standard R script file, then exporting certain objects only.

Second, we will talk about the approach if you were primarily working in a Notebook, which makes things easier.

We presume that the data have been cleaned carefully and the `Get the data', `Check the data', `Data exploration' and `Model building' steps have already been completed.

\hypertarget{demographics-table}{%
\section{Demographics table}\label{demographics-table}}

First, let's look at associations between our explanatory variable of interest (exposure) and other explanatory variables.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(tidyverse)}
\KeywordTok{library}\NormalTok{(finalfit)}

\CommentTok{# Specify explanatory variables of interest}
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{(}\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"extent.factor"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{, }
                \StringTok{"nodes"}\NormalTok{)}

\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\StringTok{"differ.factor"}\NormalTok{, explanatory,}
                     \DataTypeTok{p=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na_include=}\OtherTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-3}Exporting 'table 1': Tumour differentiation by patient and disease factors.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
label & levels & Well & Moderate & Poor & p\\
\midrule
Age (years) & Mean (SD) & 60.2 (12.8) & 59.9 (11.7) & 59.0 (12.8) & 0.644\\
Sex & Female & 51 (54.8) & 314 (47.4) & 73 (48.7) & 0.400\\
 & Male & 42 (45.2) & 349 (52.6) & 77 (51.3) & \\
\addlinespace
Extent of spread & Submucosa & 5 (5.4) & 12 (1.8) & 3 (2.0) & 0.081\\
 & Muscle & 12 (12.9) & 78 (11.8) & 12 (8.0) & \\
 & Serosa & 76 (81.7) & 542 (81.7) & 127 (84.7) & \\
\addlinespace
 & Adjacent structures & 0 (0.0) & 31 (4.7) & 8 (5.3) & \\
Obstruction & No & 69 (74.2) & 531 (80.1) & 114 (76.0) & 0.655\\
 & Yes & 19 (20.4) & 122 (18.4) & 31 (20.7) & \\
\addlinespace
 & (Missing) & 5 (5.4) & 10 (1.5) & 5 (3.3) & \\
nodes & Mean (SD) & 2.7 (2.2) & 3.6 (3.4) & 4.7 (4.4) & <0.001\\
\bottomrule
\end{tabular}}
\end{table}

Note that we include missing data in this table (see Chapter \ref{chap11-h1}).

Also note that \texttt{nodes} has not been labelled properly.

In addition, there are small numbers in some variables generating \texttt{chisq.test()} warnings (expect fewer than 5 in any cell).

Now generate a final table.\footnote{The \texttt{finalfit} functions used here - \texttt{summary\_factorlist()} and \texttt{finalfit()} were introduced in Part II - Data Analysis. We will therefore not describe the different arguments here, we use them to demonstrate R's powers of exporting to fully formatted output documents.}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{mutate}\NormalTok{(}
    \DataTypeTok{nodes =} \KeywordTok{ff_label}\NormalTok{(nodes, }\StringTok{"Lymph nodes involved"}\NormalTok{)}
\NormalTok{    )}

\NormalTok{table1 <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{summary_factorlist}\NormalTok{(}\StringTok{"differ.factor"}\NormalTok{, explanatory, }
                     \DataTypeTok{p=}\OtherTok{TRUE}\NormalTok{, }\DataTypeTok{na_include=}\OtherTok{TRUE}\NormalTok{, }
                     \DataTypeTok{add_dependent_label=}\OtherTok{TRUE}\NormalTok{,}
                     \DataTypeTok{dependent_label_prefix =} \StringTok{"Exposure: "}
\NormalTok{                     )}
\NormalTok{table1}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-5}Exporting 'table 1': Adjusting labels and output.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{>{\raggedright\arraybackslash}p{3.5cm}lrrrr}
\toprule
Exposure: Differentiation &   & Well & Moderate & Poor & p\\
\midrule
Age (years) & Mean (SD) & 60.2 (12.8) & 59.9 (11.7) & 59.0 (12.8) & 0.644\\
Sex & Female & 51 (54.8) & 314 (47.4) & 73 (48.7) & 0.400\\
 & Male & 42 (45.2) & 349 (52.6) & 77 (51.3) & \\
\addlinespace
Extent of spread & Submucosa & 5 (5.4) & 12 (1.8) & 3 (2.0) & 0.081\\
 & Muscle & 12 (12.9) & 78 (11.8) & 12 (8.0) & \\
 & Serosa & 76 (81.7) & 542 (81.7) & 127 (84.7) & \\
\addlinespace
 & Adjacent structures & 0 (0.0) & 31 (4.7) & 8 (5.3) & \\
Obstruction & No & 69 (74.2) & 531 (80.1) & 114 (76.0) & 0.655\\
 & Yes & 19 (20.4) & 122 (18.4) & 31 (20.7) & \\
\addlinespace
 & (Missing) & 5 (5.4) & 10 (1.5) & 5 (3.3) & \\
Lymph nodes involved & Mean (SD) & 2.7 (2.2) & 3.6 (3.4) & 4.7 (4.4) & <0.001\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{logistic-regression-table}{%
\section{Logistic regression table}\label{logistic-regression-table}}

After investigating the relationships between our explanatory variables, we will use logistic regression to include the outcome variable.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{explanatory <-}\StringTok{ }\KeywordTok{c}\NormalTok{( }\StringTok{"differ.factor"}\NormalTok{, }\StringTok{"age"}\NormalTok{, }\StringTok{"sex.factor"}\NormalTok{, }
                \StringTok{"extent.factor"}\NormalTok{, }\StringTok{"obstruct.factor"}\NormalTok{, }
                \StringTok{"nodes"}\NormalTok{)}
\NormalTok{dependent <-}\StringTok{ "mort_5yr"}
\NormalTok{table2 <-}\StringTok{ }\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{finalfit}\NormalTok{(dependent, explanatory, }
           \DataTypeTok{dependent_label_prefix =} \StringTok{""}\NormalTok{)}
\NormalTok{table2}
\end{Highlighting}
\end{Shaded}

\begin{table}[!h]

\caption{\label{tab:unnamed-chunk-7}Exporting a regression results table.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llrrrr}
\toprule
Mortality 5 year &   & Alive & Died & OR (univariable) & OR (multivariable)\\
\midrule
Differentiation & Well & 52 (56.5) & 40 (43.5) & - & -\\
 & Moderate & 382 (58.7) & 269 (41.3) & 0.92 (0.59-1.43, p=0.694) & 0.62 (0.38-1.01, p=0.054)\\
 & Poor & 63 (42.3) & 86 (57.7) & 1.77 (1.05-3.01, p=0.032) & 1.00 (0.56-1.78, p=0.988)\\
\addlinespace
Age (years) & Mean (SD) & 59.8 (11.4) & 59.9 (12.5) & 1.00 (0.99-1.01, p=0.986) & 1.01 (1.00-1.02, p=0.098)\\
Sex & Female & 243 (55.6) & 194 (44.4) & - & -\\
 & Male & 268 (56.1) & 210 (43.9) & 0.98 (0.76-1.27, p=0.889) & 0.97 (0.73-1.30, p=0.858)\\
\addlinespace
Extent of spread & Submucosa & 16 (80.0) & 4 (20.0) & - & -\\
 & Muscle & 78 (75.7) & 25 (24.3) & 1.28 (0.42-4.79, p=0.681) & 1.25 (0.36-5.87, p=0.742)\\
 & Serosa & 401 (53.5) & 349 (46.5) & 3.48 (1.26-12.24, p=0.027) & 3.03 (0.96-13.36, p=0.087)\\
\addlinespace
 & Adjacent structures & 16 (38.1) & 26 (61.9) & 6.50 (1.98-25.93, p=0.004) & 6.80 (1.75-34.55, p=0.010)\\
Obstruction & No & 408 (56.7) & 312 (43.3) & - & -\\
 & Yes & 89 (51.1) & 85 (48.9) & 1.25 (0.90-1.74, p=0.189) & 1.26 (0.88-1.82, p=0.206)\\
\addlinespace
Lymph nodes involved & Mean (SD) & 2.7 (2.4) & 4.9 (4.4) & 1.24 (1.18-1.30, p<0.001) & 1.24 (1.18-1.31, p<0.001)\\
\bottomrule
\end{tabular}}
\end{table}

\hypertarget{odds-ratio-plot-1}{%
\section{Odds ratio plot}\label{odds-ratio-plot-1}}

It is often preferable to express the coefficients from a regression model as a forest plot.
For instance, a plot of odds ratios can be produced using the \texttt{or\_plot()} function also from the \texttt{finalfit} package:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{colon_s }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{or_plot}\NormalTok{(dependent, explanatory, }
          \DataTypeTok{breaks =} \KeywordTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{30}\NormalTok{),}
          \DataTypeTok{table_text_size =} \FloatTok{3.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{13_exporting_files/figure-latex/unnamed-chunk-8-1.pdf}
\caption{\label{fig:unnamed-chunk-8}Odds ratio plot.}
\end{figure}

\hypertarget{ms-word-via-knitrr-markdown}{%
\section{MS Word via knitr/R Markdown}\label{ms-word-via-knitrr-markdown}}

\index{Microsoft Word}
\index{PDF}
\index{knitr}

When moving from a \texttt{.R} file to a Markdown (\texttt{.Rmd}) file, environment objects such as tables or data frames / tibbles usually require to be saved and loaded to R Markdown document.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{# Save objects for knitr/markdown}
\KeywordTok{save}\NormalTok{(table1, table2, dependent, explanatory, }
     \DataTypeTok{file =}\NormalTok{ here}\OperatorTok{::}\KeywordTok{here}\NormalTok{(}\StringTok{"data"}\NormalTok{, }\StringTok{"out.rda"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

In RStudio, select:\\
File \textgreater{} New File \textgreater{} R Markdown

A useful template file is produced by default. Try hitting knit to Word on the Knit button at the top of the \texttt{.Rmd} script window.
If you have difficulties at this stage, refer to Chapter \ref{chap12-h1}.

Now paste this into the file (we'll call it Example 1):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{---}
\NormalTok{title: "Example knitr/R Markdown document"}
\NormalTok{author: "Your name"}
\NormalTok{date: "22/5/2020"}
\NormalTok{output:}
\NormalTok{  word_document: default}
\NormalTok{---}

\BaseNTok{```\{r setup, include=FALSE\}}
\BaseNTok{# Load data into global environment. }
\BaseNTok{library(finalfit)}
\BaseNTok{library(dplyr)}
\BaseNTok{library(knitr)}
\BaseNTok{load(here::here("data", "out.rda"))}
\BaseNTok{```}

\FunctionTok{## Table 1 - Demographics}
\BaseNTok{```\{r table1, echo = FALSE\}}
\BaseNTok{kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"))}
\BaseNTok{```}

\FunctionTok{## Table 2 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r table2, echo = FALSE\}}
\BaseNTok{kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"))}
\BaseNTok{```}

\FunctionTok{## Figure 1 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r figure1, echo = FALSE\}}
\BaseNTok{explanatory = c( "differ.factor", "age", "sex.factor", }
\BaseNTok{                "extent.factor", "obstruct.factor", }
\BaseNTok{                "nodes")}
\BaseNTok{dependent = "mort_5yr"}
\BaseNTok{colon_s %>% }
\BaseNTok{  or_plot(dependent, explanatory)}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

\begin{figure}
\centering
\includegraphics{images/chapter13/1_word_knit.pdf}
\caption{\label{fig:chap13-fig-word}Knitting to Microsoft Word from R Markdown. Before (A) and after (B) adjustment.}
\end{figure}

Knitting this into a Word document results in Figure \ref{fig:chap13-fig-word}A), which looks pretty decent but some of the columns need some formatting and the plot needs resized.
Do not be tempted to do this by hand directly in the Word document.

Yes, before Markdown, we would have to move and format each table and figure directly in Word, and we would repeat this every time something changed.
Turns out some patient records were duplicated and you have to remove them before repeating the analysis over again.
Or your colleague forgot to attach an extra file with 10 more patients.

No problem, you update the dataset, re-run the script that created the tables and hit Knit in the R Markdown document.
No more mindless re-doing for you.
We think this is pretty amazing.

\hypertarget{figure-quality-in-word-output}{%
\subsection{Figure quality in Word output}\label{figure-quality-in-word-output}}

If your plots are looking a bit grainy in Word, include this in your setup chunk for high quality:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{knitr}\OperatorTok{::}\NormalTok{opts_chunk}\OperatorTok{$}\KeywordTok{set}\NormalTok{(}\DataTypeTok{dpi =} \DecValTok{300}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

The setup chunk is the one that starts with \texttt{\textasciigrave{}\textasciigrave{}\textasciigrave{}\{r\ setup,\ include\ =\ FALSE\}} and is generated automatically when you create a new R Markdown document in RStudio.

\hypertarget{create-word-template-file}{%
\section{Create Word template file}\label{create-word-template-file}}

To make sure tables always export with a suitable font size, you may edit your Word file but only to create a new template.
You will then use this template to Knit the R Markdown document again.

In the Word document the first example outputted, click on a table.
The style should be \texttt{compact}:
Right-click \textgreater{} Modify\ldots{} \textgreater{} font size = 9

Alter heading and text styles in the same way as desired.
Save this as \texttt{colonTemplate.docx} (avoid underscores in the name of this file).
Move the file to your project folder and reference it in your \texttt{.Rmd} YAML header, as shown below.
Make sure you get the spacing correct, unlike R code, the YAML header is sensitive to formatting and the number of spaces at the beginning of the argument lines.

Finally, to get the figure printed in a size where the labels don't overlap each other, you will have to specify a width for it.
The Chunk cog introduced in the previous chapter is a convenient way to change the figure size (it is in the top-right corner of each grey code chunk in an R Markdown document).
It usually takes some experimentation to find the best size for each plot/output document; in this case we are going with \texttt{fig.width\ =\ 10}.

Knitting Example 2 here gives us Figure \ref{fig:chap13-fig-word}B).
For something that is generated automatically, it looks awesome.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{---}
\NormalTok{title: "Example knitr/R Markdown document"}
\NormalTok{author: "Your name"}
\NormalTok{date: "22/5/2020"}
\NormalTok{output:}
\NormalTok{  word_document:}
\BaseNTok{    reference_docx: colonTemplate.docx}
\NormalTok{---}
  
\BaseNTok{```\{r setup, include=FALSE\}}
\BaseNTok{# Load data into global environment. }
\BaseNTok{library(finalfit)}
\BaseNTok{library(dplyr)}
\BaseNTok{library(knitr)}
\BaseNTok{load(here::here("data", "out.rda"))}
\BaseNTok{```}

\FunctionTok{## Table 1 - Demographics}
\BaseNTok{```\{r table1, echo = FALSE\}}
\BaseNTok{kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"))}
\BaseNTok{```}

\FunctionTok{## Table 2 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r table2, echo = FALSE\}}
\BaseNTok{kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"))}
\BaseNTok{```}

\FunctionTok{## Figure 1 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r figure1, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10\}}
\BaseNTok{explanatory = c( "differ.factor", "age", "sex.factor", }
\BaseNTok{                "extent.factor", "obstruct.factor", }
\BaseNTok{                "nodes")}
\BaseNTok{dependent = "mort_5yr"}
\BaseNTok{colon_s %>% }
\BaseNTok{  or_plot(dependent, explanatory, }
\BaseNTok{          breaks = c(0.5, 1, 5, 10, 20, 30))}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

\hypertarget{pdf-via-knitrr-markdown}{%
\section{PDF via knitr/R Markdown}\label{pdf-via-knitrr-markdown}}

Without changing anything in Example 1 and Knitting it into a PDF, we get \ref{fig:chap13-fig-pdf}A.

Again, most of it already looks pretty good, but some parts over-run the page and the plot is not a good size.

We can fix the plot in exactly the same way we did for the Word version (\texttt{fig.width}), but the second table that is too wide needs some special handling.
For this we use \texttt{kable\_styling(font\_size=8)} from the \texttt{kableExtra} package.
Remember to install it when using for the first time, and include \texttt{library(knitExtra)} alongside the other library lines at the setup chunk.

We will also alter the margins of your page using the geometry option in the preamble as the default margins of a PDF document coming out of R Markdown are a bit wide for us.

\begin{figure}
\includegraphics[width=0.7\linewidth]{images/chapter13/1_pdf_knit} \caption{Knitting to Microsoft Word from R Markdown. Before (A) and after (B) adjustment.}\label{fig:chap13-fig-pdf}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{---}
\NormalTok{title: "Example knitr/R Markdown document"}
\NormalTok{author: "Your name"}
\NormalTok{date: "22/5/2020"}
\NormalTok{output:}
\NormalTok{  pdf_document: default}
\NormalTok{geometry: margin=0.75in}
\NormalTok{---}

\BaseNTok{```\{r setup, include=FALSE\}}
\BaseNTok{# Load data into global environment. }
\BaseNTok{library(finalfit)}
\BaseNTok{library(dplyr)}
\BaseNTok{library(knitr)}
\BaseNTok{library(kableExtra)}
\BaseNTok{load(here::here("data", "out.rda"))}
\BaseNTok{```}

\FunctionTok{## Table 1 - Demographics}
\BaseNTok{```\{r table1, echo = FALSE\}}
\BaseNTok{kable(table1, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),}
\BaseNTok{      booktabs = TRUE)}
\BaseNTok{```}

\FunctionTok{## Table 2 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r table2, echo = FALSE\}}
\BaseNTok{kable(table2, row.names=FALSE, align=c("l", "l", "r", "r", "r", "r"),}
\BaseNTok{      booktabs=TRUE) %>% }
\BaseNTok{kable_styling(font_size=8)}
\BaseNTok{```}

\FunctionTok{## Figure 1 - Association between tumour factors and 5 year mortality}
\BaseNTok{```\{r figure1, echo=FALSE, message=FALSE, warning=FALSE, fig.width=10\}}
\BaseNTok{explanatory = c( "differ.factor", "age", "sex.factor", }
\BaseNTok{                "extent.factor", "obstruct.factor", }
\BaseNTok{                "nodes")}
\BaseNTok{dependent = "mort_5yr"}
\BaseNTok{colon_s %>% }
\BaseNTok{  or_plot(dependent, explanatory, }
\BaseNTok{          breaks = c(0.5, 1, 5, 10, 20, 30))}
\BaseNTok{```}
\end{Highlighting}
\end{Shaded}

The result is shown in Figure \ref{fig:chap13-fig-pdf}B.

\hypertarget{working-in-a-.rmd-file}{%
\section{\texorpdfstring{Working in a \texttt{.Rmd} file}{Working in a .Rmd file}}\label{working-in-a-.rmd-file}}

We now perform almost all our analyses in a Notebook / Markdown file as described in the previous chapter.
This means running all analyses within the document, without the requirement to save and reload table or plot objects.

As mentioned earlier, a Notebook document can be rendered as a PDF or a Word document.
Some refining is usually needed to move from an `analysis' document to a final `report' document, but it is often minimal.

Figure \ref{fig:chap13-fig-report} demonstrates a report-type document rendered as a PDF.
All the code is run within the document, but not included in the output (\texttt{echo=FALSE}).

\begin{figure}
\centering
\includegraphics{images/chapter13/4_colon_report.pdf}
\caption{\label{fig:chap13-fig-report}Writing a final report in a Markdown document.}
\end{figure}

\hypertarget{moving-between-formats}{%
\section{Moving between formats}\label{moving-between-formats}}

As we have shown, it is relatively straightforward to move between HTML, Word and PDF when documents are simple.
This becomes more difficult if you have a complicated document which includes lots of formatting.

For instance, if you use the package \texttt{kableExtra()} to customise your tables, you can only export to HTML and PDF.
Knitting to Word will not currently work with advanced \texttt{kableExtra} functions in your R Markdown document.
Similarly, \texttt{flextable} and \texttt{officer} are exellent packages for a love story between R Markdown and Word/MS Office, but they do not work for HTML or PDF.

\hypertarget{summary-4}{%
\section{Summary}\label{summary-4}}

The combination of R, RStudio, and Markdown is a powerful triumvirate which produces beautiful results quickly and will be greatly labour saving.
We use this combination for all academic work, but also in the production of real-time reports such as webpages and downloadable PDFs for ongoing projects.
This is a fast-moving area with new applications and features appearing every month.
We would highly recommend you spend some time getting familiar with this area, as it will become an ever more important skill in the future.

\hypertarget{chap14-h1}{%
\chapter{Version control}\label{chap14-h1}}

\index{version control@\textbf{version control}}

\begin{quote}
Always be a first rate version of yourself and not a second rate version of someone else.\\
Judy Garland
\end{quote}

Version control is essential for keeping track of data analysis projects, as well as collaborating.
It allows backup of scripts and collaboration on complex projects.
RStudio works really well with Git, an open source distributed version control system, and GitHub, a web-based Git repository hosting service.

\index{version control@\textbf{version control}!Git and GitHub}

Git is a piece of software which runs locally.
It may need to be installed first.

It is important to highlight the difference between Git (local version control software) and GitHub (a web-based repository store).

\hypertarget{setup-git-on-rstudio-and-associate-with-github}{%
\section{Setup Git on RStudio and associate with GitHub}\label{setup-git-on-rstudio-and-associate-with-github}}

In RStudio, go to Tools -\textgreater{} Global Options and select the \textbf{Git/SVN} tab.
Ensure the path to the Git executable is correct.
This is particularly important in Windows where it may not default correctly (e.g., \texttt{C:/Program\ Files\ (x86)/Git/bin/git.exe}).

\hypertarget{create-an-ssh-rsa-key-and-add-to-your-github-account}{%
\section{Create an SSH RSA key and add to your GitHub account}\label{create-an-ssh-rsa-key-and-add-to-your-github-account}}

\index{version control@\textbf{version control}!SSH RSA key}

In the \textbf{Git/SVN} tab, hit \emph{Create RSA Key} (Figure \ref{fig:chap14-fig-ssh}A).
In the window that appears, hit the \emph{Create} button (Figure \ref{fig:chap14-fig-ssh}B).
Close this window.

Click, \emph{View public key} (Figure \ref{fig:chap14-fig-ssh}C), and copy the displayed public key (Figure \ref{fig:chap14-fig-ssh}D).

If you haven't already, create a GitHub account.
On the GitHub website, open the account settings tab and click the SSH keys tab (Figure \ref{fig:chap14-fig-github}A).
Click \emph{Add SSH key} and paste in the public key you have copied from RStudio Figure \ref{fig:chap14-fig-github}B).

\begin{figure}
\centering
\includegraphics{images/chapter14/1.pdf}
\caption{\label{fig:chap14-fig-ssh}Creating an SSH key in RStudio's Global Options.}
\end{figure}

\begin{figure}
\centering
\includegraphics{images/chapter14/2.pdf}
\caption{\label{fig:chap14-fig-github}Adding your RStudio SSH key to your GitHub account.}
\end{figure}

\hypertarget{create-a-project-in-rstudio-and-commit-a-file}{%
\section{Create a project in RStudio and commit a file}\label{create-a-project-in-rstudio-and-commit-a-file}}

\index{version control@\textbf{version control}!Commit}

Next, return to RStudio and configure Git via the \textbf{Terminal} (Figure \ref{fig:chap14-fig-globalsettings}A)).
Remember Git is a piece of software running on your own computer.
This is distinct to GitHub, which is the repository website.

We will now create a new project which we want to backup to GitHub.

In RStudio, click \emph{New project} as normal (Figure \ref{fig:chap14-fig-globalsettings}B).
Click \emph{New Directory}.
Name the project and check \emph{Create a git repository}.
Now in RStudio, create a new script which you will add to your repository.

After saving your new script (e.g., test.R), it should appear in the \textbf{Git} tab beside \textbf{Environment}.

Tick the file you wish to add, and the status should turn to a green `A' (Figure \ref{fig:chap14-fig-globalsettings}C).
Now click \emph{Commit} and enter an identifying message in Commit message (Figure \ref{fig:chap14-fig-globalsettings}D).
It makes sense to do this prior to linking the project and the GitHub repository, otherwise you'll have nothing to push to GitHub.

You have now committed the current version of this file to a Git repository on your computer/server.

\begin{figure}
\centering
\includegraphics{images/chapter14/4.pdf}
\caption{\label{fig:chap14-fig-globalsettings}Configuring your GitHub account via RStudio, creating a new project, commiting a script and pushing it to GitHub.}
\end{figure}

\hypertarget{create-a-new-repository-on-github-and-link-to-rstudio-project}{%
\section{Create a new repository on GitHub and link to RStudio project}\label{create-a-new-repository-on-github-and-link-to-rstudio-project}}

\index{version control@\textbf{version control}!repository}

Now you may want to push the contents of this commit to GitHub, so it is also backed-up off site and available to collaborators.
As always, you must exercise caution when working with sensitive data.
Take steps to stop yourself from accidentally pushing whole datasets to GitHub.\footnote{It's fine to push some data to GitHub, especially if you want to make it publicly available, but you should do so consciously, not accidentally.}
You only want to push R code to GitHub, not the (sensitive) data.

When you see a dataset appear in the Git tab of your RStudio, select it, then click on More, and then Ignore.
This means the file does not get included in your Git repository, and it does not get pushed to GitHub.
GitHub is not for backing up sensitive datasets, it's for backing up R code.
And make sure your R code does not include passwords or access tokens.

In GitHub, create a \emph{New repository}, called here myproject (Figure \ref{fig:chap14-fig-newrepo}A).
You will now see the \emph{Quick setup} page on GitHub.
Copy the code below \emph{push an existing repository from the command line} (Figure \ref{fig:chap14-fig-newrepo}B).

\begin{figure}
\centering
\includegraphics{images/chapter14/5.pdf}
\caption{\label{fig:chap14-fig-newrepo}Create a new repository (repo) on GitHub.}
\end{figure}

Back in RStudio, paste the code into the \textbf{Terminal}.
Add your GitHub username and password (important!) (Figure \ref{fig:chap14-fig-link}A).
You have now pushed your commit to GitHub, and should be able to see your files in your GitHub account.

\index{version control@\textbf{version control}!pull and push}

The \textbf{Pull} and \textbf{Push} buttons in RStudio will now also work (Figure \ref{fig:chap14-fig-link}B).

To avoid always having to enter your password, copy the SSH address from GitHub and enter the code shown in Figure \ref{fig:chap14-fig-link}C and D.

Check that the \textbf{Pull} and \textbf{Push} buttons work as expected (Figure \ref{fig:chap14-fig-link}E).
Remember, after each Commit, you have to Push to GitHub, this doesn't happen automatically.

\begin{figure}
\centering
\includegraphics{images/chapter14/6.pdf}
\caption{\label{fig:chap14-fig-link}Linking an RStudio project with a GitHub repository.}
\end{figure}

\hypertarget{clone-an-existing-github-project-to-new-rstudio-project}{%
\section{Clone an existing GitHub project to new RStudio project}\label{clone-an-existing-github-project-to-new-rstudio-project}}

\index{version control@\textbf{version control}!clone}

An alternative situation is where a project already exists on GitHub and you want to copy it to an RStudio project. In version control world, this is called \textbf{cloning}.

In RStudio, click \emph{New project} as normal. Click \emph{Version Control} and select \emph{Git}.

In \emph{Clone Git Repository}, enter the GitHub repository URL as per Figure \ref{fig:chap14-fig-clone}C.
Change the project directory name if necessary.

As above, to avoid repeatedly having to enter passwords, follow the steps in Figure \ref{fig:chap14-fig-clone}D and E.

\begin{figure}
\centering
\includegraphics{images/chapter14/7.pdf}
\caption{\label{fig:chap14-fig-clone}Clone a GitHub repository to an RStudio project.}
\end{figure}

\hypertarget{summary-5}{%
\section{Summary}\label{summary-5}}

If your project is worth doing, then it is worth backing up!
This means you should use version control for every single project you are involved in.
You will quickly be surprised at how many times you wish to go back and rescue some deleted code, or to restore an accidentally deleted file.

It becomes even more important when collaborating and many individuals may be editing the same file.
As with the previous chapter, this is an area which data scientists have discovered much later than computer scientists.
Get it up and running in your own workflow and you will reap the rewards in the future.

\hypertarget{encryption}{%
\chapter{Encryption}\label{encryption}}

\index{encryption@\textbf{encryption}}

\begin{quote}
Encryption matters, and it is not just for spies and philanderers.\\
Glenn Greenwald
\end{quote}

Health data is precious and often sensitive.
Datasets may contain patient identifiable information.
Information may be clearly disclosive, such as a patient's date of birth, post/zip code, or social security number.

Other datasets may have been processed to remove the most obviously confidential information.
These still require great care, as the data is usually only `pseudoanonymised'.
This may mean that the data of an individual patient is disclosive when considered as a whole - perhaps the patient had a particularly rare diagnosis.
Or it may mean that the data can be combined with other datasets and in combination, individual patients can be identified.

The governance around safe data handling is one of the greatest challenges facing health data scientists today.
It needs to be taken very seriously and robust practices must be developed to ensure public confidence.

\hypertarget{safe-practice}{%
\section{Safe practice}\label{safe-practice}}

Storing sensitive information as raw values leaves the data vulnerable to confidentiality breaches.
This is true even when you are working in a `safe' environment, such as a secure server.

It is best to simply remove as much confidential information from records whenever possible.
If the data is not present, then it cannot be compromised.

This might not be a good idea if the data might need to be linked back to an individual at some unspecified point in the future.
This may be a problem if, for example, auditors of a clinical trial need to re-identify an individual from the trial data.
A study ID can be used, but that still requires the confidential data to be stored and available in a lookup table in another file.

This chapter is not a replacement for an information governance course.
These are essential and the reader should follow their institution's guidelines on this.
The chapter does introduce a useful R package and encryption functions that you may need to incorporate into your data analysis workflow.

\hypertarget{encryptr-package}{%
\section{\texorpdfstring{\textbf{encryptr} package}{encryptr package}}\label{encryptr-package}}

\index{encryption@\textbf{encryption}!encryptr}

The \textbf{encryptr} package is our own and allows users to store confidential data in a pseudoanonymised form, which is far less likely to result in re-identification.

Either columns in data frames/tibbles or whole files can be directly encrypted from R using strong RSA encryption.

The basis of RSA encryption is a public/private key pair and is the method used of many modern encryption applications.
The public key can be shared and is used to encrypt the information.

The private key is sensitive and should not be shared.
The private key requires a password to be set, which should follow modern rules on password complexity.
You know what you should do!
If the password is lost, it cannot be recovered.

\hypertarget{get-the-package}{%
\section{Get the package}\label{get-the-package}}

The \textbf{encryptr} package can be installed in the standard manner or the development version can be obtained from GitHub.

Full documentation is maintained separately at \href{https://encrypt-r.org}{encrypt-r.org}.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{install.packages}\NormalTok{(}\StringTok{"encryptr"}\NormalTok{)}

\CommentTok{# Or the development version from Github}
\NormalTok{remotes}\OperatorTok{::}\KeywordTok{install_github}\NormalTok{(}\StringTok{"surgicalinformatics/encryptr"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{get-the-data-6}{%
\section{Get the data}\label{get-the-data-6}}

An example dataset containing the addresses of general practitioners (family doctors) in Scotland is included in the package.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(encryptr)}
\NormalTok{gp}
\CommentTok{#> A tibble: 1,212 x 12}
\CommentTok{#>   organisation_code name    address1 address2 address3 city  postcode}
\CommentTok{#>   <chr>             <chr>   <chr>    <chr>    <chr>    <chr> <chr>}
\CommentTok{#> 1 S10002            MUIRHE… LIFF RO… MUIRHEAD NA       DUND… DD2 5NH}
\CommentTok{#> 2 S10017            THE BL… CRIEFF … KING ST… NA       CRIE… PH7 3SA}
\end{Highlighting}
\end{Shaded}

\hypertarget{generate-privatepublic-keys}{%
\section{Generate private/public keys}\label{generate-privatepublic-keys}}

\index{encryption@\textbf{encryption}!public/private keys}

The \texttt{genkeys()} function generates a public and private key pair.
A password is required to be set in the dialogue box for the private key.
Two files are written to the active directory.

The default name for the private key is:

\begin{itemize}
\tightlist
\item
  \texttt{id\_rsa}
\end{itemize}

And for the public key name is generated by default:

\begin{itemize}
\tightlist
\item
  \texttt{id\_rsa.pub}
\end{itemize}

If the private key file is lost, nothing encrypted with the public key can be recovered.
Keep this safe and secure.
Do not share it without a lot of thought on the implications.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{genkeys}\NormalTok{()}
\CommentTok{#> Private key written with name 'id_rsa'}
\CommentTok{#> Public key written with name 'id_rsa.pub'}
\end{Highlighting}
\end{Shaded}

\hypertarget{encrypt-columns-of-data}{%
\section{Encrypt columns of data}\label{encrypt-columns-of-data}}

\index{encryption@\textbf{encryption}!columns, encrypt}

Once the keys are created, it is possible to encrypt one or more columns of data in a data frame/tibble using the public key.
Every time RSA encryption is used it will generate a unique output.
Even if the same information is encrypted more than once, the output will always be different.
It is therefore not possible to match two encrypted values.

These outputs are also secure from decryption without the private key.
This may allow sharing of data within or between research teams without sharing confidential data.

Encrypting columns to a ciphertext is straightforward.
However, as stated above, an important principle is dropping sensitive data which is never going to be required.
Do not hoard more data than you need to answer your question.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{library}\NormalTok{(dplyr)}
\NormalTok{gp_encrypt =}\StringTok{ }\NormalTok{gp }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(name, address1, address2, address3)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{encrypt}\NormalTok{(postcode)}
\NormalTok{gp_encrypt}

\CommentTok{#> A tibble: 1,212 x 8}
\CommentTok{#>   organisation_code city        county     postcode }
\CommentTok{#>   <chr>             <chr>       <chr>      <chr>    }
\CommentTok{#> 1 S10002            DUNDEE      ANGUS      796284eb46ca…  }
\CommentTok{#> 2 S10017            CRIEFF      PERTHSHIRE 639dfc076ae3… }
\end{Highlighting}
\end{Shaded}

\hypertarget{decrypt-specific-information-only}{%
\section{Decrypt specific information only}\label{decrypt-specific-information-only}}

\index{encryption@\textbf{encryption}!columns, decrypt}

Decryption requires the private key generated using \texttt{genkeys()} and the password set at the time.
The password and file are not replaceable so need to be kept safe and secure.
It is important to only decrypt the specific pieces of information that are required.
The beauty of this system is that when decrypting a specific cell, the rest of the data remain secure.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gp_encrypt }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{slice}\NormalTok{(}\DecValTok{1}\OperatorTok{:}\DecValTok{2}\NormalTok{) }\OperatorTok{%>%}\StringTok{     }\CommentTok{# Only decrypt the rows and columns necessary}
\StringTok{  }\KeywordTok{decrypt}\NormalTok{(postcode)}
  
\CommentTok{#> A tibble: 1,212 x 8}
\CommentTok{#>   organisation_code city        county     postcode }
\CommentTok{#>   <chr>             <chr>       <chr>      <chr>    }
\CommentTok{#> 1 S10002            DUNDEE      ANGUS      DD2 5NH  }
\CommentTok{#> 2 S10017            CRIEFF      PERTHSHIRE PH7 3SA  }
\end{Highlighting}
\end{Shaded}

\hypertarget{using-a-lookup-table}{%
\section{Using a lookup table}\label{using-a-lookup-table}}

\index{encryption@\textbf{encryption}!lookup table}

Rather than storing the ciphertext in the working data frame, a lookup table can be used as an alternative.
Using \texttt{lookup\ =\ TRUE} has the following effects:

\begin{itemize}
\tightlist
\item
  returns the data frame / tibble with encrypted columns removed and a \texttt{key} column included;
\item
  returns the lookup table as an object in the R environment;
\item
  creates a lookup table \texttt{.csv} file in the active directory.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gp_encrypt =}\StringTok{ }\NormalTok{gp }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(name, address1, address2, address3)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{encrypt}\NormalTok{(postcode, telephone, }\DataTypeTok{lookup =} \OtherTok{TRUE}\NormalTok{)}
  
\CommentTok{#> Lookup table object created with name 'lookup'}
\CommentTok{#> Lookup table written to file with name 'lookup.csv'}

\NormalTok{gp_encrypt}

\CommentTok{#> A tibble: 1,212 x 7}
\CommentTok{#>   key   organisation_code city      county     opendate   }
\CommentTok{#>   <int> <chr>             <chr>     <chr>      <date>     }
\CommentTok{#> 1 1     S10002            DUNDEE    ANGUS      1995-05-01 }
\CommentTok{#> 2 2     S10017            CRIEFF    PERTHSHIRE 1996-04-06 }
\end{Highlighting}
\end{Shaded}

The file creation can be turned off with \texttt{write\_lookup\ =\ FALSE} and the name of the lookup can be changed with \texttt{lookup\_name\ =\ "anyNameHere"}.
The created lookup file should be itself encrypted using the method below.

Decryption is performed by passing the lookup object or file to the \texttt{decrypt()} function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gp_encrypt }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{decrypt}\NormalTok{(postcode, telephone, }\DataTypeTok{lookup_object =}\NormalTok{ lookup)}

\CommentTok{# Or}
\NormalTok{gp_encrypt }\OperatorTok{%>%}\StringTok{  }
\StringTok{  }\KeywordTok{decrypt}\NormalTok{(postcode, telephone, }\DataTypeTok{lookup_path =} \StringTok{"lookup.csv"}\NormalTok{)}

\CommentTok{#> A tibble: 1,212 x 8}
\CommentTok{#>   postcode telephone    organisation_code city    county     opendate   }
\CommentTok{#>   <chr>    <chr>        <chr>             <chr>   <chr>      <date>     }
\CommentTok{#>  1 DD2 5NH 01382 580264 S10002            DUNDEE  ANGUS      1995-05-01 }
\CommentTok{#>  2 PH7 3SA 01764 652283 S10017            CRIEFF  PERTHSHIRE 1996-04-06}
\end{Highlighting}
\end{Shaded}

\hypertarget{encrypting-a-file}{%
\section{Encrypting a file}\label{encrypting-a-file}}

\index{encryption@\textbf{encryption}!file, encrypt}

Encrypting the object within R has little point if a file with the disclosive information is still present on the system.
Files can be encrypted and decrypted using the same set of keys.

To demonstrate, the included dataset is written as a .csv file.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{write_csv}\NormalTok{(gp, }\StringTok{"gp.csv"}\NormalTok{)}

\KeywordTok{encrypt_file}\NormalTok{(}\StringTok{"gp.csv"}\NormalTok{)}
\CommentTok{#> Encrypted file written with name 'gp.csv.encryptr.bin'}
\end{Highlighting}
\end{Shaded}

Check that the file can be decrypted prior to removing the original file from your system.

Warning: it is strongly suggested that the original unencrypted data file backed up in a secure system in case de-encryption is not possible, e.g., the private key file or password is lost.

\hypertarget{decrypting-a-file}{%
\section{Decrypting a file}\label{decrypting-a-file}}

\index{encryption@\textbf{encryption}!file, decrypt}

The \texttt{decrypt\_file} function will not allow the original file to be overwritten, therefore use the option to specify a new name for the unencrypted file.

\begin{Shaded}
\begin{Highlighting}[]
\KeywordTok{decrypt_file}\NormalTok{(}\StringTok{"gp.csv.encryptr.bin"}\NormalTok{, }\DataTypeTok{file_name =} \StringTok{"gp2.csv"}\NormalTok{)}

\CommentTok{#> Decrypted file written with name 'gp2.csv'}
\end{Highlighting}
\end{Shaded}

\hypertarget{ciphertexts-are-not-matchable}{%
\section{Ciphertexts are not matchable}\label{ciphertexts-are-not-matchable}}

The ciphertext produced for a given input will change with each encryption.
This is a feature of the RSA algorithm.
Ciphertexts should not therefore be attempted to be matched between datasets encrypted using the same public key.
This is a conscious decision given the risks associated with sharing the necessary details.

\hypertarget{providing-a-public-key}{%
\section{Providing a public key}\label{providing-a-public-key}}

\index{encryption@\textbf{encryption}!public key sharing}

In collaborative projects where data may be pooled, a public key can be made available by you via a link to enable collaborators to encrypt sensitive data.
This provides a robust method for sharing potentially disclosive data points.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gp_encrypt =}\StringTok{ }\NormalTok{gp }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{select}\NormalTok{(}\OperatorTok{-}\KeywordTok{c}\NormalTok{(name, address1, address2, address3)) }\OperatorTok{%>%}\StringTok{ }
\StringTok{  }\KeywordTok{encrypt}\NormalTok{(postcode, telephone, }\DataTypeTok{public_key_path =} 
            \StringTok{"https://argonaut.is.ed.ac.uk/public/id_rsa.pub"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{use-cases}{%
\section{Use cases}\label{use-cases}}

\index{encryption@\textbf{encryption}!use cases}

\hypertarget{blinding-in-trials}{%
\subsection{Blinding in trials}\label{blinding-in-trials}}

A potential application is maintaining blinding / allocation concealment in randomised controlled clinical trials.
Using the same method of encryption, it is possible to encrypt the participant allocation group, allowing the sharing of data without compromising blinding.
If other members of the trial team are permitted to see treatment allocation (unblinded), then the decryption process can be followed to reveal the group allocation.

The benefit of this approach is that each ciphertext is unique.
This prevents researchers identifying patterns of outcomes or adverse events within a named group such as ``Group A''.
Instead, each participant appears to have a truly unique allocation group which can only be revealed by the decryption process.
In situations such as block randomisation, where the trial enrolment personnel are blinded to the allocation, this unique ciphertext further limits the impact of selection bias.

\hypertarget{re-contacting-participants}{%
\subsection{Re-contacting participants}\label{re-contacting-participants}}

Clinical research often requires further contact of participants for either planned follow-up or sometimes in cases of early cessation of trials due to harm.
\textbf{encryptr} allows the storage of contact details in pseudoanonymised format that can be decrypted only when necessary.

For example, investigators running a randomised clinical trial of a novel therapeutic agent may decide that all enrolled participants taking another medication should withdraw due to a major drug interaction.
Using a basic filter, patients taking this medication could be identified and the telephone numbers decrypted for these participants.
The remaining telephone numbers would remain encrypted preventing unnecessary re-identification of participants.

\hypertarget{long-term-follow-up-of-participants}{%
\subsection{Long-term follow-up of participants}\label{long-term-follow-up-of-participants}}

Researchers with approved projects may one day receive approval to carry out additional follow-up through tracking of outcomes through electronic healthcare records or re-contact of patients.
Should a follow-up study be approved, patient identifiers stored as ciphertexts could then be decrypted to allow matching of the participant to their own health records.

\hypertarget{summary-6}{%
\section{Summary}\label{summary-6}}

All confidential information must be treated with the utmost care.
Data should never be carried on removable devices or portable computers.
Data should never be sent by open email.
Encrypting data provides some protection against disclosure.
But particularly in healthcare, data often remains potentially disclosive (or only pseudoanonymised) even after encryption of identifiable variables.
Treat it with great care and respect.

\hypertarget{appendix}{%
\chapter*{Appendix}\label{appendix}}


This book was written in \textbf{bookdown}, which is an R package built on top of R Markdown (\citet{xie2016}).

The main packages used in this book were: \textbf{tidyverse, ggplot2, tibble, tidyr, readr, purrr, dplyr, stringr, forcats, finalfit, bookdown, broom, encryptr, gapminder, GGally, ggfortify, kableExtra, knitr, lme4, lubridate, magrittr, mice, MissMech, patchwork, rmarkdown, scales, survival, and survminer}.

R and package versions, \texttt{sessionInfo()}:

\begin{verbatim}
## R version 3.6.1 (2019-07-05)
## Platform: x86_64-pc-linux-gnu (64-bit)
## Running under: Ubuntu 16.04.6 LTS
## 
## Locale:
##   LC_CTYPE=en_GB.UTF-8       LC_NUMERIC=C              
##   LC_TIME=en_GB.UTF-8        LC_COLLATE=en_GB.UTF-8    
##   LC_MONETARY=en_GB.UTF-8    LC_MESSAGES=en_GB.UTF-8   
##   LC_PAPER=en_GB.UTF-8       LC_NAME=C                 
##   LC_ADDRESS=C               LC_TELEPHONE=C            
##   LC_MEASUREMENT=en_GB.UTF-8 LC_IDENTIFICATION=C       
## 
## Package version:
##   bookdown_0.20.2       broom_0.7.0           dplyr_1.0.0          
##   encryptr_0.1.3        finalfit_1.0.2        forcats_0.5.0        
##   gapminder_0.3.0       GGally_2.0.0          ggfortify_0.4.10     
##   ggplot2_3.3.2         kableExtra_1.1.0.9000 knitr_1.29           
##   lme4_1.1.23           lubridate_1.7.9       magrittr_1.5         
##   mice_3.10.0           MissMech_1.0.2        patchwork_1.0.1      
##   purrr_0.3.4           readr_1.3.1           rmarkdown_2.3        
##   scales_1.1.1          stringr_1.4.0         survival_3.2.3       
##   survminer_0.4.7       tibble_3.0.3          tidyr_1.1.0          
##   tidyverse_1.3.0
\end{verbatim}

  \bibliography{book.bib,packages.bib}

\backmatter
\printindex

\end{document}
